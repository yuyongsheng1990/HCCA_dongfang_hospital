{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n2022.3.9\\n术后预后模型：\\n    生存时间模型\\n    风险评分模型\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "2022.3.9\n",
    "术后预后模型：\n",
    "    生存时间模型\n",
    "    风险评分模型\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "project_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model =pd.read_excel(project_path +'/data/result/feature_engineering/df_4.5_model_data_forward-术后.xlsx',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'jaundice', 'N', 'M', 'Gazzaniga_T', 'MSKCC', 'Blumgart_T',\n",
       "       'Bismuth_C', 'cardio_disease', 'nbdd', 'HCVAb', 'DB', 'ALT',\n",
       "       'biliary_disease', 'HBsAg', 'T', 'surgery_result', 'emaciation',\n",
       "       'tumor_CEA', 'tumor_CA19-9', 'tumor_CA125', 'tumor_size', 'tumor_AFP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    129\n",
       "1    111\n",
       "0    100\n",
       "3     77\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_col=['jaundice', 'N', 'M', 'Gazzaniga_T', 'MSKCC', 'Blumgart_T','Bismuth_C', 'cardio_disease', \n",
    "              'nbdd', 'HCVAb','biliary_disease', 'HBsAg', 'T', 'surgery_result', 'emaciation']\n",
    "\n",
    "continuous_col=[x for x in df_model.columns if x not in discrete_col]\n",
    "continuous_col.remove('label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 防止不同维特征数据差距过大，影响建模效果\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "# df_model[continuous_col]=ss.fit_transform(df_model[continuous_col])\n",
    "for i in continuous_col:\n",
    "    df_model[[i]] = ss.fit_transform(df_model[[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'jaundice', 'N', 'M', 'Gazzaniga_T', 'MSKCC', 'Blumgart_T',\n",
       "       'Bismuth_C', 'cardio_disease', 'nbdd', 'HCVAb', 'DB', 'ALT',\n",
       "       'biliary_disease', 'HBsAg', 'T', 'surgery_result', 'emaciation',\n",
       "       'tumor_CEA', 'tumor_CA19-9', 'tumor_CA125', 'tumor_size', 'tumor_AFP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.to_excel(project_path+'/data/result/modeling/df_1.2_数据归一化.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 插补数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用随机森林对缺失值进行插补\n",
    "import pandas as pd\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "def missing_value_interpolation(df):\n",
    "    df = df.reset_index(drop=True)\n",
    "    # 提取存在缺失值的列名\n",
    "    missing_list = []\n",
    "    for i in df.columns:\n",
    "        if df[i].isnull().sum()>0:\n",
    "            missing_list.append(i)\n",
    "    missing_list_copy = missing_list.copy()\n",
    "    # 用该列未缺失的值训练随机森林，然后用训练好的rf预测缺失值\n",
    "    for i in range(len(missing_list)):\n",
    "        name=missing_list[0]\n",
    "        df_missing = df[missing_list_copy]\n",
    "        # 将其他列的缺失值用0表示。\n",
    "        missing_list.remove(name)\n",
    "        for j in missing_list:\n",
    "            df_missing[j]=df_missing[j].astype('str').apply(lambda x: 0 if x=='nan' else x)\n",
    "        df_missing_is = df_missing[df_missing[name].isnull()]\n",
    "        df_missing_not = df_missing[df_missing[name].notnull()]\n",
    "        y = df_missing_not[name]\n",
    "        x = df_missing_not.drop([name],axis=1)\n",
    "\n",
    "        rfr = RandomForestRegressor(n_estimators=300,\n",
    "                                    random_state=3)\n",
    "        rfr.fit(x, y)\n",
    "        #预测缺失值\n",
    "        predict = rfr.predict(df_missing_is.drop([name],axis=1))\n",
    "        #填补缺失值\n",
    "        df.loc[df[name].isnull(),name] = predict\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 插补建模数据\n",
    "df_model_cb=missing_value_interpolation(df_model)\n",
    "# df_model_cb=df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417, 23)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_cb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存插补数据\n",
    "df_model_cb.to_excel(project_path + '/data/result/modeling/df_1.3_model_data_插补.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算随机数种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:01:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:01:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:01:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:01:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:01:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:01:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:01:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:01:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:01:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:01:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:01:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:01:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:01:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:02:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:02:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:02:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:03:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:03:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import r2_score,average_precision_score,precision_recall_curve\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,roc_auc_score,accuracy_score\n",
    "\n",
    "# 划分训练集和测试集，比例为8:2\n",
    "x = df_model_cb.drop(['label'],axis=1)\n",
    "y = df_model_cb['label']\n",
    "\n",
    "seeds_list=[]\n",
    "cat_f1_list=[]\n",
    "for i in range(101):\n",
    "    \n",
    "    tran_x, test_x, tran_y, test_y = train_test_split(x, y, test_size=0.2, random_state=i)\n",
    "    \n",
    "    # 分类数据过采样\n",
    "    from imblearn.over_sampling import SMOTE,ADASYN \n",
    "    sm = SMOTE(random_state=0)\n",
    "    tran_x_sm,tran_y_sm = sm.fit_resample(tran_x,tran_y)\n",
    "#     tran_x_sm,tran_y_sm=tran_x,tran_y\n",
    "    \n",
    "    import xgboost\n",
    "    cat_model=xgboost.XGBClassifier(max_depth=5,\n",
    "                        learning_rate=0.01,\n",
    "                        n_estimators=500,\n",
    "                        min_child_weight=0.5,\n",
    "                        eta=0.1,\n",
    "                        gamma=0.5,\n",
    "                        reg_lambda=10,\n",
    "                        subsample=0.5,\n",
    "                        colsample_bytree=0.8,\n",
    "                        nthread=4,\n",
    "                        scale_pos_weight=1,\n",
    "                        random_state=3)\n",
    "    # 分类模型\n",
    "    cat_model.fit(tran_x_sm,tran_y_sm)\n",
    "    cat_predictions=cat_model.predict(test_x)\n",
    "    cat_f1=f1_score(test_y,cat_predictions,average='macro')\n",
    "    # 防止分类数据的测试集划分不平衡\n",
    "    if not (2 >=(test_y.value_counts().values[0])/(test_y.value_counts().values[-1]) >=1):\n",
    "        continue\n",
    "\n",
    "#     import catboost\n",
    "#     # CatBoost模型\n",
    "#     cat_model=catboost.CatBoostRegressor(iterations=300, \n",
    "#                                           learning_rate=0.2, \n",
    "#                                           depth=6,\n",
    "#                                           l2_leaf_reg=2,\n",
    "#                                           subsample=1,\n",
    "#                                           loss_function='RMSE', # 'CrossEntropy',\n",
    "#                                           random_state=3)\n",
    "#     # 回归模型\n",
    "#     cat_model.fit(tran_x,tran_y)\n",
    "#     cat_predictions=cat_model.predict(test_x)\n",
    "#     cat_f1=r2_score(test_y,cat_predictions)\n",
    "    \n",
    "    seeds_list.append(i)\n",
    "    cat_f1_list.append(cat_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    27\n",
       "2    20\n",
       "0    20\n",
       "3    17\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "df_seeds=pd.DataFrame(data={'seed':seeds_list,\n",
    "                           'cat_f1':cat_f1_list})\n",
    "df_seeds=df_seeds.sort_values(['cat_f1'], ascending=0).reset_index(drop=True)\n",
    "df_seeds.to_excel(project_path+'/data/df_seeds.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_index=df_seeds.loc[0,'seed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分类随机数种子\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 划分训练集和测试集，比例为8:2\n",
    "x = df_model_cb.drop(['label'],axis=1)\n",
    "y = df_model_cb['label']\n",
    "\n",
    "tran_x, test_x, tran_y, test_y = train_test_split(x, y, test_size=0.2, random_state=seed_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417, 23)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333, 22)\n",
      "(84, 22)\n"
     ]
    }
   ],
   "source": [
    "print(tran_x.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    129\n",
       "1    111\n",
       "0    100\n",
       "3     77\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    108\n",
       "1     86\n",
       "0     80\n",
       "3     59\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25\n",
       "2    21\n",
       "0    20\n",
       "3    18\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaundice</th>\n",
       "      <th>N</th>\n",
       "      <th>M</th>\n",
       "      <th>Gazzaniga_T</th>\n",
       "      <th>MSKCC</th>\n",
       "      <th>Blumgart_T</th>\n",
       "      <th>Bismuth_C</th>\n",
       "      <th>cardio_disease</th>\n",
       "      <th>nbdd</th>\n",
       "      <th>HCVAb</th>\n",
       "      <th>...</th>\n",
       "      <th>biliary_disease</th>\n",
       "      <th>HBsAg</th>\n",
       "      <th>T</th>\n",
       "      <th>surgery_result</th>\n",
       "      <th>emaciation</th>\n",
       "      <th>tumor_CEA</th>\n",
       "      <th>tumor_CA19-9</th>\n",
       "      <th>tumor_CA125</th>\n",
       "      <th>tumor_size</th>\n",
       "      <th>tumor_AFP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.214341</td>\n",
       "      <td>-0.916045</td>\n",
       "      <td>-0.205619</td>\n",
       "      <td>0.106830</td>\n",
       "      <td>-0.112759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>-0.260471</td>\n",
       "      <td>1.666576</td>\n",
       "      <td>-0.134375</td>\n",
       "      <td>-0.753887</td>\n",
       "      <td>-0.097976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120107</td>\n",
       "      <td>-0.601906</td>\n",
       "      <td>-0.137012</td>\n",
       "      <td>-1.614604</td>\n",
       "      <td>-0.093049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>-0.179743</td>\n",
       "      <td>0.350135</td>\n",
       "      <td>-0.121279</td>\n",
       "      <td>-0.753887</td>\n",
       "      <td>-0.009282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.164143</td>\n",
       "      <td>-0.820867</td>\n",
       "      <td>-0.184461</td>\n",
       "      <td>0.106830</td>\n",
       "      <td>-0.087308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     jaundice    N    M  Gazzaniga_T  MSKCC  Blumgart_T  Bismuth_C  \\\n",
       "302         1  0.0  0.0          1.0    1.0         1.0        3.0   \n",
       "375         1  0.0  0.0          1.0    1.0         1.0        2.0   \n",
       "214         1  0.0  0.0          1.0    1.0         1.0        3.0   \n",
       "255         1  0.0  0.0          1.0    1.0         1.0        3.0   \n",
       "235         1  1.0  0.0          1.0    1.0         1.0        2.0   \n",
       "\n",
       "     cardio_disease  nbdd  HCVAb  ...  biliary_disease     HBsAg    T  \\\n",
       "302               0     0    0.0  ...              0.0  0.000000  2.0   \n",
       "375               0     0    0.0  ...              0.0  0.053333  2.0   \n",
       "214               0     1    0.0  ...              0.0  0.000000  2.0   \n",
       "255               0     0    0.0  ...              0.0  0.000000  2.0   \n",
       "235               0     1    0.0  ...              0.0  0.000000  4.0   \n",
       "\n",
       "     surgery_result  emaciation  tumor_CEA  tumor_CA19-9  tumor_CA125  \\\n",
       "302             0.0    0.000000  -0.214341     -0.916045    -0.205619   \n",
       "375             0.0    0.226667  -0.260471      1.666576    -0.134375   \n",
       "214             0.0    0.000000   0.120107     -0.601906    -0.137012   \n",
       "255             0.0    0.226667  -0.179743      0.350135    -0.121279   \n",
       "235             1.0    0.000000  -0.164143     -0.820867    -0.184461   \n",
       "\n",
       "     tumor_size  tumor_AFP  \n",
       "302    0.106830  -0.112759  \n",
       "375   -0.753887  -0.097976  \n",
       "214   -1.614604  -0.093049  \n",
       "255   -0.753887  -0.009282  \n",
       "235    0.106830  -0.087308  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaundice</th>\n",
       "      <th>N</th>\n",
       "      <th>M</th>\n",
       "      <th>Gazzaniga_T</th>\n",
       "      <th>MSKCC</th>\n",
       "      <th>Blumgart_T</th>\n",
       "      <th>Bismuth_C</th>\n",
       "      <th>cardio_disease</th>\n",
       "      <th>nbdd</th>\n",
       "      <th>HCVAb</th>\n",
       "      <th>...</th>\n",
       "      <th>biliary_disease</th>\n",
       "      <th>HBsAg</th>\n",
       "      <th>T</th>\n",
       "      <th>surgery_result</th>\n",
       "      <th>emaciation</th>\n",
       "      <th>tumor_CEA</th>\n",
       "      <th>tumor_CA19-9</th>\n",
       "      <th>tumor_CA125</th>\n",
       "      <th>tumor_size</th>\n",
       "      <th>tumor_AFP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.231640</td>\n",
       "      <td>-1.005340</td>\n",
       "      <td>-0.185416</td>\n",
       "      <td>0.106830</td>\n",
       "      <td>-0.117686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.168210</td>\n",
       "      <td>-0.903479</td>\n",
       "      <td>-0.224759</td>\n",
       "      <td>-1.528532</td>\n",
       "      <td>0.049847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.012519</td>\n",
       "      <td>-0.267716</td>\n",
       "      <td>-0.092006</td>\n",
       "      <td>0.106830</td>\n",
       "      <td>0.059702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.179743</td>\n",
       "      <td>-0.468230</td>\n",
       "      <td>0.112319</td>\n",
       "      <td>-0.323528</td>\n",
       "      <td>-0.043774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.248939</td>\n",
       "      <td>-0.918985</td>\n",
       "      <td>-0.206682</td>\n",
       "      <td>-0.227128</td>\n",
       "      <td>0.025210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     jaundice    N    M  Gazzaniga_T  MSKCC  Blumgart_T  Bismuth_C  \\\n",
       "379         1  0.0  0.0          3.0    3.0         4.0        3.0   \n",
       "42          0  0.0  0.0          1.0    1.0         1.0        3.0   \n",
       "250         1  0.0  0.0          1.0    1.0         1.0        1.0   \n",
       "320         1  0.0  0.0          1.0    1.0         1.0        2.0   \n",
       "221         1  0.0  0.0          1.0    1.0         1.0        1.0   \n",
       "\n",
       "     cardio_disease  nbdd  HCVAb  ...  biliary_disease  HBsAg    T  \\\n",
       "379               0     0    0.0  ...              0.0    0.0  4.0   \n",
       "42                0     0    0.0  ...              0.0    0.0  2.0   \n",
       "250               0     0    0.0  ...              0.0    0.0  2.0   \n",
       "320               0     0    0.0  ...              0.0    0.0  2.0   \n",
       "221               1     0    0.0  ...              0.0    0.0  2.0   \n",
       "\n",
       "     surgery_result  emaciation  tumor_CEA  tumor_CA19-9  tumor_CA125  \\\n",
       "379             0.0         0.0  -0.231640     -1.005340    -0.185416   \n",
       "42              0.0         0.0  -0.168210     -0.903479    -0.224759   \n",
       "250             0.0         2.0  -0.012519     -0.267716    -0.092006   \n",
       "320             0.0         0.0  -0.179743     -0.468230     0.112319   \n",
       "221             0.0         0.0  -0.248939     -0.918985    -0.206682   \n",
       "\n",
       "     tumor_size  tumor_AFP  \n",
       "379    0.106830  -0.117686  \n",
       "42    -1.528532   0.049847  \n",
       "250    0.106830   0.059702  \n",
       "320   -0.323528  -0.043774  \n",
       "221   -0.227128   0.025210  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379    0\n",
       "42     0\n",
       "250    3\n",
       "320    1\n",
       "221    3\n",
       "      ..\n",
       "3      1\n",
       "189    2\n",
       "13     1\n",
       "301    1\n",
       "293    3\n",
       "Name: label, Length: 84, dtype: int64"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练集过采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行过采样\n",
    "from imblearn.over_sampling import SMOTE,ADASYN \n",
    "from imblearn.combine import SMOTETomek\n",
    "sm = SMOTE(random_state=0)\n",
    "# sm=ADASYN(random_state=0)\n",
    "\n",
    "tran_x_sm,tran_y_sm = sm.fit_resample(tran_x,tran_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(432, 22)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran_x_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    108\n",
       "2    108\n",
       "1    108\n",
       "0    108\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran_y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaundice</th>\n",
       "      <th>N</th>\n",
       "      <th>M</th>\n",
       "      <th>Gazzaniga_T</th>\n",
       "      <th>MSKCC</th>\n",
       "      <th>Blumgart_T</th>\n",
       "      <th>Bismuth_C</th>\n",
       "      <th>cardio_disease</th>\n",
       "      <th>nbdd</th>\n",
       "      <th>HCVAb</th>\n",
       "      <th>...</th>\n",
       "      <th>biliary_disease</th>\n",
       "      <th>HBsAg</th>\n",
       "      <th>T</th>\n",
       "      <th>surgery_result</th>\n",
       "      <th>emaciation</th>\n",
       "      <th>tumor_CEA</th>\n",
       "      <th>tumor_CA19-9</th>\n",
       "      <th>tumor_CA125</th>\n",
       "      <th>tumor_size</th>\n",
       "      <th>tumor_AFP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.214341</td>\n",
       "      <td>-0.916045</td>\n",
       "      <td>-0.205619</td>\n",
       "      <td>0.106830</td>\n",
       "      <td>-0.112759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>-0.260471</td>\n",
       "      <td>1.666576</td>\n",
       "      <td>-0.134375</td>\n",
       "      <td>-0.753887</td>\n",
       "      <td>-0.097976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120107</td>\n",
       "      <td>-0.601906</td>\n",
       "      <td>-0.137012</td>\n",
       "      <td>-1.614604</td>\n",
       "      <td>-0.093049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>-0.179743</td>\n",
       "      <td>0.350135</td>\n",
       "      <td>-0.121279</td>\n",
       "      <td>-0.753887</td>\n",
       "      <td>-0.009282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.164143</td>\n",
       "      <td>-0.820867</td>\n",
       "      <td>-0.184461</td>\n",
       "      <td>0.106830</td>\n",
       "      <td>-0.087308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   jaundice    N    M  Gazzaniga_T  MSKCC  Blumgart_T  Bismuth_C  \\\n",
       "0         1  0.0  0.0          1.0    1.0         1.0        3.0   \n",
       "1         1  0.0  0.0          1.0    1.0         1.0        2.0   \n",
       "2         1  0.0  0.0          1.0    1.0         1.0        3.0   \n",
       "3         1  0.0  0.0          1.0    1.0         1.0        3.0   \n",
       "4         1  1.0  0.0          1.0    1.0         1.0        2.0   \n",
       "\n",
       "   cardio_disease  nbdd  HCVAb  ...  biliary_disease     HBsAg    T  \\\n",
       "0               0     0    0.0  ...              0.0  0.000000  2.0   \n",
       "1               0     0    0.0  ...              0.0  0.053333  2.0   \n",
       "2               0     1    0.0  ...              0.0  0.000000  2.0   \n",
       "3               0     0    0.0  ...              0.0  0.000000  2.0   \n",
       "4               0     1    0.0  ...              0.0  0.000000  4.0   \n",
       "\n",
       "   surgery_result  emaciation  tumor_CEA  tumor_CA19-9  tumor_CA125  \\\n",
       "0             0.0    0.000000  -0.214341     -0.916045    -0.205619   \n",
       "1             0.0    0.226667  -0.260471      1.666576    -0.134375   \n",
       "2             0.0    0.000000   0.120107     -0.601906    -0.137012   \n",
       "3             0.0    0.226667  -0.179743      0.350135    -0.121279   \n",
       "4             1.0    0.000000  -0.164143     -0.820867    -0.184461   \n",
       "\n",
       "   tumor_size  tumor_AFP  \n",
       "0    0.106830  -0.112759  \n",
       "1   -0.753887  -0.097976  \n",
       "2   -1.614604  -0.093049  \n",
       "3   -0.753887  -0.009282  \n",
       "4    0.106830  -0.087308  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran_x_sm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_x_sm.to_excel(project_path+'/data/tran_x_sm.xlsx')\n",
    "tran_y_sm.to_excel(project_path+'/data/tran_y_sm.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多分类模型：5-fold on training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training dataset:5-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:05:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "0:\tlearn: 1.3585635\ttotal: 4.25ms\tremaining: 1.7s\n",
      "1:\tlearn: 1.3222115\ttotal: 8.63ms\tremaining: 1.72s\n",
      "2:\tlearn: 1.2946708\ttotal: 13.4ms\tremaining: 1.78s\n",
      "3:\tlearn: 1.2637432\ttotal: 18.6ms\tremaining: 1.84s\n",
      "4:\tlearn: 1.2377976\ttotal: 22ms\tremaining: 1.74s\n",
      "5:\tlearn: 1.2125150\ttotal: 25.8ms\tremaining: 1.7s\n",
      "6:\tlearn: 1.1916469\ttotal: 29.6ms\tremaining: 1.66s\n",
      "7:\tlearn: 1.1685586\ttotal: 33.1ms\tremaining: 1.62s\n",
      "8:\tlearn: 1.1440411\ttotal: 36.5ms\tremaining: 1.59s\n",
      "9:\tlearn: 1.1253075\ttotal: 40.1ms\tremaining: 1.56s\n",
      "10:\tlearn: 1.1102433\ttotal: 44.2ms\tremaining: 1.56s\n",
      "11:\tlearn: 1.0903263\ttotal: 47.9ms\tremaining: 1.55s\n",
      "12:\tlearn: 1.0766675\ttotal: 51.9ms\tremaining: 1.55s\n",
      "13:\tlearn: 1.0588945\ttotal: 55.4ms\tremaining: 1.53s\n",
      "14:\tlearn: 1.0460525\ttotal: 59.9ms\tremaining: 1.54s\n",
      "15:\tlearn: 1.0347713\ttotal: 64ms\tremaining: 1.53s\n",
      "16:\tlearn: 1.0247090\ttotal: 67.4ms\tremaining: 1.52s\n",
      "17:\tlearn: 1.0050010\ttotal: 70.6ms\tremaining: 1.5s\n",
      "18:\tlearn: 0.9878669\ttotal: 74.8ms\tremaining: 1.5s\n",
      "19:\tlearn: 0.9718334\ttotal: 78.4ms\tremaining: 1.49s\n",
      "20:\tlearn: 0.9573270\ttotal: 82.1ms\tremaining: 1.48s\n",
      "21:\tlearn: 0.9427792\ttotal: 85.4ms\tremaining: 1.47s\n",
      "22:\tlearn: 0.9313426\ttotal: 88.7ms\tremaining: 1.45s\n",
      "23:\tlearn: 0.9235666\ttotal: 92.7ms\tremaining: 1.45s\n",
      "24:\tlearn: 0.9141944\ttotal: 96.4ms\tremaining: 1.45s\n",
      "25:\tlearn: 0.8988514\ttotal: 101ms\tremaining: 1.45s\n",
      "26:\tlearn: 0.8858620\ttotal: 106ms\tremaining: 1.46s\n",
      "27:\tlearn: 0.8724405\ttotal: 109ms\tremaining: 1.45s\n",
      "28:\tlearn: 0.8628182\ttotal: 112ms\tremaining: 1.44s\n",
      "29:\tlearn: 0.8517000\ttotal: 116ms\tremaining: 1.42s\n",
      "30:\tlearn: 0.8399368\ttotal: 118ms\tremaining: 1.41s\n",
      "31:\tlearn: 0.8302449\ttotal: 123ms\tremaining: 1.41s\n",
      "32:\tlearn: 0.8226334\ttotal: 126ms\tremaining: 1.4s\n",
      "33:\tlearn: 0.8085872\ttotal: 129ms\tremaining: 1.38s\n",
      "34:\tlearn: 0.7978812\ttotal: 131ms\tremaining: 1.37s\n",
      "35:\tlearn: 0.7923241\ttotal: 134ms\tremaining: 1.36s\n",
      "36:\tlearn: 0.7812010\ttotal: 138ms\tremaining: 1.35s\n",
      "37:\tlearn: 0.7719555\ttotal: 141ms\tremaining: 1.34s\n",
      "38:\tlearn: 0.7635705\ttotal: 144ms\tremaining: 1.33s\n",
      "39:\tlearn: 0.7543209\ttotal: 147ms\tremaining: 1.32s\n",
      "40:\tlearn: 0.7463626\ttotal: 150ms\tremaining: 1.31s\n",
      "41:\tlearn: 0.7380526\ttotal: 154ms\tremaining: 1.32s\n",
      "42:\tlearn: 0.7310477\ttotal: 158ms\tremaining: 1.31s\n",
      "43:\tlearn: 0.7256618\ttotal: 161ms\tremaining: 1.3s\n",
      "44:\tlearn: 0.7188157\ttotal: 164ms\tremaining: 1.29s\n",
      "45:\tlearn: 0.7128772\ttotal: 168ms\tremaining: 1.29s\n",
      "46:\tlearn: 0.7003708\ttotal: 172ms\tremaining: 1.29s\n",
      "47:\tlearn: 0.6927073\ttotal: 178ms\tremaining: 1.3s\n",
      "48:\tlearn: 0.6862462\ttotal: 182ms\tremaining: 1.3s\n",
      "49:\tlearn: 0.6778393\ttotal: 186ms\tremaining: 1.3s\n",
      "50:\tlearn: 0.6733556\ttotal: 189ms\tremaining: 1.3s\n",
      "51:\tlearn: 0.6636818\ttotal: 193ms\tremaining: 1.29s\n",
      "52:\tlearn: 0.6578113\ttotal: 196ms\tremaining: 1.28s\n",
      "53:\tlearn: 0.6491454\ttotal: 200ms\tremaining: 1.28s\n",
      "54:\tlearn: 0.6454153\ttotal: 204ms\tremaining: 1.28s\n",
      "55:\tlearn: 0.6391052\ttotal: 207ms\tremaining: 1.27s\n",
      "56:\tlearn: 0.6332845\ttotal: 210ms\tremaining: 1.26s\n",
      "57:\tlearn: 0.6284858\ttotal: 214ms\tremaining: 1.26s\n",
      "58:\tlearn: 0.6228927\ttotal: 218ms\tremaining: 1.26s\n",
      "59:\tlearn: 0.6144854\ttotal: 221ms\tremaining: 1.25s\n",
      "60:\tlearn: 0.6090485\ttotal: 224ms\tremaining: 1.25s\n",
      "61:\tlearn: 0.6016056\ttotal: 227ms\tremaining: 1.24s\n",
      "62:\tlearn: 0.5966450\ttotal: 231ms\tremaining: 1.24s\n",
      "63:\tlearn: 0.5910107\ttotal: 235ms\tremaining: 1.23s\n",
      "64:\tlearn: 0.5857360\ttotal: 238ms\tremaining: 1.23s\n",
      "65:\tlearn: 0.5806198\ttotal: 242ms\tremaining: 1.22s\n",
      "66:\tlearn: 0.5786331\ttotal: 244ms\tremaining: 1.21s\n",
      "67:\tlearn: 0.5718943\ttotal: 248ms\tremaining: 1.21s\n",
      "68:\tlearn: 0.5648792\ttotal: 253ms\tremaining: 1.21s\n",
      "69:\tlearn: 0.5601948\ttotal: 257ms\tremaining: 1.21s\n",
      "70:\tlearn: 0.5567288\ttotal: 260ms\tremaining: 1.2s\n",
      "71:\tlearn: 0.5513687\ttotal: 264ms\tremaining: 1.2s\n",
      "72:\tlearn: 0.5450071\ttotal: 268ms\tremaining: 1.2s\n",
      "73:\tlearn: 0.5403405\ttotal: 271ms\tremaining: 1.19s\n",
      "74:\tlearn: 0.5365101\ttotal: 274ms\tremaining: 1.19s\n",
      "75:\tlearn: 0.5311644\ttotal: 277ms\tremaining: 1.18s\n",
      "76:\tlearn: 0.5250758\ttotal: 281ms\tremaining: 1.18s\n",
      "77:\tlearn: 0.5193460\ttotal: 284ms\tremaining: 1.17s\n",
      "78:\tlearn: 0.5143844\ttotal: 287ms\tremaining: 1.17s\n",
      "79:\tlearn: 0.5077515\ttotal: 290ms\tremaining: 1.16s\n",
      "80:\tlearn: 0.5019950\ttotal: 293ms\tremaining: 1.15s\n",
      "81:\tlearn: 0.4981262\ttotal: 297ms\tremaining: 1.15s\n",
      "82:\tlearn: 0.4943379\ttotal: 300ms\tremaining: 1.14s\n",
      "83:\tlearn: 0.4909437\ttotal: 302ms\tremaining: 1.14s\n",
      "84:\tlearn: 0.4850009\ttotal: 305ms\tremaining: 1.13s\n",
      "85:\tlearn: 0.4784118\ttotal: 308ms\tremaining: 1.13s\n",
      "86:\tlearn: 0.4753213\ttotal: 312ms\tremaining: 1.12s\n",
      "87:\tlearn: 0.4700640\ttotal: 316ms\tremaining: 1.12s\n",
      "88:\tlearn: 0.4646624\ttotal: 319ms\tremaining: 1.11s\n",
      "89:\tlearn: 0.4613095\ttotal: 321ms\tremaining: 1.11s\n",
      "90:\tlearn: 0.4547802\ttotal: 324ms\tremaining: 1.1s\n",
      "91:\tlearn: 0.4499137\ttotal: 328ms\tremaining: 1.1s\n",
      "92:\tlearn: 0.4466927\ttotal: 331ms\tremaining: 1.09s\n",
      "93:\tlearn: 0.4416930\ttotal: 334ms\tremaining: 1.08s\n",
      "94:\tlearn: 0.4363422\ttotal: 337ms\tremaining: 1.08s\n",
      "95:\tlearn: 0.4314132\ttotal: 340ms\tremaining: 1.07s\n",
      "96:\tlearn: 0.4290986\ttotal: 344ms\tremaining: 1.07s\n",
      "97:\tlearn: 0.4243063\ttotal: 348ms\tremaining: 1.07s\n",
      "98:\tlearn: 0.4190051\ttotal: 351ms\tremaining: 1.06s\n",
      "99:\tlearn: 0.4140608\ttotal: 354ms\tremaining: 1.06s\n",
      "100:\tlearn: 0.4094673\ttotal: 359ms\tremaining: 1.06s\n",
      "101:\tlearn: 0.4061617\ttotal: 364ms\tremaining: 1.06s\n",
      "102:\tlearn: 0.4027668\ttotal: 367ms\tremaining: 1.06s\n",
      "103:\tlearn: 0.3985924\ttotal: 371ms\tremaining: 1.05s\n",
      "104:\tlearn: 0.3951378\ttotal: 375ms\tremaining: 1.05s\n",
      "105:\tlearn: 0.3914182\ttotal: 378ms\tremaining: 1.05s\n",
      "106:\tlearn: 0.3877750\ttotal: 381ms\tremaining: 1.04s\n",
      "107:\tlearn: 0.3859559\ttotal: 385ms\tremaining: 1.04s\n",
      "108:\tlearn: 0.3822581\ttotal: 388ms\tremaining: 1.03s\n",
      "109:\tlearn: 0.3784826\ttotal: 392ms\tremaining: 1.03s\n",
      "110:\tlearn: 0.3744138\ttotal: 395ms\tremaining: 1.03s\n",
      "111:\tlearn: 0.3699154\ttotal: 399ms\tremaining: 1.02s\n",
      "112:\tlearn: 0.3668122\ttotal: 402ms\tremaining: 1.02s\n",
      "113:\tlearn: 0.3627896\ttotal: 405ms\tremaining: 1.02s\n",
      "114:\tlearn: 0.3599964\ttotal: 409ms\tremaining: 1.01s\n",
      "115:\tlearn: 0.3560577\ttotal: 412ms\tremaining: 1.01s\n",
      "116:\tlearn: 0.3524100\ttotal: 417ms\tremaining: 1.01s\n",
      "117:\tlearn: 0.3492336\ttotal: 421ms\tremaining: 1s\n",
      "118:\tlearn: 0.3463627\ttotal: 425ms\tremaining: 1s\n",
      "119:\tlearn: 0.3436446\ttotal: 430ms\tremaining: 1s\n",
      "120:\tlearn: 0.3416259\ttotal: 433ms\tremaining: 999ms\n",
      "121:\tlearn: 0.3394877\ttotal: 437ms\tremaining: 996ms\n",
      "122:\tlearn: 0.3361388\ttotal: 442ms\tremaining: 994ms\n",
      "123:\tlearn: 0.3342933\ttotal: 445ms\tremaining: 990ms\n",
      "124:\tlearn: 0.3329963\ttotal: 448ms\tremaining: 985ms\n",
      "125:\tlearn: 0.3288297\ttotal: 451ms\tremaining: 980ms\n",
      "126:\tlearn: 0.3263712\ttotal: 454ms\tremaining: 977ms\n",
      "127:\tlearn: 0.3237115\ttotal: 458ms\tremaining: 973ms\n",
      "128:\tlearn: 0.3214012\ttotal: 461ms\tremaining: 968ms\n",
      "129:\tlearn: 0.3200647\ttotal: 464ms\tremaining: 963ms\n",
      "130:\tlearn: 0.3176803\ttotal: 467ms\tremaining: 958ms\n",
      "131:\tlearn: 0.3150567\ttotal: 471ms\tremaining: 957ms\n",
      "132:\tlearn: 0.3118205\ttotal: 474ms\tremaining: 952ms\n",
      "133:\tlearn: 0.3095638\ttotal: 477ms\tremaining: 948ms\n",
      "134:\tlearn: 0.3063032\ttotal: 480ms\tremaining: 943ms\n",
      "135:\tlearn: 0.3048314\ttotal: 483ms\tremaining: 938ms\n",
      "136:\tlearn: 0.3020693\ttotal: 488ms\tremaining: 936ms\n",
      "137:\tlearn: 0.3003822\ttotal: 491ms\tremaining: 932ms\n",
      "138:\tlearn: 0.2968265\ttotal: 494ms\tremaining: 927ms\n",
      "139:\tlearn: 0.2946701\ttotal: 497ms\tremaining: 923ms\n",
      "140:\tlearn: 0.2924544\ttotal: 501ms\tremaining: 921ms\n",
      "141:\tlearn: 0.2896256\ttotal: 505ms\tremaining: 917ms\n",
      "142:\tlearn: 0.2870232\ttotal: 508ms\tremaining: 912ms\n",
      "143:\tlearn: 0.2846489\ttotal: 511ms\tremaining: 909ms\n",
      "144:\tlearn: 0.2817786\ttotal: 516ms\tremaining: 907ms\n",
      "145:\tlearn: 0.2791897\ttotal: 519ms\tremaining: 904ms\n",
      "146:\tlearn: 0.2781957\ttotal: 522ms\tremaining: 899ms\n",
      "147:\tlearn: 0.2765734\ttotal: 525ms\tremaining: 894ms\n",
      "148:\tlearn: 0.2737951\ttotal: 528ms\tremaining: 890ms\n",
      "149:\tlearn: 0.2703731\ttotal: 533ms\tremaining: 888ms\n",
      "150:\tlearn: 0.2678368\ttotal: 536ms\tremaining: 884ms\n",
      "151:\tlearn: 0.2646236\ttotal: 540ms\tremaining: 881ms\n",
      "152:\tlearn: 0.2630986\ttotal: 543ms\tremaining: 877ms\n",
      "153:\tlearn: 0.2603030\ttotal: 546ms\tremaining: 873ms\n",
      "154:\tlearn: 0.2584629\ttotal: 550ms\tremaining: 870ms\n",
      "155:\tlearn: 0.2572505\ttotal: 553ms\tremaining: 865ms\n",
      "156:\tlearn: 0.2549067\ttotal: 557ms\tremaining: 862ms\n",
      "157:\tlearn: 0.2531254\ttotal: 560ms\tremaining: 858ms\n",
      "158:\tlearn: 0.2516887\ttotal: 565ms\tremaining: 856ms\n",
      "159:\tlearn: 0.2503663\ttotal: 568ms\tremaining: 853ms\n",
      "160:\tlearn: 0.2480305\ttotal: 571ms\tremaining: 848ms\n",
      "161:\tlearn: 0.2464254\ttotal: 575ms\tremaining: 844ms\n",
      "162:\tlearn: 0.2438567\ttotal: 580ms\tremaining: 843ms\n",
      "163:\tlearn: 0.2429297\ttotal: 584ms\tremaining: 840ms\n",
      "164:\tlearn: 0.2408376\ttotal: 587ms\tremaining: 836ms\n",
      "165:\tlearn: 0.2387457\ttotal: 604ms\tremaining: 852ms\n",
      "166:\tlearn: 0.2369046\ttotal: 607ms\tremaining: 847ms\n",
      "167:\tlearn: 0.2354327\ttotal: 610ms\tremaining: 843ms\n",
      "168:\tlearn: 0.2341016\ttotal: 614ms\tremaining: 840ms\n",
      "169:\tlearn: 0.2324210\ttotal: 617ms\tremaining: 835ms\n",
      "170:\tlearn: 0.2310297\ttotal: 620ms\tremaining: 831ms\n",
      "171:\tlearn: 0.2299520\ttotal: 623ms\tremaining: 826ms\n",
      "172:\tlearn: 0.2288226\ttotal: 627ms\tremaining: 822ms\n",
      "173:\tlearn: 0.2274710\ttotal: 631ms\tremaining: 819ms\n",
      "174:\tlearn: 0.2255548\ttotal: 634ms\tremaining: 815ms\n",
      "175:\tlearn: 0.2239059\ttotal: 637ms\tremaining: 810ms\n",
      "176:\tlearn: 0.2232354\ttotal: 640ms\tremaining: 806ms\n",
      "177:\tlearn: 0.2214696\ttotal: 646ms\tremaining: 806ms\n",
      "178:\tlearn: 0.2197949\ttotal: 649ms\tremaining: 801ms\n",
      "179:\tlearn: 0.2183789\ttotal: 652ms\tremaining: 797ms\n",
      "180:\tlearn: 0.2165995\ttotal: 655ms\tremaining: 792ms\n",
      "181:\tlearn: 0.2151057\ttotal: 658ms\tremaining: 788ms\n",
      "182:\tlearn: 0.2134570\ttotal: 661ms\tremaining: 784ms\n",
      "183:\tlearn: 0.2115998\ttotal: 665ms\tremaining: 780ms\n",
      "184:\tlearn: 0.2107146\ttotal: 668ms\tremaining: 776ms\n",
      "185:\tlearn: 0.2093102\ttotal: 670ms\tremaining: 771ms\n",
      "186:\tlearn: 0.2076020\ttotal: 673ms\tremaining: 767ms\n",
      "187:\tlearn: 0.2060898\ttotal: 677ms\tremaining: 763ms\n",
      "188:\tlearn: 0.2044918\ttotal: 680ms\tremaining: 759ms\n",
      "189:\tlearn: 0.2033670\ttotal: 683ms\tremaining: 755ms\n",
      "190:\tlearn: 0.2024727\ttotal: 686ms\tremaining: 751ms\n",
      "191:\tlearn: 0.2019487\ttotal: 689ms\tremaining: 746ms\n",
      "192:\tlearn: 0.2006548\ttotal: 692ms\tremaining: 743ms\n",
      "193:\tlearn: 0.1990756\ttotal: 695ms\tremaining: 738ms\n",
      "194:\tlearn: 0.1981557\ttotal: 698ms\tremaining: 734ms\n",
      "195:\tlearn: 0.1966988\ttotal: 701ms\tremaining: 730ms\n",
      "196:\tlearn: 0.1949942\ttotal: 705ms\tremaining: 726ms\n",
      "197:\tlearn: 0.1936569\ttotal: 709ms\tremaining: 723ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198:\tlearn: 0.1925331\ttotal: 713ms\tremaining: 720ms\n",
      "199:\tlearn: 0.1916148\ttotal: 717ms\tremaining: 717ms\n",
      "200:\tlearn: 0.1902551\ttotal: 721ms\tremaining: 714ms\n",
      "201:\tlearn: 0.1887869\ttotal: 725ms\tremaining: 710ms\n",
      "202:\tlearn: 0.1880565\ttotal: 728ms\tremaining: 706ms\n",
      "203:\tlearn: 0.1868042\ttotal: 731ms\tremaining: 702ms\n",
      "204:\tlearn: 0.1858565\ttotal: 734ms\tremaining: 698ms\n",
      "205:\tlearn: 0.1843918\ttotal: 738ms\tremaining: 695ms\n",
      "206:\tlearn: 0.1834683\ttotal: 741ms\tremaining: 691ms\n",
      "207:\tlearn: 0.1824834\ttotal: 744ms\tremaining: 687ms\n",
      "208:\tlearn: 0.1814836\ttotal: 748ms\tremaining: 683ms\n",
      "209:\tlearn: 0.1802268\ttotal: 752ms\tremaining: 680ms\n",
      "210:\tlearn: 0.1793747\ttotal: 756ms\tremaining: 677ms\n",
      "211:\tlearn: 0.1784312\ttotal: 759ms\tremaining: 673ms\n",
      "212:\tlearn: 0.1775948\ttotal: 762ms\tremaining: 669ms\n",
      "213:\tlearn: 0.1765903\ttotal: 765ms\tremaining: 665ms\n",
      "214:\tlearn: 0.1752404\ttotal: 768ms\tremaining: 661ms\n",
      "215:\tlearn: 0.1739858\ttotal: 772ms\tremaining: 657ms\n",
      "216:\tlearn: 0.1729467\ttotal: 775ms\tremaining: 654ms\n",
      "217:\tlearn: 0.1724700\ttotal: 779ms\tremaining: 650ms\n",
      "218:\tlearn: 0.1716157\ttotal: 785ms\tremaining: 649ms\n",
      "219:\tlearn: 0.1707118\ttotal: 788ms\tremaining: 645ms\n",
      "220:\tlearn: 0.1695649\ttotal: 791ms\tremaining: 641ms\n",
      "221:\tlearn: 0.1680090\ttotal: 794ms\tremaining: 637ms\n",
      "222:\tlearn: 0.1671900\ttotal: 797ms\tremaining: 633ms\n",
      "223:\tlearn: 0.1665827\ttotal: 800ms\tremaining: 629ms\n",
      "224:\tlearn: 0.1656319\ttotal: 804ms\tremaining: 625ms\n",
      "225:\tlearn: 0.1642950\ttotal: 807ms\tremaining: 621ms\n",
      "226:\tlearn: 0.1637233\ttotal: 810ms\tremaining: 617ms\n",
      "227:\tlearn: 0.1630536\ttotal: 813ms\tremaining: 613ms\n",
      "228:\tlearn: 0.1618097\ttotal: 816ms\tremaining: 609ms\n",
      "229:\tlearn: 0.1610871\ttotal: 819ms\tremaining: 605ms\n",
      "230:\tlearn: 0.1600855\ttotal: 822ms\tremaining: 601ms\n",
      "231:\tlearn: 0.1588111\ttotal: 825ms\tremaining: 597ms\n",
      "232:\tlearn: 0.1579197\ttotal: 828ms\tremaining: 593ms\n",
      "233:\tlearn: 0.1574425\ttotal: 831ms\tremaining: 589ms\n",
      "234:\tlearn: 0.1560482\ttotal: 834ms\tremaining: 586ms\n",
      "235:\tlearn: 0.1551126\ttotal: 838ms\tremaining: 582ms\n",
      "236:\tlearn: 0.1542269\ttotal: 841ms\tremaining: 578ms\n",
      "237:\tlearn: 0.1536769\ttotal: 844ms\tremaining: 574ms\n",
      "238:\tlearn: 0.1528664\ttotal: 849ms\tremaining: 572ms\n",
      "239:\tlearn: 0.1518448\ttotal: 852ms\tremaining: 568ms\n",
      "240:\tlearn: 0.1508993\ttotal: 856ms\tremaining: 565ms\n",
      "241:\tlearn: 0.1499589\ttotal: 859ms\tremaining: 561ms\n",
      "242:\tlearn: 0.1491250\ttotal: 862ms\tremaining: 557ms\n",
      "243:\tlearn: 0.1483756\ttotal: 865ms\tremaining: 553ms\n",
      "244:\tlearn: 0.1473593\ttotal: 868ms\tremaining: 549ms\n",
      "245:\tlearn: 0.1463202\ttotal: 871ms\tremaining: 545ms\n",
      "246:\tlearn: 0.1455057\ttotal: 874ms\tremaining: 541ms\n",
      "247:\tlearn: 0.1449104\ttotal: 877ms\tremaining: 538ms\n",
      "248:\tlearn: 0.1441065\ttotal: 880ms\tremaining: 534ms\n",
      "249:\tlearn: 0.1436669\ttotal: 883ms\tremaining: 530ms\n",
      "250:\tlearn: 0.1426789\ttotal: 886ms\tremaining: 526ms\n",
      "251:\tlearn: 0.1420160\ttotal: 890ms\tremaining: 523ms\n",
      "252:\tlearn: 0.1412576\ttotal: 893ms\tremaining: 519ms\n",
      "253:\tlearn: 0.1406771\ttotal: 896ms\tremaining: 515ms\n",
      "254:\tlearn: 0.1402243\ttotal: 901ms\tremaining: 512ms\n",
      "255:\tlearn: 0.1397365\ttotal: 905ms\tremaining: 509ms\n",
      "256:\tlearn: 0.1390814\ttotal: 908ms\tremaining: 505ms\n",
      "257:\tlearn: 0.1380126\ttotal: 914ms\tremaining: 503ms\n",
      "258:\tlearn: 0.1373000\ttotal: 917ms\tremaining: 499ms\n",
      "259:\tlearn: 0.1365780\ttotal: 920ms\tremaining: 495ms\n",
      "260:\tlearn: 0.1357077\ttotal: 924ms\tremaining: 492ms\n",
      "261:\tlearn: 0.1348338\ttotal: 927ms\tremaining: 488ms\n",
      "262:\tlearn: 0.1338657\ttotal: 931ms\tremaining: 485ms\n",
      "263:\tlearn: 0.1334638\ttotal: 934ms\tremaining: 481ms\n",
      "264:\tlearn: 0.1329503\ttotal: 937ms\tremaining: 477ms\n",
      "265:\tlearn: 0.1320954\ttotal: 940ms\tremaining: 473ms\n",
      "266:\tlearn: 0.1313582\ttotal: 943ms\tremaining: 470ms\n",
      "267:\tlearn: 0.1306858\ttotal: 946ms\tremaining: 466ms\n",
      "268:\tlearn: 0.1299358\ttotal: 949ms\tremaining: 462ms\n",
      "269:\tlearn: 0.1294990\ttotal: 952ms\tremaining: 458ms\n",
      "270:\tlearn: 0.1287865\ttotal: 956ms\tremaining: 455ms\n",
      "271:\tlearn: 0.1280470\ttotal: 959ms\tremaining: 451ms\n",
      "272:\tlearn: 0.1274418\ttotal: 964ms\tremaining: 448ms\n",
      "273:\tlearn: 0.1268051\ttotal: 969ms\tremaining: 445ms\n",
      "274:\tlearn: 0.1261376\ttotal: 972ms\tremaining: 442ms\n",
      "275:\tlearn: 0.1256925\ttotal: 975ms\tremaining: 438ms\n",
      "276:\tlearn: 0.1251290\ttotal: 979ms\tremaining: 435ms\n",
      "277:\tlearn: 0.1245306\ttotal: 982ms\tremaining: 431ms\n",
      "278:\tlearn: 0.1240861\ttotal: 984ms\tremaining: 427ms\n",
      "279:\tlearn: 0.1234031\ttotal: 987ms\tremaining: 423ms\n",
      "280:\tlearn: 0.1226995\ttotal: 990ms\tremaining: 419ms\n",
      "281:\tlearn: 0.1221993\ttotal: 994ms\tremaining: 416ms\n",
      "282:\tlearn: 0.1214075\ttotal: 997ms\tremaining: 412ms\n",
      "283:\tlearn: 0.1211140\ttotal: 1s\tremaining: 409ms\n",
      "284:\tlearn: 0.1203872\ttotal: 1s\tremaining: 405ms\n",
      "285:\tlearn: 0.1199685\ttotal: 1.01s\tremaining: 402ms\n",
      "286:\tlearn: 0.1195725\ttotal: 1.01s\tremaining: 398ms\n",
      "287:\tlearn: 0.1190871\ttotal: 1.01s\tremaining: 394ms\n",
      "288:\tlearn: 0.1183182\ttotal: 1.02s\tremaining: 391ms\n",
      "289:\tlearn: 0.1178061\ttotal: 1.02s\tremaining: 388ms\n",
      "290:\tlearn: 0.1170393\ttotal: 1.03s\tremaining: 385ms\n",
      "291:\tlearn: 0.1167469\ttotal: 1.03s\tremaining: 381ms\n",
      "292:\tlearn: 0.1161328\ttotal: 1.03s\tremaining: 377ms\n",
      "293:\tlearn: 0.1154126\ttotal: 1.03s\tremaining: 373ms\n",
      "294:\tlearn: 0.1147599\ttotal: 1.04s\tremaining: 370ms\n",
      "295:\tlearn: 0.1143708\ttotal: 1.04s\tremaining: 366ms\n",
      "296:\tlearn: 0.1138178\ttotal: 1.04s\tremaining: 362ms\n",
      "297:\tlearn: 0.1133624\ttotal: 1.05s\tremaining: 359ms\n",
      "298:\tlearn: 0.1128248\ttotal: 1.05s\tremaining: 355ms\n",
      "299:\tlearn: 0.1124108\ttotal: 1.05s\tremaining: 352ms\n",
      "300:\tlearn: 0.1119834\ttotal: 1.06s\tremaining: 348ms\n",
      "301:\tlearn: 0.1115587\ttotal: 1.06s\tremaining: 345ms\n",
      "302:\tlearn: 0.1109695\ttotal: 1.06s\tremaining: 341ms\n",
      "303:\tlearn: 0.1106573\ttotal: 1.07s\tremaining: 337ms\n",
      "304:\tlearn: 0.1101422\ttotal: 1.07s\tremaining: 334ms\n",
      "305:\tlearn: 0.1097194\ttotal: 1.08s\tremaining: 331ms\n",
      "306:\tlearn: 0.1090639\ttotal: 1.08s\tremaining: 327ms\n",
      "307:\tlearn: 0.1084927\ttotal: 1.08s\tremaining: 324ms\n",
      "308:\tlearn: 0.1080352\ttotal: 1.09s\tremaining: 321ms\n",
      "309:\tlearn: 0.1075965\ttotal: 1.09s\tremaining: 317ms\n",
      "310:\tlearn: 0.1069485\ttotal: 1.1s\tremaining: 314ms\n",
      "311:\tlearn: 0.1064418\ttotal: 1.1s\tremaining: 310ms\n",
      "312:\tlearn: 0.1059758\ttotal: 1.1s\tremaining: 307ms\n",
      "313:\tlearn: 0.1055033\ttotal: 1.11s\tremaining: 303ms\n",
      "314:\tlearn: 0.1049830\ttotal: 1.11s\tremaining: 300ms\n",
      "315:\tlearn: 0.1045210\ttotal: 1.11s\tremaining: 296ms\n",
      "316:\tlearn: 0.1038864\ttotal: 1.12s\tremaining: 292ms\n",
      "317:\tlearn: 0.1034787\ttotal: 1.12s\tremaining: 289ms\n",
      "318:\tlearn: 0.1033812\ttotal: 1.12s\tremaining: 285ms\n",
      "319:\tlearn: 0.1029712\ttotal: 1.13s\tremaining: 281ms\n",
      "320:\tlearn: 0.1026556\ttotal: 1.13s\tremaining: 278ms\n",
      "321:\tlearn: 0.1020977\ttotal: 1.13s\tremaining: 274ms\n",
      "322:\tlearn: 0.1016574\ttotal: 1.14s\tremaining: 271ms\n",
      "323:\tlearn: 0.1011300\ttotal: 1.14s\tremaining: 267ms\n",
      "324:\tlearn: 0.1006713\ttotal: 1.14s\tremaining: 264ms\n",
      "325:\tlearn: 0.1004883\ttotal: 1.15s\tremaining: 260ms\n",
      "326:\tlearn: 0.1000003\ttotal: 1.15s\tremaining: 257ms\n",
      "327:\tlearn: 0.0993651\ttotal: 1.16s\tremaining: 254ms\n",
      "328:\tlearn: 0.0990082\ttotal: 1.16s\tremaining: 250ms\n",
      "329:\tlearn: 0.0985962\ttotal: 1.16s\tremaining: 247ms\n",
      "330:\tlearn: 0.0983478\ttotal: 1.17s\tremaining: 243ms\n",
      "331:\tlearn: 0.0980686\ttotal: 1.17s\tremaining: 240ms\n",
      "332:\tlearn: 0.0977829\ttotal: 1.17s\tremaining: 236ms\n",
      "333:\tlearn: 0.0973766\ttotal: 1.18s\tremaining: 233ms\n",
      "334:\tlearn: 0.0968720\ttotal: 1.18s\tremaining: 229ms\n",
      "335:\tlearn: 0.0964897\ttotal: 1.18s\tremaining: 226ms\n",
      "336:\tlearn: 0.0962311\ttotal: 1.19s\tremaining: 222ms\n",
      "337:\tlearn: 0.0958972\ttotal: 1.19s\tremaining: 218ms\n",
      "338:\tlearn: 0.0955747\ttotal: 1.19s\tremaining: 215ms\n",
      "339:\tlearn: 0.0951300\ttotal: 1.2s\tremaining: 211ms\n",
      "340:\tlearn: 0.0945920\ttotal: 1.2s\tremaining: 208ms\n",
      "341:\tlearn: 0.0942375\ttotal: 1.21s\tremaining: 205ms\n",
      "342:\tlearn: 0.0939203\ttotal: 1.21s\tremaining: 201ms\n",
      "343:\tlearn: 0.0935991\ttotal: 1.21s\tremaining: 197ms\n",
      "344:\tlearn: 0.0931666\ttotal: 1.22s\tremaining: 194ms\n",
      "345:\tlearn: 0.0928612\ttotal: 1.22s\tremaining: 190ms\n",
      "346:\tlearn: 0.0923706\ttotal: 1.22s\tremaining: 187ms\n",
      "347:\tlearn: 0.0918691\ttotal: 1.23s\tremaining: 183ms\n",
      "348:\tlearn: 0.0914252\ttotal: 1.23s\tremaining: 180ms\n",
      "349:\tlearn: 0.0911372\ttotal: 1.23s\tremaining: 176ms\n",
      "350:\tlearn: 0.0906702\ttotal: 1.24s\tremaining: 172ms\n",
      "351:\tlearn: 0.0902104\ttotal: 1.24s\tremaining: 169ms\n",
      "352:\tlearn: 0.0897732\ttotal: 1.24s\tremaining: 165ms\n",
      "353:\tlearn: 0.0894446\ttotal: 1.25s\tremaining: 162ms\n",
      "354:\tlearn: 0.0893814\ttotal: 1.25s\tremaining: 158ms\n",
      "355:\tlearn: 0.0890232\ttotal: 1.25s\tremaining: 155ms\n",
      "356:\tlearn: 0.0888150\ttotal: 1.25s\tremaining: 151ms\n",
      "357:\tlearn: 0.0886172\ttotal: 1.26s\tremaining: 148ms\n",
      "358:\tlearn: 0.0882288\ttotal: 1.26s\tremaining: 144ms\n",
      "359:\tlearn: 0.0879304\ttotal: 1.27s\tremaining: 141ms\n",
      "360:\tlearn: 0.0876548\ttotal: 1.27s\tremaining: 138ms\n",
      "361:\tlearn: 0.0873081\ttotal: 1.28s\tremaining: 134ms\n",
      "362:\tlearn: 0.0868476\ttotal: 1.28s\tremaining: 131ms\n",
      "363:\tlearn: 0.0866416\ttotal: 1.28s\tremaining: 127ms\n",
      "364:\tlearn: 0.0864755\ttotal: 1.29s\tremaining: 123ms\n",
      "365:\tlearn: 0.0862698\ttotal: 1.29s\tremaining: 120ms\n",
      "366:\tlearn: 0.0859518\ttotal: 1.29s\tremaining: 116ms\n",
      "367:\tlearn: 0.0856191\ttotal: 1.3s\tremaining: 113ms\n",
      "368:\tlearn: 0.0853980\ttotal: 1.3s\tremaining: 109ms\n",
      "369:\tlearn: 0.0851698\ttotal: 1.3s\tremaining: 106ms\n",
      "370:\tlearn: 0.0848348\ttotal: 1.31s\tremaining: 102ms\n",
      "371:\tlearn: 0.0846011\ttotal: 1.31s\tremaining: 98.7ms\n",
      "372:\tlearn: 0.0843474\ttotal: 1.31s\tremaining: 95.2ms\n",
      "373:\tlearn: 0.0840961\ttotal: 1.32s\tremaining: 91.6ms\n",
      "374:\tlearn: 0.0838863\ttotal: 1.32s\tremaining: 88.1ms\n",
      "375:\tlearn: 0.0836075\ttotal: 1.33s\tremaining: 84.7ms\n",
      "376:\tlearn: 0.0832550\ttotal: 1.33s\tremaining: 81.1ms\n",
      "377:\tlearn: 0.0829569\ttotal: 1.33s\tremaining: 77.6ms\n",
      "378:\tlearn: 0.0826278\ttotal: 1.34s\tremaining: 74.2ms\n",
      "379:\tlearn: 0.0823139\ttotal: 1.34s\tremaining: 70.7ms\n",
      "380:\tlearn: 0.0822388\ttotal: 1.34s\tremaining: 67.1ms\n",
      "381:\tlearn: 0.0818204\ttotal: 1.35s\tremaining: 63.6ms\n",
      "382:\tlearn: 0.0814829\ttotal: 1.35s\tremaining: 60ms\n",
      "383:\tlearn: 0.0810139\ttotal: 1.35s\tremaining: 56.5ms\n",
      "384:\tlearn: 0.0807710\ttotal: 1.36s\tremaining: 53ms\n",
      "385:\tlearn: 0.0804780\ttotal: 1.36s\tremaining: 49.4ms\n",
      "386:\tlearn: 0.0801699\ttotal: 1.37s\tremaining: 45.9ms\n",
      "387:\tlearn: 0.0798515\ttotal: 1.37s\tremaining: 42.4ms\n",
      "388:\tlearn: 0.0794432\ttotal: 1.37s\tremaining: 38.8ms\n",
      "389:\tlearn: 0.0792163\ttotal: 1.38s\tremaining: 35.3ms\n",
      "390:\tlearn: 0.0788957\ttotal: 1.38s\tremaining: 31.8ms\n",
      "391:\tlearn: 0.0785177\ttotal: 1.38s\tremaining: 28.2ms\n",
      "392:\tlearn: 0.0781406\ttotal: 1.39s\tremaining: 24.7ms\n",
      "393:\tlearn: 0.0777525\ttotal: 1.39s\tremaining: 21.2ms\n",
      "394:\tlearn: 0.0775065\ttotal: 1.4s\tremaining: 17.7ms\n",
      "395:\tlearn: 0.0774032\ttotal: 1.4s\tremaining: 14.1ms\n",
      "396:\tlearn: 0.0770440\ttotal: 1.4s\tremaining: 10.6ms\n",
      "397:\tlearn: 0.0767783\ttotal: 1.41s\tremaining: 7.07ms\n",
      "398:\tlearn: 0.0765120\ttotal: 1.41s\tremaining: 3.54ms\n",
      "399:\tlearn: 0.0763156\ttotal: 1.41s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.96432 |  0:00:00s\n",
      "epoch 1  | loss: 1.63505 |  0:00:00s\n",
      "epoch 2  | loss: 1.52703 |  0:00:00s\n",
      "epoch 3  | loss: 1.44452 |  0:00:00s\n",
      "epoch 4  | loss: 1.43137 |  0:00:00s\n",
      "epoch 5  | loss: 1.36454 |  0:00:00s\n",
      "epoch 6  | loss: 1.35845 |  0:00:00s\n",
      "epoch 7  | loss: 1.3507  |  0:00:00s\n",
      "epoch 8  | loss: 1.33069 |  0:00:00s\n",
      "epoch 9  | loss: 1.3209  |  0:00:00s\n",
      "epoch 10 | loss: 1.29466 |  0:00:00s\n",
      "epoch 11 | loss: 1.30288 |  0:00:00s\n",
      "epoch 12 | loss: 1.29966 |  0:00:01s\n",
      "epoch 13 | loss: 1.29823 |  0:00:01s\n",
      "epoch 14 | loss: 1.2539  |  0:00:01s\n",
      "epoch 15 | loss: 1.26351 |  0:00:01s\n",
      "epoch 16 | loss: 1.24045 |  0:00:01s\n",
      "epoch 17 | loss: 1.20963 |  0:00:01s\n",
      "epoch 18 | loss: 1.20077 |  0:00:01s\n",
      "epoch 19 | loss: 1.22846 |  0:00:01s\n",
      "epoch 20 | loss: 1.22331 |  0:00:01s\n",
      "epoch 21 | loss: 1.18842 |  0:00:01s\n",
      "epoch 22 | loss: 1.16835 |  0:00:01s\n",
      "epoch 23 | loss: 1.16372 |  0:00:01s\n",
      "epoch 24 | loss: 1.1724  |  0:00:02s\n",
      "epoch 25 | loss: 1.13046 |  0:00:02s\n",
      "epoch 26 | loss: 1.16573 |  0:00:02s\n",
      "epoch 27 | loss: 1.17446 |  0:00:02s\n",
      "epoch 28 | loss: 1.1543  |  0:00:02s\n",
      "epoch 29 | loss: 1.19474 |  0:00:02s\n",
      "epoch 30 | loss: 1.15297 |  0:00:02s\n",
      "epoch 31 | loss: 1.16033 |  0:00:02s\n",
      "epoch 32 | loss: 1.09626 |  0:00:02s\n",
      "epoch 33 | loss: 1.11837 |  0:00:02s\n",
      "epoch 34 | loss: 1.09929 |  0:00:02s\n",
      "epoch 35 | loss: 1.11524 |  0:00:02s\n",
      "epoch 36 | loss: 1.12141 |  0:00:03s\n",
      "epoch 37 | loss: 1.10825 |  0:00:03s\n",
      "epoch 38 | loss: 1.10778 |  0:00:03s\n",
      "epoch 39 | loss: 1.08529 |  0:00:03s\n",
      "epoch 40 | loss: 1.10319 |  0:00:03s\n",
      "epoch 41 | loss: 1.12346 |  0:00:03s\n",
      "epoch 42 | loss: 1.07385 |  0:00:03s\n",
      "epoch 43 | loss: 1.03134 |  0:00:03s\n",
      "epoch 44 | loss: 1.05674 |  0:00:03s\n",
      "epoch 45 | loss: 1.03429 |  0:00:03s\n",
      "epoch 46 | loss: 1.00379 |  0:00:03s\n",
      "epoch 47 | loss: 1.00033 |  0:00:03s\n",
      "epoch 48 | loss: 1.02434 |  0:00:04s\n",
      "epoch 49 | loss: 0.98686 |  0:00:04s\n",
      "epoch 50 | loss: 1.01453 |  0:00:04s\n",
      "epoch 51 | loss: 1.03669 |  0:00:04s\n",
      "epoch 52 | loss: 1.05729 |  0:00:04s\n",
      "epoch 53 | loss: 1.02523 |  0:00:04s\n",
      "epoch 54 | loss: 1.00849 |  0:00:04s\n",
      "epoch 55 | loss: 1.02829 |  0:00:04s\n",
      "epoch 56 | loss: 0.97653 |  0:00:04s\n",
      "epoch 57 | loss: 0.96479 |  0:00:04s\n",
      "epoch 58 | loss: 0.95542 |  0:00:04s\n",
      "epoch 59 | loss: 1.03042 |  0:00:04s\n",
      "epoch 60 | loss: 0.9963  |  0:00:05s\n",
      "epoch 61 | loss: 0.99288 |  0:00:05s\n",
      "epoch 62 | loss: 1.00278 |  0:00:05s\n",
      "epoch 63 | loss: 0.98221 |  0:00:05s\n",
      "epoch 64 | loss: 0.94339 |  0:00:05s\n",
      "epoch 65 | loss: 0.95818 |  0:00:05s\n",
      "epoch 66 | loss: 1.03399 |  0:00:05s\n",
      "epoch 67 | loss: 0.94087 |  0:00:05s\n",
      "epoch 68 | loss: 0.9596  |  0:00:05s\n",
      "epoch 69 | loss: 0.95194 |  0:00:05s\n",
      "epoch 70 | loss: 0.94288 |  0:00:05s\n",
      "epoch 71 | loss: 0.93231 |  0:00:05s\n",
      "epoch 72 | loss: 0.99214 |  0:00:05s\n",
      "epoch 73 | loss: 0.93288 |  0:00:06s\n",
      "epoch 74 | loss: 0.92887 |  0:00:06s\n",
      "epoch 75 | loss: 0.94107 |  0:00:06s\n",
      "epoch 76 | loss: 0.9119  |  0:00:06s\n",
      "epoch 77 | loss: 0.91537 |  0:00:06s\n",
      "epoch 78 | loss: 0.90775 |  0:00:06s\n",
      "epoch 79 | loss: 0.93162 |  0:00:06s\n",
      "epoch 80 | loss: 0.90976 |  0:00:06s\n",
      "epoch 81 | loss: 0.95241 |  0:00:06s\n",
      "epoch 82 | loss: 0.90215 |  0:00:06s\n",
      "epoch 83 | loss: 0.8823  |  0:00:06s\n",
      "epoch 84 | loss: 0.87474 |  0:00:06s\n",
      "epoch 85 | loss: 0.9443  |  0:00:07s\n",
      "epoch 86 | loss: 0.89935 |  0:00:07s\n",
      "epoch 87 | loss: 0.90484 |  0:00:07s\n",
      "epoch 88 | loss: 0.9382  |  0:00:07s\n",
      "epoch 89 | loss: 0.87469 |  0:00:07s\n",
      "epoch 90 | loss: 0.86061 |  0:00:07s\n",
      "epoch 91 | loss: 0.90205 |  0:00:07s\n",
      "epoch 92 | loss: 0.84195 |  0:00:07s\n",
      "epoch 93 | loss: 0.9284  |  0:00:07s\n",
      "epoch 94 | loss: 0.87893 |  0:00:07s\n",
      "epoch 95 | loss: 0.91064 |  0:00:07s\n",
      "epoch 96 | loss: 0.94311 |  0:00:08s\n",
      "epoch 97 | loss: 0.87572 |  0:00:08s\n",
      "epoch 98 | loss: 0.85536 |  0:00:08s\n",
      "epoch 99 | loss: 0.8385  |  0:00:08s\n",
      "epoch 100| loss: 0.84152 |  0:00:08s\n",
      "epoch 101| loss: 0.84778 |  0:00:08s\n",
      "epoch 102| loss: 0.85431 |  0:00:08s\n",
      "epoch 103| loss: 0.85736 |  0:00:08s\n",
      "epoch 104| loss: 0.81    |  0:00:08s\n",
      "epoch 105| loss: 0.80836 |  0:00:08s\n",
      "epoch 106| loss: 0.84827 |  0:00:08s\n",
      "epoch 107| loss: 0.86858 |  0:00:08s\n",
      "epoch 108| loss: 0.85273 |  0:00:09s\n",
      "epoch 109| loss: 0.87881 |  0:00:09s\n",
      "epoch 110| loss: 0.81878 |  0:00:09s\n",
      "epoch 111| loss: 0.82941 |  0:00:09s\n",
      "epoch 112| loss: 0.84601 |  0:00:09s\n",
      "epoch 113| loss: 0.77723 |  0:00:09s\n",
      "epoch 114| loss: 0.8069  |  0:00:09s\n",
      "epoch 115| loss: 0.81969 |  0:00:09s\n",
      "epoch 116| loss: 0.8375  |  0:00:09s\n",
      "epoch 117| loss: 0.82422 |  0:00:09s\n",
      "epoch 118| loss: 0.80985 |  0:00:09s\n",
      "epoch 119| loss: 0.75566 |  0:00:09s\n",
      "epoch 120| loss: 0.78495 |  0:00:10s\n",
      "epoch 121| loss: 0.75681 |  0:00:10s\n",
      "epoch 122| loss: 0.79212 |  0:00:10s\n",
      "epoch 123| loss: 0.7395  |  0:00:10s\n",
      "epoch 124| loss: 0.84563 |  0:00:10s\n",
      "epoch 125| loss: 0.74336 |  0:00:10s\n",
      "epoch 126| loss: 0.80102 |  0:00:10s\n",
      "epoch 127| loss: 0.73472 |  0:00:10s\n",
      "epoch 128| loss: 0.75045 |  0:00:10s\n",
      "epoch 129| loss: 0.81055 |  0:00:10s\n",
      "epoch 130| loss: 0.7748  |  0:00:10s\n",
      "epoch 131| loss: 0.73214 |  0:00:10s\n",
      "epoch 132| loss: 0.70827 |  0:00:11s\n",
      "epoch 133| loss: 0.70502 |  0:00:11s\n",
      "epoch 134| loss: 0.68928 |  0:00:11s\n",
      "epoch 135| loss: 0.81476 |  0:00:11s\n",
      "epoch 136| loss: 0.75631 |  0:00:11s\n",
      "epoch 137| loss: 0.74864 |  0:00:11s\n",
      "epoch 138| loss: 0.6964  |  0:00:11s\n",
      "epoch 139| loss: 0.77048 |  0:00:11s\n",
      "epoch 140| loss: 0.71624 |  0:00:11s\n",
      "epoch 141| loss: 0.8217  |  0:00:11s\n",
      "epoch 142| loss: 0.69639 |  0:00:11s\n",
      "epoch 143| loss: 0.67042 |  0:00:12s\n",
      "epoch 144| loss: 0.76737 |  0:00:12s\n",
      "epoch 145| loss: 0.71786 |  0:00:12s\n",
      "epoch 146| loss: 0.75623 |  0:00:12s\n",
      "epoch 147| loss: 0.75018 |  0:00:12s\n",
      "epoch 148| loss: 0.73128 |  0:00:12s\n",
      "epoch 149| loss: 0.73718 |  0:00:12s\n",
      "epoch 150| loss: 0.70837 |  0:00:12s\n",
      "epoch 151| loss: 0.75451 |  0:00:12s\n",
      "epoch 152| loss: 0.68162 |  0:00:12s\n",
      "epoch 153| loss: 0.71429 |  0:00:12s\n",
      "epoch 154| loss: 0.69019 |  0:00:12s\n",
      "epoch 155| loss: 0.7057  |  0:00:13s\n",
      "epoch 156| loss: 0.66005 |  0:00:13s\n",
      "epoch 157| loss: 0.68012 |  0:00:13s\n",
      "epoch 158| loss: 0.67136 |  0:00:13s\n",
      "epoch 159| loss: 0.62951 |  0:00:13s\n",
      "epoch 160| loss: 0.61624 |  0:00:13s\n",
      "epoch 161| loss: 0.6401  |  0:00:13s\n",
      "epoch 162| loss: 0.66151 |  0:00:13s\n",
      "epoch 163| loss: 0.6476  |  0:00:13s\n",
      "epoch 164| loss: 0.71976 |  0:00:13s\n",
      "epoch 165| loss: 0.64024 |  0:00:13s\n",
      "epoch 166| loss: 0.63249 |  0:00:13s\n",
      "epoch 167| loss: 0.61862 |  0:00:14s\n",
      "epoch 168| loss: 0.62172 |  0:00:14s\n",
      "epoch 169| loss: 0.6438  |  0:00:14s\n",
      "epoch 170| loss: 0.65114 |  0:00:14s\n",
      "epoch 171| loss: 0.60871 |  0:00:14s\n",
      "epoch 172| loss: 0.62797 |  0:00:14s\n",
      "epoch 173| loss: 0.67289 |  0:00:14s\n",
      "epoch 174| loss: 0.72022 |  0:00:14s\n",
      "epoch 175| loss: 0.60713 |  0:00:14s\n",
      "epoch 176| loss: 0.62991 |  0:00:14s\n",
      "epoch 177| loss: 0.7098  |  0:00:14s\n",
      "epoch 178| loss: 0.59846 |  0:00:14s\n",
      "epoch 179| loss: 0.60854 |  0:00:15s\n",
      "epoch 180| loss: 0.68651 |  0:00:15s\n",
      "epoch 181| loss: 0.59091 |  0:00:15s\n",
      "epoch 182| loss: 0.59037 |  0:00:15s\n",
      "epoch 183| loss: 0.60005 |  0:00:15s\n",
      "epoch 184| loss: 0.6524  |  0:00:15s\n",
      "epoch 185| loss: 0.59302 |  0:00:15s\n",
      "epoch 186| loss: 0.64326 |  0:00:15s\n",
      "epoch 187| loss: 0.54394 |  0:00:15s\n",
      "epoch 188| loss: 0.63048 |  0:00:15s\n",
      "epoch 189| loss: 0.61357 |  0:00:15s\n",
      "epoch 190| loss: 0.59038 |  0:00:15s\n",
      "epoch 191| loss: 0.59388 |  0:00:16s\n",
      "epoch 192| loss: 0.5841  |  0:00:16s\n",
      "epoch 193| loss: 0.60881 |  0:00:16s\n",
      "epoch 194| loss: 0.58208 |  0:00:16s\n",
      "epoch 195| loss: 0.62885 |  0:00:16s\n",
      "epoch 196| loss: 0.5938  |  0:00:16s\n",
      "epoch 197| loss: 0.60114 |  0:00:16s\n",
      "epoch 198| loss: 0.65352 |  0:00:16s\n",
      "epoch 199| loss: 0.59053 |  0:00:16s\n",
      "XGBoost\n",
      "LGBM\n",
      "CatBoost\n",
      "RF\n",
      "GBDT\n",
      "SVR\n",
      "LR\n",
      "ANN\n",
      "TabNet\n",
      "[12:06:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "0:\tlearn: 1.3634514\ttotal: 4.25ms\tremaining: 1.7s\n",
      "1:\tlearn: 1.3318908\ttotal: 8.48ms\tremaining: 1.69s\n",
      "2:\tlearn: 1.3029938\ttotal: 12.8ms\tremaining: 1.7s\n",
      "3:\tlearn: 1.2842993\ttotal: 16.6ms\tremaining: 1.65s\n",
      "4:\tlearn: 1.2638635\ttotal: 20.8ms\tremaining: 1.64s\n",
      "5:\tlearn: 1.2415178\ttotal: 25.4ms\tremaining: 1.67s\n",
      "6:\tlearn: 1.2225143\ttotal: 31.9ms\tremaining: 1.79s\n",
      "7:\tlearn: 1.1979231\ttotal: 35.7ms\tremaining: 1.75s\n",
      "8:\tlearn: 1.1803268\ttotal: 39.9ms\tremaining: 1.73s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\tlearn: 1.1606698\ttotal: 44.5ms\tremaining: 1.74s\n",
      "10:\tlearn: 1.1435711\ttotal: 48.2ms\tremaining: 1.7s\n",
      "11:\tlearn: 1.1298960\ttotal: 52ms\tremaining: 1.68s\n",
      "12:\tlearn: 1.1129454\ttotal: 56.3ms\tremaining: 1.68s\n",
      "13:\tlearn: 1.0940416\ttotal: 60.1ms\tremaining: 1.66s\n",
      "14:\tlearn: 1.0798032\ttotal: 64.2ms\tremaining: 1.65s\n",
      "15:\tlearn: 1.0678150\ttotal: 68.1ms\tremaining: 1.63s\n",
      "16:\tlearn: 1.0451090\ttotal: 71.8ms\tremaining: 1.62s\n",
      "17:\tlearn: 1.0308581\ttotal: 75.4ms\tremaining: 1.6s\n",
      "18:\tlearn: 1.0155439\ttotal: 80ms\tremaining: 1.6s\n",
      "19:\tlearn: 1.0028890\ttotal: 86.6ms\tremaining: 1.65s\n",
      "20:\tlearn: 0.9864381\ttotal: 90.1ms\tremaining: 1.63s\n",
      "21:\tlearn: 0.9773057\ttotal: 93.1ms\tremaining: 1.6s\n",
      "22:\tlearn: 0.9649354\ttotal: 96.1ms\tremaining: 1.57s\n",
      "23:\tlearn: 0.9506875\ttotal: 99.1ms\tremaining: 1.55s\n",
      "24:\tlearn: 0.9404474\ttotal: 103ms\tremaining: 1.54s\n",
      "25:\tlearn: 0.9258776\ttotal: 106ms\tremaining: 1.52s\n",
      "26:\tlearn: 0.9139234\ttotal: 109ms\tremaining: 1.5s\n",
      "27:\tlearn: 0.9029393\ttotal: 112ms\tremaining: 1.48s\n",
      "28:\tlearn: 0.8899547\ttotal: 115ms\tremaining: 1.47s\n",
      "29:\tlearn: 0.8773693\ttotal: 119ms\tremaining: 1.46s\n",
      "30:\tlearn: 0.8626771\ttotal: 122ms\tremaining: 1.46s\n",
      "31:\tlearn: 0.8544676\ttotal: 125ms\tremaining: 1.44s\n",
      "32:\tlearn: 0.8422153\ttotal: 129ms\tremaining: 1.43s\n",
      "33:\tlearn: 0.8326991\ttotal: 132ms\tremaining: 1.42s\n",
      "34:\tlearn: 0.8210606\ttotal: 136ms\tremaining: 1.42s\n",
      "35:\tlearn: 0.8128295\ttotal: 139ms\tremaining: 1.41s\n",
      "36:\tlearn: 0.8043077\ttotal: 142ms\tremaining: 1.4s\n",
      "37:\tlearn: 0.7949643\ttotal: 146ms\tremaining: 1.39s\n",
      "38:\tlearn: 0.7918090\ttotal: 148ms\tremaining: 1.37s\n",
      "39:\tlearn: 0.7862360\ttotal: 152ms\tremaining: 1.36s\n",
      "40:\tlearn: 0.7792976\ttotal: 155ms\tremaining: 1.36s\n",
      "41:\tlearn: 0.7743041\ttotal: 160ms\tremaining: 1.36s\n",
      "42:\tlearn: 0.7664345\ttotal: 165ms\tremaining: 1.37s\n",
      "43:\tlearn: 0.7575789\ttotal: 168ms\tremaining: 1.36s\n",
      "44:\tlearn: 0.7490087\ttotal: 171ms\tremaining: 1.35s\n",
      "45:\tlearn: 0.7392624\ttotal: 174ms\tremaining: 1.34s\n",
      "46:\tlearn: 0.7333272\ttotal: 177ms\tremaining: 1.33s\n",
      "47:\tlearn: 0.7258569\ttotal: 181ms\tremaining: 1.33s\n",
      "48:\tlearn: 0.7183417\ttotal: 184ms\tremaining: 1.32s\n",
      "49:\tlearn: 0.7139807\ttotal: 188ms\tremaining: 1.31s\n",
      "50:\tlearn: 0.7068899\ttotal: 191ms\tremaining: 1.31s\n",
      "51:\tlearn: 0.7006720\ttotal: 194ms\tremaining: 1.3s\n",
      "52:\tlearn: 0.6958794\ttotal: 198ms\tremaining: 1.3s\n",
      "53:\tlearn: 0.6900616\ttotal: 202ms\tremaining: 1.3s\n",
      "54:\tlearn: 0.6827077\ttotal: 206ms\tremaining: 1.29s\n",
      "55:\tlearn: 0.6767314\ttotal: 209ms\tremaining: 1.28s\n",
      "56:\tlearn: 0.6708470\ttotal: 213ms\tremaining: 1.28s\n",
      "57:\tlearn: 0.6622584\ttotal: 218ms\tremaining: 1.29s\n",
      "58:\tlearn: 0.6586104\ttotal: 222ms\tremaining: 1.28s\n",
      "59:\tlearn: 0.6521289\ttotal: 226ms\tremaining: 1.28s\n",
      "60:\tlearn: 0.6455754\ttotal: 229ms\tremaining: 1.27s\n",
      "61:\tlearn: 0.6387085\ttotal: 232ms\tremaining: 1.27s\n",
      "62:\tlearn: 0.6301897\ttotal: 236ms\tremaining: 1.26s\n",
      "63:\tlearn: 0.6247976\ttotal: 240ms\tremaining: 1.26s\n",
      "64:\tlearn: 0.6188614\ttotal: 243ms\tremaining: 1.25s\n",
      "65:\tlearn: 0.6136366\ttotal: 247ms\tremaining: 1.25s\n",
      "66:\tlearn: 0.6081559\ttotal: 251ms\tremaining: 1.25s\n",
      "67:\tlearn: 0.6030335\ttotal: 254ms\tremaining: 1.24s\n",
      "68:\tlearn: 0.5971415\ttotal: 258ms\tremaining: 1.24s\n",
      "69:\tlearn: 0.5917402\ttotal: 261ms\tremaining: 1.23s\n",
      "70:\tlearn: 0.5861757\ttotal: 264ms\tremaining: 1.22s\n",
      "71:\tlearn: 0.5784751\ttotal: 268ms\tremaining: 1.22s\n",
      "72:\tlearn: 0.5726853\ttotal: 272ms\tremaining: 1.22s\n",
      "73:\tlearn: 0.5666197\ttotal: 275ms\tremaining: 1.21s\n",
      "74:\tlearn: 0.5583997\ttotal: 281ms\tremaining: 1.22s\n",
      "75:\tlearn: 0.5559776\ttotal: 284ms\tremaining: 1.21s\n",
      "76:\tlearn: 0.5481150\ttotal: 287ms\tremaining: 1.2s\n",
      "77:\tlearn: 0.5435875\ttotal: 290ms\tremaining: 1.2s\n",
      "78:\tlearn: 0.5383926\ttotal: 294ms\tremaining: 1.2s\n",
      "79:\tlearn: 0.5328409\ttotal: 298ms\tremaining: 1.19s\n",
      "80:\tlearn: 0.5259581\ttotal: 300ms\tremaining: 1.18s\n",
      "81:\tlearn: 0.5196830\ttotal: 304ms\tremaining: 1.18s\n",
      "82:\tlearn: 0.5133272\ttotal: 308ms\tremaining: 1.18s\n",
      "83:\tlearn: 0.5095177\ttotal: 312ms\tremaining: 1.17s\n",
      "84:\tlearn: 0.5025690\ttotal: 315ms\tremaining: 1.17s\n",
      "85:\tlearn: 0.4951935\ttotal: 318ms\tremaining: 1.16s\n",
      "86:\tlearn: 0.4891808\ttotal: 322ms\tremaining: 1.16s\n",
      "87:\tlearn: 0.4850049\ttotal: 325ms\tremaining: 1.15s\n",
      "88:\tlearn: 0.4787558\ttotal: 329ms\tremaining: 1.15s\n",
      "89:\tlearn: 0.4728901\ttotal: 333ms\tremaining: 1.15s\n",
      "90:\tlearn: 0.4678243\ttotal: 336ms\tremaining: 1.14s\n",
      "91:\tlearn: 0.4624823\ttotal: 341ms\tremaining: 1.14s\n",
      "92:\tlearn: 0.4572421\ttotal: 345ms\tremaining: 1.14s\n",
      "93:\tlearn: 0.4548761\ttotal: 347ms\tremaining: 1.13s\n",
      "94:\tlearn: 0.4526844\ttotal: 350ms\tremaining: 1.12s\n",
      "95:\tlearn: 0.4508482\ttotal: 354ms\tremaining: 1.12s\n",
      "96:\tlearn: 0.4483482\ttotal: 358ms\tremaining: 1.12s\n",
      "97:\tlearn: 0.4450400\ttotal: 361ms\tremaining: 1.11s\n",
      "98:\tlearn: 0.4413420\ttotal: 365ms\tremaining: 1.11s\n",
      "99:\tlearn: 0.4364057\ttotal: 368ms\tremaining: 1.1s\n",
      "100:\tlearn: 0.4313019\ttotal: 373ms\tremaining: 1.1s\n",
      "101:\tlearn: 0.4265191\ttotal: 378ms\tremaining: 1.1s\n",
      "102:\tlearn: 0.4234315\ttotal: 381ms\tremaining: 1.1s\n",
      "103:\tlearn: 0.4194355\ttotal: 384ms\tremaining: 1.09s\n",
      "104:\tlearn: 0.4172531\ttotal: 388ms\tremaining: 1.09s\n",
      "105:\tlearn: 0.4132583\ttotal: 391ms\tremaining: 1.08s\n",
      "106:\tlearn: 0.4095991\ttotal: 395ms\tremaining: 1.08s\n",
      "107:\tlearn: 0.4042863\ttotal: 399ms\tremaining: 1.08s\n",
      "108:\tlearn: 0.4005697\ttotal: 403ms\tremaining: 1.08s\n",
      "109:\tlearn: 0.3972387\ttotal: 408ms\tremaining: 1.07s\n",
      "110:\tlearn: 0.3938165\ttotal: 413ms\tremaining: 1.07s\n",
      "111:\tlearn: 0.3917161\ttotal: 417ms\tremaining: 1.07s\n",
      "112:\tlearn: 0.3886724\ttotal: 420ms\tremaining: 1.07s\n",
      "113:\tlearn: 0.3862826\ttotal: 424ms\tremaining: 1.06s\n",
      "114:\tlearn: 0.3835086\ttotal: 427ms\tremaining: 1.06s\n",
      "115:\tlearn: 0.3788359\ttotal: 430ms\tremaining: 1.05s\n",
      "116:\tlearn: 0.3734278\ttotal: 433ms\tremaining: 1.05s\n",
      "117:\tlearn: 0.3702331\ttotal: 437ms\tremaining: 1.04s\n",
      "118:\tlearn: 0.3671084\ttotal: 441ms\tremaining: 1.04s\n",
      "119:\tlearn: 0.3634728\ttotal: 444ms\tremaining: 1.03s\n",
      "120:\tlearn: 0.3593643\ttotal: 447ms\tremaining: 1.03s\n",
      "121:\tlearn: 0.3566094\ttotal: 450ms\tremaining: 1.03s\n",
      "122:\tlearn: 0.3546008\ttotal: 454ms\tremaining: 1.02s\n",
      "123:\tlearn: 0.3514606\ttotal: 458ms\tremaining: 1.02s\n",
      "124:\tlearn: 0.3490091\ttotal: 462ms\tremaining: 1.01s\n",
      "125:\tlearn: 0.3444601\ttotal: 468ms\tremaining: 1.02s\n",
      "126:\tlearn: 0.3419710\ttotal: 472ms\tremaining: 1.01s\n",
      "127:\tlearn: 0.3404533\ttotal: 475ms\tremaining: 1.01s\n",
      "128:\tlearn: 0.3378794\ttotal: 478ms\tremaining: 1s\n",
      "129:\tlearn: 0.3342310\ttotal: 481ms\tremaining: 999ms\n",
      "130:\tlearn: 0.3316707\ttotal: 485ms\tremaining: 996ms\n",
      "131:\tlearn: 0.3301938\ttotal: 488ms\tremaining: 991ms\n",
      "132:\tlearn: 0.3271505\ttotal: 491ms\tremaining: 986ms\n",
      "133:\tlearn: 0.3255556\ttotal: 494ms\tremaining: 981ms\n",
      "134:\tlearn: 0.3227049\ttotal: 497ms\tremaining: 976ms\n",
      "135:\tlearn: 0.3194831\ttotal: 501ms\tremaining: 972ms\n",
      "136:\tlearn: 0.3167481\ttotal: 504ms\tremaining: 967ms\n",
      "137:\tlearn: 0.3143671\ttotal: 507ms\tremaining: 963ms\n",
      "138:\tlearn: 0.3109937\ttotal: 510ms\tremaining: 958ms\n",
      "139:\tlearn: 0.3085826\ttotal: 514ms\tremaining: 954ms\n",
      "140:\tlearn: 0.3067334\ttotal: 517ms\tremaining: 950ms\n",
      "141:\tlearn: 0.3050654\ttotal: 521ms\tremaining: 946ms\n",
      "142:\tlearn: 0.3035362\ttotal: 524ms\tremaining: 942ms\n",
      "143:\tlearn: 0.3001114\ttotal: 528ms\tremaining: 939ms\n",
      "144:\tlearn: 0.2975856\ttotal: 533ms\tremaining: 937ms\n",
      "145:\tlearn: 0.2946263\ttotal: 536ms\tremaining: 933ms\n",
      "146:\tlearn: 0.2917724\ttotal: 540ms\tremaining: 929ms\n",
      "147:\tlearn: 0.2887572\ttotal: 543ms\tremaining: 924ms\n",
      "148:\tlearn: 0.2862638\ttotal: 546ms\tremaining: 920ms\n",
      "149:\tlearn: 0.2838726\ttotal: 549ms\tremaining: 916ms\n",
      "150:\tlearn: 0.2822322\ttotal: 552ms\tremaining: 911ms\n",
      "151:\tlearn: 0.2795649\ttotal: 556ms\tremaining: 907ms\n",
      "152:\tlearn: 0.2766463\ttotal: 559ms\tremaining: 902ms\n",
      "153:\tlearn: 0.2748049\ttotal: 562ms\tremaining: 898ms\n",
      "154:\tlearn: 0.2712835\ttotal: 565ms\tremaining: 893ms\n",
      "155:\tlearn: 0.2690802\ttotal: 568ms\tremaining: 889ms\n",
      "156:\tlearn: 0.2668854\ttotal: 571ms\tremaining: 885ms\n",
      "157:\tlearn: 0.2646205\ttotal: 575ms\tremaining: 881ms\n",
      "158:\tlearn: 0.2623071\ttotal: 579ms\tremaining: 878ms\n",
      "159:\tlearn: 0.2599367\ttotal: 583ms\tremaining: 875ms\n",
      "160:\tlearn: 0.2577048\ttotal: 587ms\tremaining: 872ms\n",
      "161:\tlearn: 0.2558644\ttotal: 592ms\tremaining: 869ms\n",
      "162:\tlearn: 0.2537877\ttotal: 597ms\tremaining: 869ms\n",
      "163:\tlearn: 0.2507867\ttotal: 601ms\tremaining: 865ms\n",
      "164:\tlearn: 0.2491962\ttotal: 605ms\tremaining: 861ms\n",
      "165:\tlearn: 0.2474496\ttotal: 609ms\tremaining: 858ms\n",
      "166:\tlearn: 0.2462072\ttotal: 612ms\tremaining: 854ms\n",
      "167:\tlearn: 0.2442412\ttotal: 615ms\tremaining: 849ms\n",
      "168:\tlearn: 0.2425916\ttotal: 618ms\tremaining: 845ms\n",
      "169:\tlearn: 0.2411029\ttotal: 621ms\tremaining: 840ms\n",
      "170:\tlearn: 0.2396089\ttotal: 624ms\tremaining: 836ms\n",
      "171:\tlearn: 0.2378148\ttotal: 628ms\tremaining: 832ms\n",
      "172:\tlearn: 0.2359207\ttotal: 631ms\tremaining: 828ms\n",
      "173:\tlearn: 0.2348177\ttotal: 634ms\tremaining: 824ms\n",
      "174:\tlearn: 0.2330811\ttotal: 637ms\tremaining: 819ms\n",
      "175:\tlearn: 0.2315392\ttotal: 641ms\tremaining: 816ms\n",
      "176:\tlearn: 0.2297644\ttotal: 645ms\tremaining: 812ms\n",
      "177:\tlearn: 0.2286011\ttotal: 649ms\tremaining: 809ms\n",
      "178:\tlearn: 0.2268814\ttotal: 652ms\tremaining: 805ms\n",
      "179:\tlearn: 0.2254434\ttotal: 656ms\tremaining: 802ms\n",
      "180:\tlearn: 0.2237118\ttotal: 661ms\tremaining: 800ms\n",
      "181:\tlearn: 0.2227853\ttotal: 664ms\tremaining: 796ms\n",
      "182:\tlearn: 0.2212516\ttotal: 667ms\tremaining: 791ms\n",
      "183:\tlearn: 0.2192136\ttotal: 671ms\tremaining: 787ms\n",
      "184:\tlearn: 0.2174779\ttotal: 674ms\tremaining: 783ms\n",
      "185:\tlearn: 0.2166246\ttotal: 677ms\tremaining: 779ms\n",
      "186:\tlearn: 0.2160354\ttotal: 680ms\tremaining: 775ms\n",
      "187:\tlearn: 0.2147260\ttotal: 683ms\tremaining: 770ms\n",
      "188:\tlearn: 0.2133659\ttotal: 686ms\tremaining: 766ms\n",
      "189:\tlearn: 0.2115694\ttotal: 690ms\tremaining: 762ms\n",
      "190:\tlearn: 0.2100502\ttotal: 692ms\tremaining: 758ms\n",
      "191:\tlearn: 0.2091206\ttotal: 696ms\tremaining: 754ms\n",
      "192:\tlearn: 0.2077799\ttotal: 698ms\tremaining: 749ms\n",
      "193:\tlearn: 0.2066804\ttotal: 701ms\tremaining: 745ms\n",
      "194:\tlearn: 0.2055483\ttotal: 705ms\tremaining: 741ms\n",
      "195:\tlearn: 0.2040911\ttotal: 708ms\tremaining: 737ms\n",
      "196:\tlearn: 0.2020752\ttotal: 712ms\tremaining: 734ms\n",
      "197:\tlearn: 0.2006755\ttotal: 715ms\tremaining: 730ms\n",
      "198:\tlearn: 0.1993713\ttotal: 719ms\tremaining: 726ms\n",
      "199:\tlearn: 0.1978626\ttotal: 722ms\tremaining: 722ms\n",
      "200:\tlearn: 0.1970469\ttotal: 727ms\tremaining: 720ms\n",
      "201:\tlearn: 0.1961533\ttotal: 730ms\tremaining: 716ms\n",
      "202:\tlearn: 0.1945965\ttotal: 733ms\tremaining: 712ms\n",
      "203:\tlearn: 0.1933112\ttotal: 737ms\tremaining: 708ms\n",
      "204:\tlearn: 0.1920232\ttotal: 740ms\tremaining: 704ms\n",
      "205:\tlearn: 0.1908239\ttotal: 743ms\tremaining: 700ms\n",
      "206:\tlearn: 0.1890249\ttotal: 746ms\tremaining: 696ms\n",
      "207:\tlearn: 0.1877734\ttotal: 749ms\tremaining: 691ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208:\tlearn: 0.1865271\ttotal: 753ms\tremaining: 688ms\n",
      "209:\tlearn: 0.1855174\ttotal: 756ms\tremaining: 684ms\n",
      "210:\tlearn: 0.1839730\ttotal: 759ms\tremaining: 680ms\n",
      "211:\tlearn: 0.1831569\ttotal: 762ms\tremaining: 676ms\n",
      "212:\tlearn: 0.1824332\ttotal: 765ms\tremaining: 672ms\n",
      "213:\tlearn: 0.1807288\ttotal: 769ms\tremaining: 668ms\n",
      "214:\tlearn: 0.1801852\ttotal: 772ms\tremaining: 665ms\n",
      "215:\tlearn: 0.1787035\ttotal: 777ms\tremaining: 662ms\n",
      "216:\tlearn: 0.1784266\ttotal: 780ms\tremaining: 658ms\n",
      "217:\tlearn: 0.1773163\ttotal: 785ms\tremaining: 655ms\n",
      "218:\tlearn: 0.1763363\ttotal: 791ms\tremaining: 654ms\n",
      "219:\tlearn: 0.1753235\ttotal: 794ms\tremaining: 650ms\n",
      "220:\tlearn: 0.1744773\ttotal: 797ms\tremaining: 646ms\n",
      "221:\tlearn: 0.1734833\ttotal: 801ms\tremaining: 642ms\n",
      "222:\tlearn: 0.1728095\ttotal: 804ms\tremaining: 638ms\n",
      "223:\tlearn: 0.1718165\ttotal: 807ms\tremaining: 634ms\n",
      "224:\tlearn: 0.1706480\ttotal: 810ms\tremaining: 630ms\n",
      "225:\tlearn: 0.1694550\ttotal: 812ms\tremaining: 626ms\n",
      "226:\tlearn: 0.1687213\ttotal: 816ms\tremaining: 622ms\n",
      "227:\tlearn: 0.1673163\ttotal: 819ms\tremaining: 618ms\n",
      "228:\tlearn: 0.1662690\ttotal: 822ms\tremaining: 614ms\n",
      "229:\tlearn: 0.1655683\ttotal: 825ms\tremaining: 610ms\n",
      "230:\tlearn: 0.1647696\ttotal: 828ms\tremaining: 606ms\n",
      "231:\tlearn: 0.1641745\ttotal: 832ms\tremaining: 602ms\n",
      "232:\tlearn: 0.1630695\ttotal: 835ms\tremaining: 598ms\n",
      "233:\tlearn: 0.1615939\ttotal: 839ms\tremaining: 595ms\n",
      "234:\tlearn: 0.1610221\ttotal: 842ms\tremaining: 591ms\n",
      "235:\tlearn: 0.1605279\ttotal: 845ms\tremaining: 587ms\n",
      "236:\tlearn: 0.1597144\ttotal: 848ms\tremaining: 583ms\n",
      "237:\tlearn: 0.1590021\ttotal: 853ms\tremaining: 580ms\n",
      "238:\tlearn: 0.1578334\ttotal: 857ms\tremaining: 577ms\n",
      "239:\tlearn: 0.1569987\ttotal: 860ms\tremaining: 573ms\n",
      "240:\tlearn: 0.1561760\ttotal: 863ms\tremaining: 570ms\n",
      "241:\tlearn: 0.1552779\ttotal: 866ms\tremaining: 566ms\n",
      "242:\tlearn: 0.1544429\ttotal: 869ms\tremaining: 562ms\n",
      "243:\tlearn: 0.1531882\ttotal: 872ms\tremaining: 558ms\n",
      "244:\tlearn: 0.1521958\ttotal: 876ms\tremaining: 554ms\n",
      "245:\tlearn: 0.1516119\ttotal: 879ms\tremaining: 551ms\n",
      "246:\tlearn: 0.1507105\ttotal: 883ms\tremaining: 547ms\n",
      "247:\tlearn: 0.1498385\ttotal: 886ms\tremaining: 543ms\n",
      "248:\tlearn: 0.1490360\ttotal: 889ms\tremaining: 539ms\n",
      "249:\tlearn: 0.1480763\ttotal: 892ms\tremaining: 535ms\n",
      "250:\tlearn: 0.1472773\ttotal: 896ms\tremaining: 532ms\n",
      "251:\tlearn: 0.1467208\ttotal: 900ms\tremaining: 529ms\n",
      "252:\tlearn: 0.1461938\ttotal: 904ms\tremaining: 525ms\n",
      "253:\tlearn: 0.1453863\ttotal: 908ms\tremaining: 522ms\n",
      "254:\tlearn: 0.1447139\ttotal: 912ms\tremaining: 519ms\n",
      "255:\tlearn: 0.1439957\ttotal: 915ms\tremaining: 515ms\n",
      "256:\tlearn: 0.1430099\ttotal: 919ms\tremaining: 511ms\n",
      "257:\tlearn: 0.1423485\ttotal: 922ms\tremaining: 507ms\n",
      "258:\tlearn: 0.1413367\ttotal: 926ms\tremaining: 504ms\n",
      "259:\tlearn: 0.1408024\ttotal: 929ms\tremaining: 500ms\n",
      "260:\tlearn: 0.1396124\ttotal: 933ms\tremaining: 497ms\n",
      "261:\tlearn: 0.1387717\ttotal: 936ms\tremaining: 493ms\n",
      "262:\tlearn: 0.1380969\ttotal: 939ms\tremaining: 489ms\n",
      "263:\tlearn: 0.1371356\ttotal: 943ms\tremaining: 486ms\n",
      "264:\tlearn: 0.1363634\ttotal: 946ms\tremaining: 482ms\n",
      "265:\tlearn: 0.1357402\ttotal: 950ms\tremaining: 478ms\n",
      "266:\tlearn: 0.1349031\ttotal: 953ms\tremaining: 475ms\n",
      "267:\tlearn: 0.1340964\ttotal: 957ms\tremaining: 471ms\n",
      "268:\tlearn: 0.1332207\ttotal: 960ms\tremaining: 468ms\n",
      "269:\tlearn: 0.1326723\ttotal: 964ms\tremaining: 464ms\n",
      "270:\tlearn: 0.1320706\ttotal: 968ms\tremaining: 461ms\n",
      "271:\tlearn: 0.1313928\ttotal: 973ms\tremaining: 458ms\n",
      "272:\tlearn: 0.1308570\ttotal: 977ms\tremaining: 455ms\n",
      "273:\tlearn: 0.1303212\ttotal: 980ms\tremaining: 451ms\n",
      "274:\tlearn: 0.1294461\ttotal: 983ms\tremaining: 447ms\n",
      "275:\tlearn: 0.1288216\ttotal: 986ms\tremaining: 443ms\n",
      "276:\tlearn: 0.1280128\ttotal: 991ms\tremaining: 440ms\n",
      "277:\tlearn: 0.1274759\ttotal: 994ms\tremaining: 436ms\n",
      "278:\tlearn: 0.1265820\ttotal: 998ms\tremaining: 433ms\n",
      "279:\tlearn: 0.1259642\ttotal: 1s\tremaining: 429ms\n",
      "280:\tlearn: 0.1252668\ttotal: 1s\tremaining: 426ms\n",
      "281:\tlearn: 0.1244329\ttotal: 1.01s\tremaining: 422ms\n",
      "282:\tlearn: 0.1239546\ttotal: 1.01s\tremaining: 418ms\n",
      "283:\tlearn: 0.1235329\ttotal: 1.01s\tremaining: 415ms\n",
      "284:\tlearn: 0.1230913\ttotal: 1.02s\tremaining: 411ms\n",
      "285:\tlearn: 0.1228256\ttotal: 1.02s\tremaining: 408ms\n",
      "286:\tlearn: 0.1219980\ttotal: 1.02s\tremaining: 404ms\n",
      "287:\tlearn: 0.1213672\ttotal: 1.03s\tremaining: 401ms\n",
      "288:\tlearn: 0.1208903\ttotal: 1.03s\tremaining: 397ms\n",
      "289:\tlearn: 0.1202329\ttotal: 1.04s\tremaining: 394ms\n",
      "290:\tlearn: 0.1197804\ttotal: 1.04s\tremaining: 391ms\n",
      "291:\tlearn: 0.1191745\ttotal: 1.05s\tremaining: 387ms\n",
      "292:\tlearn: 0.1187242\ttotal: 1.05s\tremaining: 383ms\n",
      "293:\tlearn: 0.1182229\ttotal: 1.05s\tremaining: 380ms\n",
      "294:\tlearn: 0.1176689\ttotal: 1.06s\tremaining: 376ms\n",
      "295:\tlearn: 0.1171082\ttotal: 1.06s\tremaining: 373ms\n",
      "296:\tlearn: 0.1165919\ttotal: 1.06s\tremaining: 369ms\n",
      "297:\tlearn: 0.1159609\ttotal: 1.07s\tremaining: 365ms\n",
      "298:\tlearn: 0.1154363\ttotal: 1.07s\tremaining: 362ms\n",
      "299:\tlearn: 0.1147063\ttotal: 1.07s\tremaining: 358ms\n",
      "300:\tlearn: 0.1141663\ttotal: 1.08s\tremaining: 354ms\n",
      "301:\tlearn: 0.1136020\ttotal: 1.08s\tremaining: 351ms\n",
      "302:\tlearn: 0.1130418\ttotal: 1.08s\tremaining: 347ms\n",
      "303:\tlearn: 0.1125261\ttotal: 1.09s\tremaining: 344ms\n",
      "304:\tlearn: 0.1122897\ttotal: 1.09s\tremaining: 340ms\n",
      "305:\tlearn: 0.1115450\ttotal: 1.09s\tremaining: 336ms\n",
      "306:\tlearn: 0.1110133\ttotal: 1.1s\tremaining: 333ms\n",
      "307:\tlearn: 0.1106122\ttotal: 1.1s\tremaining: 330ms\n",
      "308:\tlearn: 0.1102486\ttotal: 1.11s\tremaining: 326ms\n",
      "309:\tlearn: 0.1095902\ttotal: 1.11s\tremaining: 323ms\n",
      "310:\tlearn: 0.1090891\ttotal: 1.11s\tremaining: 319ms\n",
      "311:\tlearn: 0.1085266\ttotal: 1.12s\tremaining: 315ms\n",
      "312:\tlearn: 0.1081350\ttotal: 1.12s\tremaining: 312ms\n",
      "313:\tlearn: 0.1076927\ttotal: 1.13s\tremaining: 308ms\n",
      "314:\tlearn: 0.1071193\ttotal: 1.13s\tremaining: 305ms\n",
      "315:\tlearn: 0.1065922\ttotal: 1.13s\tremaining: 301ms\n",
      "316:\tlearn: 0.1059333\ttotal: 1.14s\tremaining: 297ms\n",
      "317:\tlearn: 0.1055351\ttotal: 1.14s\tremaining: 294ms\n",
      "318:\tlearn: 0.1051528\ttotal: 1.14s\tremaining: 290ms\n",
      "319:\tlearn: 0.1047206\ttotal: 1.15s\tremaining: 286ms\n",
      "320:\tlearn: 0.1042152\ttotal: 1.15s\tremaining: 283ms\n",
      "321:\tlearn: 0.1039079\ttotal: 1.15s\tremaining: 279ms\n",
      "322:\tlearn: 0.1034532\ttotal: 1.16s\tremaining: 276ms\n",
      "323:\tlearn: 0.1028538\ttotal: 1.16s\tremaining: 272ms\n",
      "324:\tlearn: 0.1025653\ttotal: 1.16s\tremaining: 269ms\n",
      "325:\tlearn: 0.1021798\ttotal: 1.17s\tremaining: 265ms\n",
      "326:\tlearn: 0.1017628\ttotal: 1.17s\tremaining: 262ms\n",
      "327:\tlearn: 0.1012970\ttotal: 1.18s\tremaining: 258ms\n",
      "328:\tlearn: 0.1008345\ttotal: 1.18s\tremaining: 254ms\n",
      "329:\tlearn: 0.1006495\ttotal: 1.18s\tremaining: 251ms\n",
      "330:\tlearn: 0.1002671\ttotal: 1.19s\tremaining: 247ms\n",
      "331:\tlearn: 0.0997573\ttotal: 1.19s\tremaining: 243ms\n",
      "332:\tlearn: 0.0992079\ttotal: 1.19s\tremaining: 240ms\n",
      "333:\tlearn: 0.0989366\ttotal: 1.2s\tremaining: 236ms\n",
      "334:\tlearn: 0.0983011\ttotal: 1.2s\tremaining: 232ms\n",
      "335:\tlearn: 0.0976913\ttotal: 1.2s\tremaining: 229ms\n",
      "336:\tlearn: 0.0972014\ttotal: 1.2s\tremaining: 225ms\n",
      "337:\tlearn: 0.0968439\ttotal: 1.21s\tremaining: 221ms\n",
      "338:\tlearn: 0.0965059\ttotal: 1.21s\tremaining: 218ms\n",
      "339:\tlearn: 0.0961235\ttotal: 1.21s\tremaining: 214ms\n",
      "340:\tlearn: 0.0958298\ttotal: 1.22s\tremaining: 211ms\n",
      "341:\tlearn: 0.0953116\ttotal: 1.22s\tremaining: 207ms\n",
      "342:\tlearn: 0.0951196\ttotal: 1.22s\tremaining: 203ms\n",
      "343:\tlearn: 0.0947805\ttotal: 1.23s\tremaining: 200ms\n",
      "344:\tlearn: 0.0945302\ttotal: 1.23s\tremaining: 196ms\n",
      "345:\tlearn: 0.0942538\ttotal: 1.24s\tremaining: 193ms\n",
      "346:\tlearn: 0.0939640\ttotal: 1.24s\tremaining: 189ms\n",
      "347:\tlearn: 0.0934701\ttotal: 1.24s\tremaining: 186ms\n",
      "348:\tlearn: 0.0930841\ttotal: 1.25s\tremaining: 182ms\n",
      "349:\tlearn: 0.0926637\ttotal: 1.25s\tremaining: 179ms\n",
      "350:\tlearn: 0.0923911\ttotal: 1.25s\tremaining: 175ms\n",
      "351:\tlearn: 0.0919264\ttotal: 1.26s\tremaining: 172ms\n",
      "352:\tlearn: 0.0915572\ttotal: 1.26s\tremaining: 168ms\n",
      "353:\tlearn: 0.0910927\ttotal: 1.26s\tremaining: 164ms\n",
      "354:\tlearn: 0.0906828\ttotal: 1.27s\tremaining: 161ms\n",
      "355:\tlearn: 0.0902640\ttotal: 1.27s\tremaining: 157ms\n",
      "356:\tlearn: 0.0897927\ttotal: 1.27s\tremaining: 154ms\n",
      "357:\tlearn: 0.0894974\ttotal: 1.28s\tremaining: 150ms\n",
      "358:\tlearn: 0.0892883\ttotal: 1.28s\tremaining: 146ms\n",
      "359:\tlearn: 0.0889587\ttotal: 1.28s\tremaining: 143ms\n",
      "360:\tlearn: 0.0885819\ttotal: 1.29s\tremaining: 139ms\n",
      "361:\tlearn: 0.0882966\ttotal: 1.29s\tremaining: 136ms\n",
      "362:\tlearn: 0.0879456\ttotal: 1.29s\tremaining: 132ms\n",
      "363:\tlearn: 0.0876254\ttotal: 1.3s\tremaining: 128ms\n",
      "364:\tlearn: 0.0873559\ttotal: 1.3s\tremaining: 125ms\n",
      "365:\tlearn: 0.0870162\ttotal: 1.31s\tremaining: 122ms\n",
      "366:\tlearn: 0.0865313\ttotal: 1.31s\tremaining: 118ms\n",
      "367:\tlearn: 0.0860763\ttotal: 1.32s\tremaining: 114ms\n",
      "368:\tlearn: 0.0856367\ttotal: 1.32s\tremaining: 111ms\n",
      "369:\tlearn: 0.0852058\ttotal: 1.32s\tremaining: 107ms\n",
      "370:\tlearn: 0.0847554\ttotal: 1.33s\tremaining: 104ms\n",
      "371:\tlearn: 0.0845102\ttotal: 1.33s\tremaining: 100ms\n",
      "372:\tlearn: 0.0843630\ttotal: 1.33s\tremaining: 96.5ms\n",
      "373:\tlearn: 0.0838715\ttotal: 1.33s\tremaining: 92.9ms\n",
      "374:\tlearn: 0.0834992\ttotal: 1.34s\tremaining: 89.3ms\n",
      "375:\tlearn: 0.0832859\ttotal: 1.34s\tremaining: 85.7ms\n",
      "376:\tlearn: 0.0828077\ttotal: 1.34s\tremaining: 82.1ms\n",
      "377:\tlearn: 0.0823665\ttotal: 1.35s\tremaining: 78.5ms\n",
      "378:\tlearn: 0.0821914\ttotal: 1.35s\tremaining: 74.9ms\n",
      "379:\tlearn: 0.0818460\ttotal: 1.35s\tremaining: 71.3ms\n",
      "380:\tlearn: 0.0814818\ttotal: 1.36s\tremaining: 67.7ms\n",
      "381:\tlearn: 0.0811433\ttotal: 1.36s\tremaining: 64.2ms\n",
      "382:\tlearn: 0.0808431\ttotal: 1.36s\tremaining: 60.6ms\n",
      "383:\tlearn: 0.0804734\ttotal: 1.37s\tremaining: 57.1ms\n",
      "384:\tlearn: 0.0800820\ttotal: 1.38s\tremaining: 53.6ms\n",
      "385:\tlearn: 0.0797301\ttotal: 1.38s\tremaining: 50ms\n",
      "386:\tlearn: 0.0794036\ttotal: 1.38s\tremaining: 46.4ms\n",
      "387:\tlearn: 0.0791530\ttotal: 1.39s\tremaining: 42.9ms\n",
      "388:\tlearn: 0.0788131\ttotal: 1.39s\tremaining: 39.3ms\n",
      "389:\tlearn: 0.0785233\ttotal: 1.39s\tremaining: 35.7ms\n",
      "390:\tlearn: 0.0780418\ttotal: 1.4s\tremaining: 32.1ms\n",
      "391:\tlearn: 0.0777749\ttotal: 1.4s\tremaining: 28.5ms\n",
      "392:\tlearn: 0.0774813\ttotal: 1.4s\tremaining: 25ms\n",
      "393:\tlearn: 0.0772187\ttotal: 1.41s\tremaining: 21.4ms\n",
      "394:\tlearn: 0.0770204\ttotal: 1.41s\tremaining: 17.8ms\n",
      "395:\tlearn: 0.0767954\ttotal: 1.41s\tremaining: 14.3ms\n",
      "396:\tlearn: 0.0765726\ttotal: 1.42s\tremaining: 10.7ms\n",
      "397:\tlearn: 0.0762697\ttotal: 1.42s\tremaining: 7.13ms\n",
      "398:\tlearn: 0.0759647\ttotal: 1.42s\tremaining: 3.56ms\n",
      "399:\tlearn: 0.0756413\ttotal: 1.43s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.94829 |  0:00:00s\n",
      "epoch 1  | loss: 1.62086 |  0:00:00s\n",
      "epoch 2  | loss: 1.42165 |  0:00:00s\n",
      "epoch 3  | loss: 1.44398 |  0:00:00s\n",
      "epoch 4  | loss: 1.3589  |  0:00:00s\n",
      "epoch 5  | loss: 1.36435 |  0:00:00s\n",
      "epoch 6  | loss: 1.33562 |  0:00:00s\n",
      "epoch 7  | loss: 1.30616 |  0:00:00s\n",
      "epoch 8  | loss: 1.3063  |  0:00:00s\n",
      "epoch 9  | loss: 1.28525 |  0:00:00s\n",
      "epoch 10 | loss: 1.2777  |  0:00:00s\n",
      "epoch 11 | loss: 1.26247 |  0:00:00s\n",
      "epoch 12 | loss: 1.23666 |  0:00:01s\n",
      "epoch 13 | loss: 1.2198  |  0:00:01s\n",
      "epoch 14 | loss: 1.22621 |  0:00:01s\n",
      "epoch 15 | loss: 1.21    |  0:00:01s\n",
      "epoch 16 | loss: 1.21861 |  0:00:01s\n",
      "epoch 17 | loss: 1.19868 |  0:00:01s\n",
      "epoch 18 | loss: 1.1601  |  0:00:01s\n",
      "epoch 19 | loss: 1.21235 |  0:00:01s\n",
      "epoch 20 | loss: 1.18655 |  0:00:01s\n",
      "epoch 21 | loss: 1.16781 |  0:00:01s\n",
      "epoch 22 | loss: 1.21008 |  0:00:01s\n",
      "epoch 23 | loss: 1.14811 |  0:00:02s\n",
      "epoch 24 | loss: 1.17776 |  0:00:02s\n",
      "epoch 25 | loss: 1.14029 |  0:00:02s\n",
      "epoch 26 | loss: 1.16955 |  0:00:02s\n",
      "epoch 27 | loss: 1.16106 |  0:00:02s\n",
      "epoch 28 | loss: 1.10751 |  0:00:02s\n",
      "epoch 29 | loss: 1.121   |  0:00:02s\n",
      "epoch 30 | loss: 1.13722 |  0:00:02s\n",
      "epoch 31 | loss: 1.14477 |  0:00:02s\n",
      "epoch 32 | loss: 1.15492 |  0:00:02s\n",
      "epoch 33 | loss: 1.13529 |  0:00:02s\n",
      "epoch 34 | loss: 1.09297 |  0:00:02s\n",
      "epoch 35 | loss: 1.09929 |  0:00:02s\n",
      "epoch 36 | loss: 1.11657 |  0:00:03s\n",
      "epoch 37 | loss: 1.10087 |  0:00:03s\n",
      "epoch 38 | loss: 1.10877 |  0:00:03s\n",
      "epoch 39 | loss: 1.07452 |  0:00:03s\n",
      "epoch 40 | loss: 1.05801 |  0:00:03s\n",
      "epoch 41 | loss: 1.14562 |  0:00:03s\n",
      "epoch 42 | loss: 1.05241 |  0:00:03s\n",
      "epoch 43 | loss: 1.05382 |  0:00:03s\n",
      "epoch 44 | loss: 1.08296 |  0:00:03s\n",
      "epoch 45 | loss: 1.03944 |  0:00:03s\n",
      "epoch 46 | loss: 1.05707 |  0:00:03s\n",
      "epoch 47 | loss: 1.01028 |  0:00:03s\n",
      "epoch 48 | loss: 1.05598 |  0:00:03s\n",
      "epoch 49 | loss: 1.06407 |  0:00:04s\n",
      "epoch 50 | loss: 1.02925 |  0:00:04s\n",
      "epoch 51 | loss: 1.00323 |  0:00:04s\n",
      "epoch 52 | loss: 1.00585 |  0:00:04s\n",
      "epoch 53 | loss: 0.94872 |  0:00:04s\n",
      "epoch 54 | loss: 1.01888 |  0:00:04s\n",
      "epoch 55 | loss: 0.99937 |  0:00:04s\n",
      "epoch 56 | loss: 1.01822 |  0:00:04s\n",
      "epoch 57 | loss: 0.97988 |  0:00:04s\n",
      "epoch 58 | loss: 0.99369 |  0:00:04s\n",
      "epoch 59 | loss: 1.0448  |  0:00:04s\n",
      "epoch 60 | loss: 0.98779 |  0:00:04s\n",
      "epoch 61 | loss: 1.008   |  0:00:05s\n",
      "epoch 62 | loss: 1.0142  |  0:00:05s\n",
      "epoch 63 | loss: 0.9561  |  0:00:05s\n",
      "epoch 64 | loss: 0.98321 |  0:00:05s\n",
      "epoch 65 | loss: 0.92529 |  0:00:05s\n",
      "epoch 66 | loss: 0.95593 |  0:00:05s\n",
      "epoch 67 | loss: 0.93135 |  0:00:05s\n",
      "epoch 68 | loss: 0.95737 |  0:00:05s\n",
      "epoch 69 | loss: 0.97406 |  0:00:05s\n",
      "epoch 70 | loss: 0.93165 |  0:00:05s\n",
      "epoch 71 | loss: 0.90708 |  0:00:05s\n",
      "epoch 72 | loss: 0.94799 |  0:00:05s\n",
      "epoch 73 | loss: 0.88457 |  0:00:06s\n",
      "epoch 74 | loss: 0.98506 |  0:00:06s\n",
      "epoch 75 | loss: 0.92306 |  0:00:06s\n",
      "epoch 76 | loss: 0.95888 |  0:00:06s\n",
      "epoch 77 | loss: 0.96737 |  0:00:06s\n",
      "epoch 78 | loss: 0.93041 |  0:00:06s\n",
      "epoch 79 | loss: 0.94636 |  0:00:06s\n",
      "epoch 80 | loss: 0.91664 |  0:00:06s\n",
      "epoch 81 | loss: 0.93731 |  0:00:06s\n",
      "epoch 82 | loss: 0.96405 |  0:00:06s\n",
      "epoch 83 | loss: 0.88915 |  0:00:06s\n",
      "epoch 84 | loss: 0.90406 |  0:00:06s\n",
      "epoch 85 | loss: 0.86765 |  0:00:07s\n",
      "epoch 86 | loss: 0.90155 |  0:00:07s\n",
      "epoch 87 | loss: 0.89951 |  0:00:07s\n",
      "epoch 88 | loss: 0.89493 |  0:00:07s\n",
      "epoch 89 | loss: 0.94505 |  0:00:07s\n",
      "epoch 90 | loss: 0.85344 |  0:00:07s\n",
      "epoch 91 | loss: 0.87247 |  0:00:07s\n",
      "epoch 92 | loss: 0.85033 |  0:00:07s\n",
      "epoch 93 | loss: 0.90242 |  0:00:07s\n",
      "epoch 94 | loss: 0.90758 |  0:00:07s\n",
      "epoch 95 | loss: 0.91055 |  0:00:07s\n",
      "epoch 96 | loss: 0.92395 |  0:00:07s\n",
      "epoch 97 | loss: 0.86891 |  0:00:08s\n",
      "epoch 98 | loss: 0.88386 |  0:00:08s\n",
      "epoch 99 | loss: 0.85492 |  0:00:08s\n",
      "epoch 100| loss: 0.87529 |  0:00:08s\n",
      "epoch 101| loss: 0.83289 |  0:00:08s\n",
      "epoch 102| loss: 0.91087 |  0:00:08s\n",
      "epoch 103| loss: 0.83118 |  0:00:08s\n",
      "epoch 104| loss: 0.87569 |  0:00:08s\n",
      "epoch 105| loss: 0.83769 |  0:00:08s\n",
      "epoch 106| loss: 0.84607 |  0:00:08s\n",
      "epoch 107| loss: 0.86526 |  0:00:08s\n",
      "epoch 108| loss: 0.88664 |  0:00:08s\n",
      "epoch 109| loss: 0.93066 |  0:00:09s\n",
      "epoch 110| loss: 0.83211 |  0:00:09s\n",
      "epoch 111| loss: 0.82425 |  0:00:09s\n",
      "epoch 112| loss: 0.81255 |  0:00:09s\n",
      "epoch 113| loss: 0.81723 |  0:00:09s\n",
      "epoch 114| loss: 0.79723 |  0:00:09s\n",
      "epoch 115| loss: 0.83576 |  0:00:09s\n",
      "epoch 116| loss: 0.8131  |  0:00:09s\n",
      "epoch 117| loss: 0.91965 |  0:00:09s\n",
      "epoch 118| loss: 0.85295 |  0:00:09s\n",
      "epoch 119| loss: 0.79225 |  0:00:09s\n",
      "epoch 120| loss: 0.81661 |  0:00:09s\n",
      "epoch 121| loss: 0.83531 |  0:00:10s\n",
      "epoch 122| loss: 0.78865 |  0:00:10s\n",
      "epoch 123| loss: 0.78032 |  0:00:10s\n",
      "epoch 124| loss: 0.86618 |  0:00:10s\n",
      "epoch 125| loss: 0.80585 |  0:00:10s\n",
      "epoch 126| loss: 0.79234 |  0:00:10s\n",
      "epoch 127| loss: 0.8198  |  0:00:10s\n",
      "epoch 128| loss: 0.81038 |  0:00:10s\n",
      "epoch 129| loss: 0.79348 |  0:00:10s\n",
      "epoch 130| loss: 0.83253 |  0:00:10s\n",
      "epoch 131| loss: 0.77896 |  0:00:10s\n",
      "epoch 132| loss: 0.82614 |  0:00:10s\n",
      "epoch 133| loss: 0.76503 |  0:00:10s\n",
      "epoch 134| loss: 0.78774 |  0:00:11s\n",
      "epoch 135| loss: 0.75639 |  0:00:11s\n",
      "epoch 136| loss: 0.74606 |  0:00:11s\n",
      "epoch 137| loss: 0.71803 |  0:00:11s\n",
      "epoch 138| loss: 0.73139 |  0:00:11s\n",
      "epoch 139| loss: 0.76566 |  0:00:11s\n",
      "epoch 140| loss: 0.67888 |  0:00:11s\n",
      "epoch 141| loss: 0.73468 |  0:00:11s\n",
      "epoch 142| loss: 0.72181 |  0:00:11s\n",
      "epoch 143| loss: 0.72028 |  0:00:11s\n",
      "epoch 144| loss: 0.78161 |  0:00:11s\n",
      "epoch 145| loss: 0.72233 |  0:00:11s\n",
      "epoch 146| loss: 0.67235 |  0:00:12s\n",
      "epoch 147| loss: 0.69633 |  0:00:12s\n",
      "epoch 148| loss: 0.7183  |  0:00:12s\n",
      "epoch 149| loss: 0.67423 |  0:00:12s\n",
      "epoch 150| loss: 0.75247 |  0:00:12s\n",
      "epoch 151| loss: 0.70598 |  0:00:12s\n",
      "epoch 152| loss: 0.69297 |  0:00:12s\n",
      "epoch 153| loss: 0.68086 |  0:00:12s\n",
      "epoch 154| loss: 0.77132 |  0:00:12s\n",
      "epoch 155| loss: 0.70389 |  0:00:12s\n",
      "epoch 156| loss: 0.71598 |  0:00:12s\n",
      "epoch 157| loss: 0.71394 |  0:00:12s\n",
      "epoch 158| loss: 0.64807 |  0:00:12s\n",
      "epoch 159| loss: 0.65968 |  0:00:13s\n",
      "epoch 160| loss: 0.75397 |  0:00:13s\n",
      "epoch 161| loss: 0.68187 |  0:00:13s\n",
      "epoch 162| loss: 0.73504 |  0:00:13s\n",
      "epoch 163| loss: 0.76537 |  0:00:13s\n",
      "epoch 164| loss: 0.67828 |  0:00:13s\n",
      "epoch 165| loss: 0.69556 |  0:00:13s\n",
      "epoch 166| loss: 0.72998 |  0:00:13s\n",
      "epoch 167| loss: 0.71388 |  0:00:13s\n",
      "epoch 168| loss: 0.69181 |  0:00:13s\n",
      "epoch 169| loss: 0.67979 |  0:00:13s\n",
      "epoch 170| loss: 0.66364 |  0:00:13s\n",
      "epoch 171| loss: 0.65323 |  0:00:14s\n",
      "epoch 172| loss: 0.71428 |  0:00:14s\n",
      "epoch 173| loss: 0.69497 |  0:00:14s\n",
      "epoch 174| loss: 0.64769 |  0:00:14s\n",
      "epoch 175| loss: 0.62441 |  0:00:14s\n",
      "epoch 176| loss: 0.66007 |  0:00:14s\n",
      "epoch 177| loss: 0.69449 |  0:00:14s\n",
      "epoch 178| loss: 0.63571 |  0:00:14s\n",
      "epoch 179| loss: 0.67434 |  0:00:14s\n",
      "epoch 180| loss: 0.66295 |  0:00:14s\n",
      "epoch 181| loss: 0.63499 |  0:00:14s\n",
      "epoch 182| loss: 0.64375 |  0:00:14s\n",
      "epoch 183| loss: 0.6022  |  0:00:15s\n",
      "epoch 184| loss: 0.67168 |  0:00:15s\n",
      "epoch 185| loss: 0.64142 |  0:00:15s\n",
      "epoch 186| loss: 0.65648 |  0:00:15s\n",
      "epoch 187| loss: 0.59341 |  0:00:15s\n",
      "epoch 188| loss: 0.60333 |  0:00:15s\n",
      "epoch 189| loss: 0.6623  |  0:00:15s\n",
      "epoch 190| loss: 0.61115 |  0:00:15s\n",
      "epoch 191| loss: 0.67598 |  0:00:15s\n",
      "epoch 192| loss: 0.64795 |  0:00:15s\n",
      "epoch 193| loss: 0.69199 |  0:00:15s\n",
      "epoch 194| loss: 0.64142 |  0:00:15s\n",
      "epoch 195| loss: 0.69879 |  0:00:16s\n",
      "epoch 196| loss: 0.63745 |  0:00:16s\n",
      "epoch 197| loss: 0.68096 |  0:00:16s\n",
      "epoch 198| loss: 0.66089 |  0:00:16s\n",
      "epoch 199| loss: 0.59625 |  0:00:16s\n",
      "XGBoost\n",
      "LGBM\n",
      "CatBoost\n",
      "RF\n",
      "GBDT\n",
      "SVR\n",
      "LR\n",
      "ANN\n",
      "TabNet\n",
      "[12:06:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "0:\tlearn: 1.3620863\ttotal: 4.12ms\tremaining: 1.64s\n",
      "1:\tlearn: 1.3298797\ttotal: 8.66ms\tremaining: 1.72s\n",
      "2:\tlearn: 1.2969266\ttotal: 12.3ms\tremaining: 1.63s\n",
      "3:\tlearn: 1.2664361\ttotal: 15.8ms\tremaining: 1.56s\n",
      "4:\tlearn: 1.2454191\ttotal: 19.2ms\tremaining: 1.52s\n",
      "5:\tlearn: 1.2253816\ttotal: 23.6ms\tremaining: 1.55s\n",
      "6:\tlearn: 1.2073006\ttotal: 27.5ms\tremaining: 1.54s\n",
      "7:\tlearn: 1.1888991\ttotal: 31.3ms\tremaining: 1.53s\n",
      "8:\tlearn: 1.1671837\ttotal: 35.1ms\tremaining: 1.53s\n",
      "9:\tlearn: 1.1489226\ttotal: 39.3ms\tremaining: 1.53s\n",
      "10:\tlearn: 1.1296149\ttotal: 43.9ms\tremaining: 1.55s\n",
      "11:\tlearn: 1.1161582\ttotal: 47.7ms\tremaining: 1.54s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:\tlearn: 1.0996084\ttotal: 52ms\tremaining: 1.55s\n",
      "13:\tlearn: 1.0828364\ttotal: 58.6ms\tremaining: 1.61s\n",
      "14:\tlearn: 1.0636048\ttotal: 62.4ms\tremaining: 1.6s\n",
      "15:\tlearn: 1.0552024\ttotal: 66.2ms\tremaining: 1.59s\n",
      "16:\tlearn: 1.0426886\ttotal: 70.7ms\tremaining: 1.59s\n",
      "17:\tlearn: 1.0265720\ttotal: 74.6ms\tremaining: 1.58s\n",
      "18:\tlearn: 1.0088848\ttotal: 78ms\tremaining: 1.56s\n",
      "19:\tlearn: 0.9972982\ttotal: 81.4ms\tremaining: 1.55s\n",
      "20:\tlearn: 0.9823573\ttotal: 85.1ms\tremaining: 1.53s\n",
      "21:\tlearn: 0.9721839\ttotal: 88.5ms\tremaining: 1.52s\n",
      "22:\tlearn: 0.9628680\ttotal: 91.5ms\tremaining: 1.5s\n",
      "23:\tlearn: 0.9493107\ttotal: 94.5ms\tremaining: 1.48s\n",
      "24:\tlearn: 0.9408032\ttotal: 97.7ms\tremaining: 1.47s\n",
      "25:\tlearn: 0.9265171\ttotal: 102ms\tremaining: 1.47s\n",
      "26:\tlearn: 0.9129324\ttotal: 106ms\tremaining: 1.47s\n",
      "27:\tlearn: 0.8997750\ttotal: 111ms\tremaining: 1.47s\n",
      "28:\tlearn: 0.8883787\ttotal: 114ms\tremaining: 1.46s\n",
      "29:\tlearn: 0.8776972\ttotal: 119ms\tremaining: 1.47s\n",
      "30:\tlearn: 0.8665832\ttotal: 124ms\tremaining: 1.47s\n",
      "31:\tlearn: 0.8582999\ttotal: 128ms\tremaining: 1.47s\n",
      "32:\tlearn: 0.8506709\ttotal: 132ms\tremaining: 1.46s\n",
      "33:\tlearn: 0.8412644\ttotal: 136ms\tremaining: 1.46s\n",
      "34:\tlearn: 0.8329307\ttotal: 140ms\tremaining: 1.46s\n",
      "35:\tlearn: 0.8219413\ttotal: 144ms\tremaining: 1.45s\n",
      "36:\tlearn: 0.8135689\ttotal: 147ms\tremaining: 1.44s\n",
      "37:\tlearn: 0.8015949\ttotal: 151ms\tremaining: 1.44s\n",
      "38:\tlearn: 0.7985861\ttotal: 153ms\tremaining: 1.41s\n",
      "39:\tlearn: 0.7901952\ttotal: 156ms\tremaining: 1.4s\n",
      "40:\tlearn: 0.7821663\ttotal: 159ms\tremaining: 1.39s\n",
      "41:\tlearn: 0.7745418\ttotal: 162ms\tremaining: 1.38s\n",
      "42:\tlearn: 0.7663636\ttotal: 167ms\tremaining: 1.39s\n",
      "43:\tlearn: 0.7608430\ttotal: 170ms\tremaining: 1.38s\n",
      "44:\tlearn: 0.7525536\ttotal: 175ms\tremaining: 1.38s\n",
      "45:\tlearn: 0.7421135\ttotal: 178ms\tremaining: 1.37s\n",
      "46:\tlearn: 0.7367147\ttotal: 182ms\tremaining: 1.37s\n",
      "47:\tlearn: 0.7249412\ttotal: 185ms\tremaining: 1.36s\n",
      "48:\tlearn: 0.7154341\ttotal: 188ms\tremaining: 1.35s\n",
      "49:\tlearn: 0.7078886\ttotal: 191ms\tremaining: 1.34s\n",
      "50:\tlearn: 0.7036411\ttotal: 194ms\tremaining: 1.33s\n",
      "51:\tlearn: 0.7005206\ttotal: 198ms\tremaining: 1.33s\n",
      "52:\tlearn: 0.6930758\ttotal: 201ms\tremaining: 1.32s\n",
      "53:\tlearn: 0.6854862\ttotal: 205ms\tremaining: 1.31s\n",
      "54:\tlearn: 0.6792380\ttotal: 208ms\tremaining: 1.3s\n",
      "55:\tlearn: 0.6731435\ttotal: 211ms\tremaining: 1.29s\n",
      "56:\tlearn: 0.6678063\ttotal: 214ms\tremaining: 1.29s\n",
      "57:\tlearn: 0.6632259\ttotal: 217ms\tremaining: 1.28s\n",
      "58:\tlearn: 0.6578313\ttotal: 220ms\tremaining: 1.27s\n",
      "59:\tlearn: 0.6504877\ttotal: 223ms\tremaining: 1.27s\n",
      "60:\tlearn: 0.6454860\ttotal: 227ms\tremaining: 1.26s\n",
      "61:\tlearn: 0.6399892\ttotal: 232ms\tremaining: 1.26s\n",
      "62:\tlearn: 0.6318963\ttotal: 235ms\tremaining: 1.26s\n",
      "63:\tlearn: 0.6290047\ttotal: 240ms\tremaining: 1.26s\n",
      "64:\tlearn: 0.6218569\ttotal: 243ms\tremaining: 1.25s\n",
      "65:\tlearn: 0.6146151\ttotal: 247ms\tremaining: 1.25s\n",
      "66:\tlearn: 0.6079030\ttotal: 251ms\tremaining: 1.25s\n",
      "67:\tlearn: 0.6016731\ttotal: 254ms\tremaining: 1.24s\n",
      "68:\tlearn: 0.5964379\ttotal: 257ms\tremaining: 1.23s\n",
      "69:\tlearn: 0.5919994\ttotal: 261ms\tremaining: 1.23s\n",
      "70:\tlearn: 0.5842046\ttotal: 265ms\tremaining: 1.23s\n",
      "71:\tlearn: 0.5803172\ttotal: 268ms\tremaining: 1.22s\n",
      "72:\tlearn: 0.5769654\ttotal: 271ms\tremaining: 1.21s\n",
      "73:\tlearn: 0.5703789\ttotal: 274ms\tremaining: 1.21s\n",
      "74:\tlearn: 0.5657230\ttotal: 278ms\tremaining: 1.2s\n",
      "75:\tlearn: 0.5596708\ttotal: 281ms\tremaining: 1.2s\n",
      "76:\tlearn: 0.5511952\ttotal: 284ms\tremaining: 1.19s\n",
      "77:\tlearn: 0.5437829\ttotal: 287ms\tremaining: 1.18s\n",
      "78:\tlearn: 0.5398127\ttotal: 290ms\tremaining: 1.18s\n",
      "79:\tlearn: 0.5369066\ttotal: 295ms\tremaining: 1.18s\n",
      "80:\tlearn: 0.5301644\ttotal: 298ms\tremaining: 1.17s\n",
      "81:\tlearn: 0.5258159\ttotal: 302ms\tremaining: 1.17s\n",
      "82:\tlearn: 0.5209068\ttotal: 307ms\tremaining: 1.17s\n",
      "83:\tlearn: 0.5141862\ttotal: 310ms\tremaining: 1.17s\n",
      "84:\tlearn: 0.5108705\ttotal: 313ms\tremaining: 1.16s\n",
      "85:\tlearn: 0.5058196\ttotal: 316ms\tremaining: 1.15s\n",
      "86:\tlearn: 0.5010974\ttotal: 319ms\tremaining: 1.15s\n",
      "87:\tlearn: 0.4973442\ttotal: 322ms\tremaining: 1.14s\n",
      "88:\tlearn: 0.4932367\ttotal: 325ms\tremaining: 1.14s\n",
      "89:\tlearn: 0.4889992\ttotal: 329ms\tremaining: 1.13s\n",
      "90:\tlearn: 0.4837149\ttotal: 332ms\tremaining: 1.13s\n",
      "91:\tlearn: 0.4766769\ttotal: 335ms\tremaining: 1.12s\n",
      "92:\tlearn: 0.4724966\ttotal: 339ms\tremaining: 1.12s\n",
      "93:\tlearn: 0.4676522\ttotal: 342ms\tremaining: 1.11s\n",
      "94:\tlearn: 0.4621800\ttotal: 345ms\tremaining: 1.11s\n",
      "95:\tlearn: 0.4580797\ttotal: 348ms\tremaining: 1.1s\n",
      "96:\tlearn: 0.4552362\ttotal: 351ms\tremaining: 1.09s\n",
      "97:\tlearn: 0.4494604\ttotal: 355ms\tremaining: 1.09s\n",
      "98:\tlearn: 0.4445892\ttotal: 359ms\tremaining: 1.09s\n",
      "99:\tlearn: 0.4406638\ttotal: 362ms\tremaining: 1.09s\n",
      "100:\tlearn: 0.4365181\ttotal: 365ms\tremaining: 1.08s\n",
      "101:\tlearn: 0.4340322\ttotal: 371ms\tremaining: 1.08s\n",
      "102:\tlearn: 0.4292940\ttotal: 375ms\tremaining: 1.08s\n",
      "103:\tlearn: 0.4254382\ttotal: 378ms\tremaining: 1.07s\n",
      "104:\tlearn: 0.4213294\ttotal: 381ms\tremaining: 1.07s\n",
      "105:\tlearn: 0.4179197\ttotal: 384ms\tremaining: 1.06s\n",
      "106:\tlearn: 0.4150817\ttotal: 388ms\tremaining: 1.06s\n",
      "107:\tlearn: 0.4105364\ttotal: 391ms\tremaining: 1.06s\n",
      "108:\tlearn: 0.4073014\ttotal: 394ms\tremaining: 1.05s\n",
      "109:\tlearn: 0.4041975\ttotal: 397ms\tremaining: 1.05s\n",
      "110:\tlearn: 0.3985548\ttotal: 400ms\tremaining: 1.04s\n",
      "111:\tlearn: 0.3943528\ttotal: 403ms\tremaining: 1.04s\n",
      "112:\tlearn: 0.3925793\ttotal: 407ms\tremaining: 1.03s\n",
      "113:\tlearn: 0.3906339\ttotal: 410ms\tremaining: 1.03s\n",
      "114:\tlearn: 0.3867654\ttotal: 413ms\tremaining: 1.02s\n",
      "115:\tlearn: 0.3834984\ttotal: 416ms\tremaining: 1.02s\n",
      "116:\tlearn: 0.3812037\ttotal: 422ms\tremaining: 1.02s\n",
      "117:\tlearn: 0.3772936\ttotal: 426ms\tremaining: 1.02s\n",
      "118:\tlearn: 0.3738493\ttotal: 429ms\tremaining: 1.01s\n",
      "119:\tlearn: 0.3705471\ttotal: 435ms\tremaining: 1.01s\n",
      "120:\tlearn: 0.3657303\ttotal: 439ms\tremaining: 1.01s\n",
      "121:\tlearn: 0.3628462\ttotal: 442ms\tremaining: 1.01s\n",
      "122:\tlearn: 0.3589651\ttotal: 446ms\tremaining: 1s\n",
      "123:\tlearn: 0.3558799\ttotal: 449ms\tremaining: 1000ms\n",
      "124:\tlearn: 0.3534679\ttotal: 453ms\tremaining: 996ms\n",
      "125:\tlearn: 0.3512510\ttotal: 456ms\tremaining: 991ms\n",
      "126:\tlearn: 0.3478437\ttotal: 459ms\tremaining: 986ms\n",
      "127:\tlearn: 0.3443988\ttotal: 462ms\tremaining: 981ms\n",
      "128:\tlearn: 0.3411783\ttotal: 465ms\tremaining: 978ms\n",
      "129:\tlearn: 0.3385972\ttotal: 469ms\tremaining: 973ms\n",
      "130:\tlearn: 0.3357890\ttotal: 472ms\tremaining: 968ms\n",
      "131:\tlearn: 0.3332554\ttotal: 475ms\tremaining: 963ms\n",
      "132:\tlearn: 0.3305027\ttotal: 478ms\tremaining: 959ms\n",
      "133:\tlearn: 0.3278546\ttotal: 481ms\tremaining: 954ms\n",
      "134:\tlearn: 0.3259619\ttotal: 484ms\tremaining: 951ms\n",
      "135:\tlearn: 0.3229341\ttotal: 488ms\tremaining: 946ms\n",
      "136:\tlearn: 0.3204372\ttotal: 491ms\tremaining: 942ms\n",
      "137:\tlearn: 0.3181968\ttotal: 494ms\tremaining: 937ms\n",
      "138:\tlearn: 0.3165361\ttotal: 497ms\tremaining: 933ms\n",
      "139:\tlearn: 0.3133402\ttotal: 500ms\tremaining: 929ms\n",
      "140:\tlearn: 0.3110544\ttotal: 503ms\tremaining: 924ms\n",
      "141:\tlearn: 0.3093101\ttotal: 507ms\tremaining: 921ms\n",
      "142:\tlearn: 0.3058578\ttotal: 510ms\tremaining: 917ms\n",
      "143:\tlearn: 0.3031955\ttotal: 514ms\tremaining: 914ms\n",
      "144:\tlearn: 0.3009799\ttotal: 518ms\tremaining: 911ms\n",
      "145:\tlearn: 0.2987062\ttotal: 523ms\tremaining: 910ms\n",
      "146:\tlearn: 0.2959624\ttotal: 526ms\tremaining: 905ms\n",
      "147:\tlearn: 0.2934734\ttotal: 530ms\tremaining: 902ms\n",
      "148:\tlearn: 0.2906528\ttotal: 533ms\tremaining: 898ms\n",
      "149:\tlearn: 0.2883568\ttotal: 536ms\tremaining: 894ms\n",
      "150:\tlearn: 0.2852304\ttotal: 539ms\tremaining: 889ms\n",
      "151:\tlearn: 0.2839583\ttotal: 542ms\tremaining: 885ms\n",
      "152:\tlearn: 0.2817431\ttotal: 546ms\tremaining: 882ms\n",
      "153:\tlearn: 0.2785594\ttotal: 549ms\tremaining: 877ms\n",
      "154:\tlearn: 0.2763358\ttotal: 552ms\tremaining: 873ms\n",
      "155:\tlearn: 0.2740300\ttotal: 555ms\tremaining: 869ms\n",
      "156:\tlearn: 0.2723414\ttotal: 558ms\tremaining: 864ms\n",
      "157:\tlearn: 0.2709022\ttotal: 563ms\tremaining: 862ms\n",
      "158:\tlearn: 0.2696102\ttotal: 566ms\tremaining: 858ms\n",
      "159:\tlearn: 0.2678041\ttotal: 569ms\tremaining: 854ms\n",
      "160:\tlearn: 0.2660915\ttotal: 573ms\tremaining: 850ms\n",
      "161:\tlearn: 0.2639607\ttotal: 578ms\tremaining: 850ms\n",
      "162:\tlearn: 0.2611613\ttotal: 582ms\tremaining: 846ms\n",
      "163:\tlearn: 0.2594474\ttotal: 585ms\tremaining: 841ms\n",
      "164:\tlearn: 0.2569969\ttotal: 588ms\tremaining: 838ms\n",
      "165:\tlearn: 0.2550347\ttotal: 591ms\tremaining: 834ms\n",
      "166:\tlearn: 0.2534405\ttotal: 595ms\tremaining: 831ms\n",
      "167:\tlearn: 0.2515240\ttotal: 599ms\tremaining: 827ms\n",
      "168:\tlearn: 0.2498384\ttotal: 602ms\tremaining: 823ms\n",
      "169:\tlearn: 0.2484236\ttotal: 605ms\tremaining: 819ms\n",
      "170:\tlearn: 0.2469366\ttotal: 609ms\tremaining: 816ms\n",
      "171:\tlearn: 0.2455041\ttotal: 613ms\tremaining: 813ms\n",
      "172:\tlearn: 0.2439743\ttotal: 617ms\tremaining: 809ms\n",
      "173:\tlearn: 0.2424836\ttotal: 620ms\tremaining: 805ms\n",
      "174:\tlearn: 0.2406044\ttotal: 623ms\tremaining: 801ms\n",
      "175:\tlearn: 0.2390859\ttotal: 627ms\tremaining: 798ms\n",
      "176:\tlearn: 0.2375696\ttotal: 631ms\tremaining: 795ms\n",
      "177:\tlearn: 0.2367452\ttotal: 634ms\tremaining: 790ms\n",
      "178:\tlearn: 0.2347889\ttotal: 638ms\tremaining: 787ms\n",
      "179:\tlearn: 0.2333424\ttotal: 643ms\tremaining: 786ms\n",
      "180:\tlearn: 0.2320713\ttotal: 646ms\tremaining: 782ms\n",
      "181:\tlearn: 0.2303556\ttotal: 649ms\tremaining: 777ms\n",
      "182:\tlearn: 0.2286633\ttotal: 652ms\tremaining: 773ms\n",
      "183:\tlearn: 0.2273203\ttotal: 655ms\tremaining: 769ms\n",
      "184:\tlearn: 0.2260113\ttotal: 658ms\tremaining: 765ms\n",
      "185:\tlearn: 0.2240674\ttotal: 661ms\tremaining: 761ms\n",
      "186:\tlearn: 0.2227036\ttotal: 664ms\tremaining: 757ms\n",
      "187:\tlearn: 0.2216076\ttotal: 667ms\tremaining: 752ms\n",
      "188:\tlearn: 0.2203890\ttotal: 670ms\tremaining: 748ms\n",
      "189:\tlearn: 0.2185938\ttotal: 674ms\tremaining: 745ms\n",
      "190:\tlearn: 0.2173134\ttotal: 677ms\tremaining: 741ms\n",
      "191:\tlearn: 0.2149561\ttotal: 680ms\tremaining: 737ms\n",
      "192:\tlearn: 0.2134641\ttotal: 683ms\tremaining: 733ms\n",
      "193:\tlearn: 0.2121870\ttotal: 686ms\tremaining: 729ms\n",
      "194:\tlearn: 0.2101750\ttotal: 691ms\tremaining: 727ms\n",
      "195:\tlearn: 0.2084887\ttotal: 695ms\tremaining: 723ms\n",
      "196:\tlearn: 0.2072508\ttotal: 698ms\tremaining: 719ms\n",
      "197:\tlearn: 0.2061052\ttotal: 701ms\tremaining: 715ms\n",
      "198:\tlearn: 0.2053699\ttotal: 707ms\tremaining: 714ms\n",
      "199:\tlearn: 0.2043185\ttotal: 710ms\tremaining: 710ms\n",
      "200:\tlearn: 0.2026861\ttotal: 713ms\tremaining: 706ms\n",
      "201:\tlearn: 0.2006888\ttotal: 716ms\tremaining: 702ms\n",
      "202:\tlearn: 0.1994893\ttotal: 719ms\tremaining: 698ms\n",
      "203:\tlearn: 0.1984461\ttotal: 722ms\tremaining: 694ms\n",
      "204:\tlearn: 0.1975539\ttotal: 725ms\tremaining: 690ms\n",
      "205:\tlearn: 0.1958793\ttotal: 728ms\tremaining: 686ms\n",
      "206:\tlearn: 0.1945936\ttotal: 732ms\tremaining: 682ms\n",
      "207:\tlearn: 0.1936465\ttotal: 735ms\tremaining: 679ms\n",
      "208:\tlearn: 0.1921224\ttotal: 738ms\tremaining: 675ms\n",
      "209:\tlearn: 0.1913435\ttotal: 742ms\tremaining: 671ms\n",
      "210:\tlearn: 0.1905239\ttotal: 745ms\tremaining: 667ms\n",
      "211:\tlearn: 0.1892932\ttotal: 748ms\tremaining: 663ms\n",
      "212:\tlearn: 0.1876835\ttotal: 751ms\tremaining: 659ms\n",
      "213:\tlearn: 0.1859460\ttotal: 755ms\tremaining: 657ms\n",
      "214:\tlearn: 0.1850014\ttotal: 759ms\tremaining: 653ms\n",
      "215:\tlearn: 0.1835066\ttotal: 762ms\tremaining: 649ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216:\tlearn: 0.1828513\ttotal: 766ms\tremaining: 646ms\n",
      "217:\tlearn: 0.1820479\ttotal: 772ms\tremaining: 645ms\n",
      "218:\tlearn: 0.1812458\ttotal: 777ms\tremaining: 642ms\n",
      "219:\tlearn: 0.1799328\ttotal: 781ms\tremaining: 639ms\n",
      "220:\tlearn: 0.1784443\ttotal: 785ms\tremaining: 636ms\n",
      "221:\tlearn: 0.1772004\ttotal: 790ms\tremaining: 633ms\n",
      "222:\tlearn: 0.1765832\ttotal: 794ms\tremaining: 630ms\n",
      "223:\tlearn: 0.1754951\ttotal: 798ms\tremaining: 627ms\n",
      "224:\tlearn: 0.1748475\ttotal: 802ms\tremaining: 623ms\n",
      "225:\tlearn: 0.1733088\ttotal: 805ms\tremaining: 620ms\n",
      "226:\tlearn: 0.1721699\ttotal: 808ms\tremaining: 616ms\n",
      "227:\tlearn: 0.1709400\ttotal: 811ms\tremaining: 612ms\n",
      "228:\tlearn: 0.1696957\ttotal: 817ms\tremaining: 610ms\n",
      "229:\tlearn: 0.1692801\ttotal: 820ms\tremaining: 606ms\n",
      "230:\tlearn: 0.1685346\ttotal: 825ms\tremaining: 604ms\n",
      "231:\tlearn: 0.1677856\ttotal: 829ms\tremaining: 600ms\n",
      "232:\tlearn: 0.1669205\ttotal: 833ms\tremaining: 597ms\n",
      "233:\tlearn: 0.1659617\ttotal: 837ms\tremaining: 594ms\n",
      "234:\tlearn: 0.1652714\ttotal: 841ms\tremaining: 591ms\n",
      "235:\tlearn: 0.1642347\ttotal: 844ms\tremaining: 587ms\n",
      "236:\tlearn: 0.1634105\ttotal: 848ms\tremaining: 583ms\n",
      "237:\tlearn: 0.1624921\ttotal: 851ms\tremaining: 579ms\n",
      "238:\tlearn: 0.1617958\ttotal: 854ms\tremaining: 575ms\n",
      "239:\tlearn: 0.1606425\ttotal: 857ms\tremaining: 572ms\n",
      "240:\tlearn: 0.1597034\ttotal: 860ms\tremaining: 568ms\n",
      "241:\tlearn: 0.1588694\ttotal: 864ms\tremaining: 564ms\n",
      "242:\tlearn: 0.1579344\ttotal: 867ms\tremaining: 560ms\n",
      "243:\tlearn: 0.1571713\ttotal: 870ms\tremaining: 556ms\n",
      "244:\tlearn: 0.1558094\ttotal: 873ms\tremaining: 553ms\n",
      "245:\tlearn: 0.1548486\ttotal: 877ms\tremaining: 549ms\n",
      "246:\tlearn: 0.1541328\ttotal: 881ms\tremaining: 546ms\n",
      "247:\tlearn: 0.1528634\ttotal: 885ms\tremaining: 542ms\n",
      "248:\tlearn: 0.1520284\ttotal: 890ms\tremaining: 539ms\n",
      "249:\tlearn: 0.1512694\ttotal: 893ms\tremaining: 536ms\n",
      "250:\tlearn: 0.1506752\ttotal: 896ms\tremaining: 532ms\n",
      "251:\tlearn: 0.1501611\ttotal: 899ms\tremaining: 528ms\n",
      "252:\tlearn: 0.1494525\ttotal: 903ms\tremaining: 524ms\n",
      "253:\tlearn: 0.1487873\ttotal: 905ms\tremaining: 520ms\n",
      "254:\tlearn: 0.1478716\ttotal: 909ms\tremaining: 517ms\n",
      "255:\tlearn: 0.1474237\ttotal: 912ms\tremaining: 513ms\n",
      "256:\tlearn: 0.1466979\ttotal: 915ms\tremaining: 509ms\n",
      "257:\tlearn: 0.1458704\ttotal: 918ms\tremaining: 506ms\n",
      "258:\tlearn: 0.1451390\ttotal: 922ms\tremaining: 502ms\n",
      "259:\tlearn: 0.1444112\ttotal: 925ms\tremaining: 498ms\n",
      "260:\tlearn: 0.1436345\ttotal: 928ms\tremaining: 494ms\n",
      "261:\tlearn: 0.1428959\ttotal: 931ms\tremaining: 490ms\n",
      "262:\tlearn: 0.1420396\ttotal: 934ms\tremaining: 487ms\n",
      "263:\tlearn: 0.1411973\ttotal: 937ms\tremaining: 483ms\n",
      "264:\tlearn: 0.1407898\ttotal: 940ms\tremaining: 479ms\n",
      "265:\tlearn: 0.1399235\ttotal: 945ms\tremaining: 476ms\n",
      "266:\tlearn: 0.1388871\ttotal: 948ms\tremaining: 472ms\n",
      "267:\tlearn: 0.1383424\ttotal: 952ms\tremaining: 469ms\n",
      "268:\tlearn: 0.1375807\ttotal: 957ms\tremaining: 466ms\n",
      "269:\tlearn: 0.1371224\ttotal: 961ms\tremaining: 463ms\n",
      "270:\tlearn: 0.1364406\ttotal: 964ms\tremaining: 459ms\n",
      "271:\tlearn: 0.1359433\ttotal: 968ms\tremaining: 455ms\n",
      "272:\tlearn: 0.1350105\ttotal: 971ms\tremaining: 452ms\n",
      "273:\tlearn: 0.1342916\ttotal: 975ms\tremaining: 448ms\n",
      "274:\tlearn: 0.1336733\ttotal: 979ms\tremaining: 445ms\n",
      "275:\tlearn: 0.1331777\ttotal: 982ms\tremaining: 441ms\n",
      "276:\tlearn: 0.1326041\ttotal: 985ms\tremaining: 437ms\n",
      "277:\tlearn: 0.1320411\ttotal: 988ms\tremaining: 434ms\n",
      "278:\tlearn: 0.1314761\ttotal: 992ms\tremaining: 430ms\n",
      "279:\tlearn: 0.1306642\ttotal: 995ms\tremaining: 426ms\n",
      "280:\tlearn: 0.1299311\ttotal: 998ms\tremaining: 423ms\n",
      "281:\tlearn: 0.1293452\ttotal: 1s\tremaining: 419ms\n",
      "282:\tlearn: 0.1286391\ttotal: 1s\tremaining: 415ms\n",
      "283:\tlearn: 0.1278729\ttotal: 1.01s\tremaining: 412ms\n",
      "284:\tlearn: 0.1273440\ttotal: 1.01s\tremaining: 408ms\n",
      "285:\tlearn: 0.1266123\ttotal: 1.01s\tremaining: 405ms\n",
      "286:\tlearn: 0.1261458\ttotal: 1.02s\tremaining: 402ms\n",
      "287:\tlearn: 0.1256154\ttotal: 1.02s\tremaining: 398ms\n",
      "288:\tlearn: 0.1248092\ttotal: 1.03s\tremaining: 395ms\n",
      "289:\tlearn: 0.1241412\ttotal: 1.03s\tremaining: 391ms\n",
      "290:\tlearn: 0.1233853\ttotal: 1.03s\tremaining: 387ms\n",
      "291:\tlearn: 0.1228021\ttotal: 1.04s\tremaining: 384ms\n",
      "292:\tlearn: 0.1220750\ttotal: 1.04s\tremaining: 380ms\n",
      "293:\tlearn: 0.1216733\ttotal: 1.04s\tremaining: 376ms\n",
      "294:\tlearn: 0.1213757\ttotal: 1.05s\tremaining: 372ms\n",
      "295:\tlearn: 0.1205808\ttotal: 1.05s\tremaining: 369ms\n",
      "296:\tlearn: 0.1199424\ttotal: 1.05s\tremaining: 365ms\n",
      "297:\tlearn: 0.1194824\ttotal: 1.05s\tremaining: 361ms\n",
      "298:\tlearn: 0.1190057\ttotal: 1.06s\tremaining: 358ms\n",
      "299:\tlearn: 0.1185738\ttotal: 1.06s\tremaining: 354ms\n",
      "300:\tlearn: 0.1179465\ttotal: 1.06s\tremaining: 350ms\n",
      "301:\tlearn: 0.1172007\ttotal: 1.07s\tremaining: 347ms\n",
      "302:\tlearn: 0.1167334\ttotal: 1.07s\tremaining: 343ms\n",
      "303:\tlearn: 0.1162631\ttotal: 1.07s\tremaining: 339ms\n",
      "304:\tlearn: 0.1157981\ttotal: 1.08s\tremaining: 336ms\n",
      "305:\tlearn: 0.1152136\ttotal: 1.08s\tremaining: 333ms\n",
      "306:\tlearn: 0.1150516\ttotal: 1.09s\tremaining: 329ms\n",
      "307:\tlearn: 0.1146730\ttotal: 1.09s\tremaining: 325ms\n",
      "308:\tlearn: 0.1139719\ttotal: 1.09s\tremaining: 322ms\n",
      "309:\tlearn: 0.1134650\ttotal: 1.09s\tremaining: 318ms\n",
      "310:\tlearn: 0.1128752\ttotal: 1.1s\tremaining: 314ms\n",
      "311:\tlearn: 0.1123998\ttotal: 1.1s\tremaining: 311ms\n",
      "312:\tlearn: 0.1118989\ttotal: 1.1s\tremaining: 307ms\n",
      "313:\tlearn: 0.1113316\ttotal: 1.11s\tremaining: 303ms\n",
      "314:\tlearn: 0.1109484\ttotal: 1.11s\tremaining: 300ms\n",
      "315:\tlearn: 0.1102135\ttotal: 1.11s\tremaining: 296ms\n",
      "316:\tlearn: 0.1098041\ttotal: 1.12s\tremaining: 293ms\n",
      "317:\tlearn: 0.1092113\ttotal: 1.12s\tremaining: 289ms\n",
      "318:\tlearn: 0.1087346\ttotal: 1.12s\tremaining: 286ms\n",
      "319:\tlearn: 0.1083505\ttotal: 1.13s\tremaining: 282ms\n",
      "320:\tlearn: 0.1079742\ttotal: 1.13s\tremaining: 278ms\n",
      "321:\tlearn: 0.1075143\ttotal: 1.14s\tremaining: 275ms\n",
      "322:\tlearn: 0.1069503\ttotal: 1.14s\tremaining: 272ms\n",
      "323:\tlearn: 0.1065030\ttotal: 1.14s\tremaining: 268ms\n",
      "324:\tlearn: 0.1061688\ttotal: 1.15s\tremaining: 265ms\n",
      "325:\tlearn: 0.1059697\ttotal: 1.15s\tremaining: 262ms\n",
      "326:\tlearn: 0.1056390\ttotal: 1.16s\tremaining: 258ms\n",
      "327:\tlearn: 0.1051309\ttotal: 1.16s\tremaining: 255ms\n",
      "328:\tlearn: 0.1045993\ttotal: 1.16s\tremaining: 251ms\n",
      "329:\tlearn: 0.1039966\ttotal: 1.17s\tremaining: 247ms\n",
      "330:\tlearn: 0.1036788\ttotal: 1.17s\tremaining: 244ms\n",
      "331:\tlearn: 0.1032188\ttotal: 1.17s\tremaining: 240ms\n",
      "332:\tlearn: 0.1025963\ttotal: 1.18s\tremaining: 237ms\n",
      "333:\tlearn: 0.1018875\ttotal: 1.18s\tremaining: 233ms\n",
      "334:\tlearn: 0.1014875\ttotal: 1.18s\tremaining: 229ms\n",
      "335:\tlearn: 0.1009458\ttotal: 1.19s\tremaining: 226ms\n",
      "336:\tlearn: 0.1005433\ttotal: 1.19s\tremaining: 222ms\n",
      "337:\tlearn: 0.1001328\ttotal: 1.19s\tremaining: 219ms\n",
      "338:\tlearn: 0.0996732\ttotal: 1.19s\tremaining: 215ms\n",
      "339:\tlearn: 0.0991841\ttotal: 1.2s\tremaining: 212ms\n",
      "340:\tlearn: 0.0987047\ttotal: 1.2s\tremaining: 208ms\n",
      "341:\tlearn: 0.0982375\ttotal: 1.21s\tremaining: 204ms\n",
      "342:\tlearn: 0.0979373\ttotal: 1.21s\tremaining: 201ms\n",
      "343:\tlearn: 0.0976517\ttotal: 1.22s\tremaining: 198ms\n",
      "344:\tlearn: 0.0971683\ttotal: 1.22s\tremaining: 194ms\n",
      "345:\tlearn: 0.0969868\ttotal: 1.22s\tremaining: 191ms\n",
      "346:\tlearn: 0.0965600\ttotal: 1.22s\tremaining: 187ms\n",
      "347:\tlearn: 0.0962631\ttotal: 1.23s\tremaining: 183ms\n",
      "348:\tlearn: 0.0960060\ttotal: 1.23s\tremaining: 180ms\n",
      "349:\tlearn: 0.0956965\ttotal: 1.23s\tremaining: 176ms\n",
      "350:\tlearn: 0.0952497\ttotal: 1.24s\tremaining: 173ms\n",
      "351:\tlearn: 0.0949991\ttotal: 1.24s\tremaining: 169ms\n",
      "352:\tlearn: 0.0947744\ttotal: 1.24s\tremaining: 166ms\n",
      "353:\tlearn: 0.0944683\ttotal: 1.25s\tremaining: 162ms\n",
      "354:\tlearn: 0.0941699\ttotal: 1.25s\tremaining: 158ms\n",
      "355:\tlearn: 0.0939260\ttotal: 1.25s\tremaining: 155ms\n",
      "356:\tlearn: 0.0935590\ttotal: 1.26s\tremaining: 151ms\n",
      "357:\tlearn: 0.0930887\ttotal: 1.26s\tremaining: 148ms\n",
      "358:\tlearn: 0.0928543\ttotal: 1.26s\tremaining: 144ms\n",
      "359:\tlearn: 0.0926130\ttotal: 1.27s\tremaining: 141ms\n",
      "360:\tlearn: 0.0923473\ttotal: 1.27s\tremaining: 137ms\n",
      "361:\tlearn: 0.0920257\ttotal: 1.27s\tremaining: 134ms\n",
      "362:\tlearn: 0.0917659\ttotal: 1.28s\tremaining: 130ms\n",
      "363:\tlearn: 0.0913203\ttotal: 1.28s\tremaining: 127ms\n",
      "364:\tlearn: 0.0909792\ttotal: 1.28s\tremaining: 123ms\n",
      "365:\tlearn: 0.0908384\ttotal: 1.29s\tremaining: 120ms\n",
      "366:\tlearn: 0.0905831\ttotal: 1.29s\tremaining: 116ms\n",
      "367:\tlearn: 0.0901465\ttotal: 1.29s\tremaining: 113ms\n",
      "368:\tlearn: 0.0898176\ttotal: 1.3s\tremaining: 109ms\n",
      "369:\tlearn: 0.0895113\ttotal: 1.3s\tremaining: 106ms\n",
      "370:\tlearn: 0.0891601\ttotal: 1.3s\tremaining: 102ms\n",
      "371:\tlearn: 0.0886991\ttotal: 1.31s\tremaining: 98.5ms\n",
      "372:\tlearn: 0.0884153\ttotal: 1.31s\tremaining: 95ms\n",
      "373:\tlearn: 0.0879452\ttotal: 1.31s\tremaining: 91.5ms\n",
      "374:\tlearn: 0.0877329\ttotal: 1.32s\tremaining: 87.9ms\n",
      "375:\tlearn: 0.0873295\ttotal: 1.32s\tremaining: 84.4ms\n",
      "376:\tlearn: 0.0870621\ttotal: 1.33s\tremaining: 81ms\n",
      "377:\tlearn: 0.0869195\ttotal: 1.33s\tremaining: 77.4ms\n",
      "378:\tlearn: 0.0867134\ttotal: 1.33s\tremaining: 73.9ms\n",
      "379:\tlearn: 0.0865278\ttotal: 1.34s\tremaining: 70.4ms\n",
      "380:\tlearn: 0.0862238\ttotal: 1.34s\tremaining: 67ms\n",
      "381:\tlearn: 0.0858743\ttotal: 1.35s\tremaining: 63.4ms\n",
      "382:\tlearn: 0.0854773\ttotal: 1.35s\tremaining: 59.9ms\n",
      "383:\tlearn: 0.0851065\ttotal: 1.35s\tremaining: 56.3ms\n",
      "384:\tlearn: 0.0846651\ttotal: 1.36s\tremaining: 52.8ms\n",
      "385:\tlearn: 0.0841554\ttotal: 1.36s\tremaining: 49.3ms\n",
      "386:\tlearn: 0.0838188\ttotal: 1.36s\tremaining: 45.8ms\n",
      "387:\tlearn: 0.0836200\ttotal: 1.36s\tremaining: 42.2ms\n",
      "388:\tlearn: 0.0832262\ttotal: 1.37s\tremaining: 38.7ms\n",
      "389:\tlearn: 0.0830044\ttotal: 1.37s\tremaining: 35.2ms\n",
      "390:\tlearn: 0.0827437\ttotal: 1.37s\tremaining: 31.6ms\n",
      "391:\tlearn: 0.0824900\ttotal: 1.38s\tremaining: 28.1ms\n",
      "392:\tlearn: 0.0823022\ttotal: 1.38s\tremaining: 24.6ms\n",
      "393:\tlearn: 0.0820218\ttotal: 1.38s\tremaining: 21.1ms\n",
      "394:\tlearn: 0.0817299\ttotal: 1.39s\tremaining: 17.6ms\n",
      "395:\tlearn: 0.0813765\ttotal: 1.39s\tremaining: 14.1ms\n",
      "396:\tlearn: 0.0811325\ttotal: 1.4s\tremaining: 10.5ms\n",
      "397:\tlearn: 0.0809262\ttotal: 1.4s\tremaining: 7.04ms\n",
      "398:\tlearn: 0.0806453\ttotal: 1.4s\tremaining: 3.52ms\n",
      "399:\tlearn: 0.0804520\ttotal: 1.41s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.88479 |  0:00:00s\n",
      "epoch 1  | loss: 1.56658 |  0:00:00s\n",
      "epoch 2  | loss: 1.45543 |  0:00:00s\n",
      "epoch 3  | loss: 1.42973 |  0:00:00s\n",
      "epoch 4  | loss: 1.39428 |  0:00:00s\n",
      "epoch 5  | loss: 1.37443 |  0:00:00s\n",
      "epoch 6  | loss: 1.31041 |  0:00:00s\n",
      "epoch 7  | loss: 1.34905 |  0:00:00s\n",
      "epoch 8  | loss: 1.35275 |  0:00:00s\n",
      "epoch 9  | loss: 1.34232 |  0:00:00s\n",
      "epoch 10 | loss: 1.33529 |  0:00:00s\n",
      "epoch 11 | loss: 1.32465 |  0:00:00s\n",
      "epoch 12 | loss: 1.31009 |  0:00:01s\n",
      "epoch 13 | loss: 1.2733  |  0:00:01s\n",
      "epoch 14 | loss: 1.25294 |  0:00:01s\n",
      "epoch 15 | loss: 1.25745 |  0:00:01s\n",
      "epoch 16 | loss: 1.23611 |  0:00:01s\n",
      "epoch 17 | loss: 1.20471 |  0:00:01s\n",
      "epoch 18 | loss: 1.19946 |  0:00:01s\n",
      "epoch 19 | loss: 1.23177 |  0:00:01s\n",
      "epoch 20 | loss: 1.19483 |  0:00:01s\n",
      "epoch 21 | loss: 1.20145 |  0:00:01s\n",
      "epoch 22 | loss: 1.1796  |  0:00:01s\n",
      "epoch 23 | loss: 1.21884 |  0:00:01s\n",
      "epoch 24 | loss: 1.17203 |  0:00:02s\n",
      "epoch 25 | loss: 1.18085 |  0:00:02s\n",
      "epoch 26 | loss: 1.12601 |  0:00:02s\n",
      "epoch 27 | loss: 1.13731 |  0:00:02s\n",
      "epoch 28 | loss: 1.16265 |  0:00:02s\n",
      "epoch 29 | loss: 1.14352 |  0:00:02s\n",
      "epoch 30 | loss: 1.13445 |  0:00:02s\n",
      "epoch 31 | loss: 1.14256 |  0:00:02s\n",
      "epoch 32 | loss: 1.10742 |  0:00:02s\n",
      "epoch 33 | loss: 1.14132 |  0:00:02s\n",
      "epoch 34 | loss: 1.10526 |  0:00:02s\n",
      "epoch 35 | loss: 1.08829 |  0:00:02s\n",
      "epoch 36 | loss: 1.08102 |  0:00:03s\n",
      "epoch 37 | loss: 1.11768 |  0:00:03s\n",
      "epoch 38 | loss: 1.0917  |  0:00:03s\n",
      "epoch 39 | loss: 1.09245 |  0:00:03s\n",
      "epoch 40 | loss: 1.09669 |  0:00:03s\n",
      "epoch 41 | loss: 1.12114 |  0:00:03s\n",
      "epoch 42 | loss: 1.09193 |  0:00:03s\n",
      "epoch 43 | loss: 1.08278 |  0:00:03s\n",
      "epoch 44 | loss: 1.07562 |  0:00:03s\n",
      "epoch 45 | loss: 1.09251 |  0:00:03s\n",
      "epoch 46 | loss: 1.09147 |  0:00:03s\n",
      "epoch 47 | loss: 1.10072 |  0:00:04s\n",
      "epoch 48 | loss: 1.06174 |  0:00:04s\n",
      "epoch 49 | loss: 1.04388 |  0:00:04s\n",
      "epoch 50 | loss: 1.04483 |  0:00:04s\n",
      "epoch 51 | loss: 1.06657 |  0:00:04s\n",
      "epoch 52 | loss: 1.05324 |  0:00:04s\n",
      "epoch 53 | loss: 1.05006 |  0:00:04s\n",
      "epoch 54 | loss: 1.04448 |  0:00:04s\n",
      "epoch 55 | loss: 1.01044 |  0:00:04s\n",
      "epoch 56 | loss: 1.04157 |  0:00:04s\n",
      "epoch 57 | loss: 1.02593 |  0:00:04s\n",
      "epoch 58 | loss: 1.03515 |  0:00:04s\n",
      "epoch 59 | loss: 1.04304 |  0:00:05s\n",
      "epoch 60 | loss: 1.04295 |  0:00:05s\n",
      "epoch 61 | loss: 1.01118 |  0:00:05s\n",
      "epoch 62 | loss: 1.02573 |  0:00:05s\n",
      "epoch 63 | loss: 1.00845 |  0:00:05s\n",
      "epoch 64 | loss: 0.96507 |  0:00:05s\n",
      "epoch 65 | loss: 1.02261 |  0:00:05s\n",
      "epoch 66 | loss: 1.01932 |  0:00:05s\n",
      "epoch 67 | loss: 0.9828  |  0:00:05s\n",
      "epoch 68 | loss: 0.97009 |  0:00:05s\n",
      "epoch 69 | loss: 1.02408 |  0:00:05s\n",
      "epoch 70 | loss: 0.96545 |  0:00:05s\n",
      "epoch 71 | loss: 0.99216 |  0:00:06s\n",
      "epoch 72 | loss: 0.98007 |  0:00:06s\n",
      "epoch 73 | loss: 0.90874 |  0:00:06s\n",
      "epoch 74 | loss: 0.95237 |  0:00:06s\n",
      "epoch 75 | loss: 0.95191 |  0:00:06s\n",
      "epoch 76 | loss: 0.95081 |  0:00:06s\n",
      "epoch 77 | loss: 0.92861 |  0:00:06s\n",
      "epoch 78 | loss: 0.92009 |  0:00:06s\n",
      "epoch 79 | loss: 0.93715 |  0:00:06s\n",
      "epoch 80 | loss: 0.96135 |  0:00:06s\n",
      "epoch 81 | loss: 0.94054 |  0:00:06s\n",
      "epoch 82 | loss: 0.95331 |  0:00:06s\n",
      "epoch 83 | loss: 0.95888 |  0:00:07s\n",
      "epoch 84 | loss: 0.91159 |  0:00:07s\n",
      "epoch 85 | loss: 0.87541 |  0:00:07s\n",
      "epoch 86 | loss: 0.96824 |  0:00:07s\n",
      "epoch 87 | loss: 0.93402 |  0:00:07s\n",
      "epoch 88 | loss: 0.89693 |  0:00:07s\n",
      "epoch 89 | loss: 0.91853 |  0:00:07s\n",
      "epoch 90 | loss: 0.89359 |  0:00:07s\n",
      "epoch 91 | loss: 0.90404 |  0:00:07s\n",
      "epoch 92 | loss: 0.91405 |  0:00:07s\n",
      "epoch 93 | loss: 0.91937 |  0:00:07s\n",
      "epoch 94 | loss: 0.85167 |  0:00:07s\n",
      "epoch 95 | loss: 0.90403 |  0:00:08s\n",
      "epoch 96 | loss: 0.91558 |  0:00:08s\n",
      "epoch 97 | loss: 0.88095 |  0:00:08s\n",
      "epoch 98 | loss: 0.89902 |  0:00:08s\n",
      "epoch 99 | loss: 0.92516 |  0:00:08s\n",
      "epoch 100| loss: 0.88848 |  0:00:08s\n",
      "epoch 101| loss: 0.8743  |  0:00:08s\n",
      "epoch 102| loss: 0.8887  |  0:00:08s\n",
      "epoch 103| loss: 0.90662 |  0:00:08s\n",
      "epoch 104| loss: 0.85534 |  0:00:08s\n",
      "epoch 105| loss: 0.83794 |  0:00:08s\n",
      "epoch 106| loss: 0.83735 |  0:00:08s\n",
      "epoch 107| loss: 0.83816 |  0:00:09s\n",
      "epoch 108| loss: 0.85431 |  0:00:09s\n",
      "epoch 109| loss: 0.81471 |  0:00:09s\n",
      "epoch 110| loss: 0.85561 |  0:00:09s\n",
      "epoch 111| loss: 0.8372  |  0:00:09s\n",
      "epoch 112| loss: 0.88123 |  0:00:09s\n",
      "epoch 113| loss: 0.85155 |  0:00:09s\n",
      "epoch 114| loss: 0.87459 |  0:00:09s\n",
      "epoch 115| loss: 0.83261 |  0:00:09s\n",
      "epoch 116| loss: 0.84155 |  0:00:09s\n",
      "epoch 117| loss: 0.80389 |  0:00:09s\n",
      "epoch 118| loss: 0.78779 |  0:00:10s\n",
      "epoch 119| loss: 0.86239 |  0:00:10s\n",
      "epoch 120| loss: 0.84275 |  0:00:10s\n",
      "epoch 121| loss: 0.79713 |  0:00:10s\n",
      "epoch 122| loss: 0.78739 |  0:00:10s\n",
      "epoch 123| loss: 0.83475 |  0:00:10s\n",
      "epoch 124| loss: 0.8037  |  0:00:10s\n",
      "epoch 125| loss: 0.83864 |  0:00:10s\n",
      "epoch 126| loss: 0.8484  |  0:00:10s\n",
      "epoch 127| loss: 0.81792 |  0:00:10s\n",
      "epoch 128| loss: 0.86108 |  0:00:10s\n",
      "epoch 129| loss: 0.86172 |  0:00:10s\n",
      "epoch 130| loss: 0.8295  |  0:00:10s\n",
      "epoch 131| loss: 0.86196 |  0:00:11s\n",
      "epoch 132| loss: 0.80733 |  0:00:11s\n",
      "epoch 133| loss: 0.82238 |  0:00:11s\n",
      "epoch 134| loss: 0.77882 |  0:00:11s\n",
      "epoch 135| loss: 0.80848 |  0:00:11s\n",
      "epoch 136| loss: 0.80318 |  0:00:11s\n",
      "epoch 137| loss: 0.77394 |  0:00:11s\n",
      "epoch 138| loss: 0.73089 |  0:00:11s\n",
      "epoch 139| loss: 0.77028 |  0:00:11s\n",
      "epoch 140| loss: 0.75351 |  0:00:11s\n",
      "epoch 141| loss: 0.718   |  0:00:11s\n",
      "epoch 142| loss: 0.79064 |  0:00:11s\n",
      "epoch 143| loss: 0.8018  |  0:00:12s\n",
      "epoch 144| loss: 0.8189  |  0:00:12s\n",
      "epoch 145| loss: 0.77934 |  0:00:12s\n",
      "epoch 146| loss: 0.77627 |  0:00:12s\n",
      "epoch 147| loss: 0.79344 |  0:00:12s\n",
      "epoch 148| loss: 0.7773  |  0:00:12s\n",
      "epoch 149| loss: 0.72592 |  0:00:12s\n",
      "epoch 150| loss: 0.7514  |  0:00:12s\n",
      "epoch 151| loss: 0.75064 |  0:00:12s\n",
      "epoch 152| loss: 0.74078 |  0:00:12s\n",
      "epoch 153| loss: 0.75852 |  0:00:12s\n",
      "epoch 154| loss: 0.72749 |  0:00:12s\n",
      "epoch 155| loss: 0.77498 |  0:00:13s\n",
      "epoch 156| loss: 0.71091 |  0:00:13s\n",
      "epoch 157| loss: 0.73318 |  0:00:13s\n",
      "epoch 158| loss: 0.72823 |  0:00:13s\n",
      "epoch 159| loss: 0.72182 |  0:00:13s\n",
      "epoch 160| loss: 0.7284  |  0:00:13s\n",
      "epoch 161| loss: 0.75343 |  0:00:13s\n",
      "epoch 162| loss: 0.79904 |  0:00:13s\n",
      "epoch 163| loss: 0.81273 |  0:00:13s\n",
      "epoch 164| loss: 0.72406 |  0:00:13s\n",
      "epoch 165| loss: 0.72597 |  0:00:13s\n",
      "epoch 166| loss: 0.70121 |  0:00:13s\n",
      "epoch 167| loss: 0.76347 |  0:00:14s\n",
      "epoch 168| loss: 0.66202 |  0:00:14s\n",
      "epoch 169| loss: 0.6685  |  0:00:14s\n",
      "epoch 170| loss: 0.72474 |  0:00:14s\n",
      "epoch 171| loss: 0.75119 |  0:00:14s\n",
      "epoch 172| loss: 0.72086 |  0:00:14s\n",
      "epoch 173| loss: 0.74203 |  0:00:14s\n",
      "epoch 174| loss: 0.69707 |  0:00:14s\n",
      "epoch 175| loss: 0.68127 |  0:00:14s\n",
      "epoch 176| loss: 0.71631 |  0:00:14s\n",
      "epoch 177| loss: 0.69591 |  0:00:14s\n",
      "epoch 178| loss: 0.70628 |  0:00:14s\n",
      "epoch 179| loss: 0.63775 |  0:00:15s\n",
      "epoch 180| loss: 0.67637 |  0:00:15s\n",
      "epoch 181| loss: 0.67459 |  0:00:15s\n",
      "epoch 182| loss: 0.76097 |  0:00:15s\n",
      "epoch 183| loss: 0.70908 |  0:00:15s\n",
      "epoch 184| loss: 0.70768 |  0:00:15s\n",
      "epoch 185| loss: 0.69112 |  0:00:15s\n",
      "epoch 186| loss: 0.69458 |  0:00:15s\n",
      "epoch 187| loss: 0.6834  |  0:00:15s\n",
      "epoch 188| loss: 0.70778 |  0:00:15s\n",
      "epoch 189| loss: 0.68355 |  0:00:15s\n",
      "epoch 190| loss: 0.72032 |  0:00:15s\n",
      "epoch 191| loss: 0.67406 |  0:00:16s\n",
      "epoch 192| loss: 0.64853 |  0:00:16s\n",
      "epoch 193| loss: 0.69485 |  0:00:16s\n",
      "epoch 194| loss: 0.71713 |  0:00:16s\n",
      "epoch 195| loss: 0.67813 |  0:00:16s\n",
      "epoch 196| loss: 0.6363  |  0:00:16s\n",
      "epoch 197| loss: 0.64159 |  0:00:16s\n",
      "epoch 198| loss: 0.66644 |  0:00:16s\n",
      "epoch 199| loss: 0.62699 |  0:00:16s\n",
      "XGBoost\n",
      "LGBM\n",
      "CatBoost\n",
      "RF\n",
      "GBDT\n",
      "SVR\n",
      "LR\n",
      "ANN\n",
      "TabNet\n",
      "[12:07:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "0:\tlearn: 1.3565284\ttotal: 8.47ms\tremaining: 3.38s\n",
      "1:\tlearn: 1.3299089\ttotal: 12.6ms\tremaining: 2.5s\n",
      "2:\tlearn: 1.3012595\ttotal: 16.4ms\tremaining: 2.17s\n",
      "3:\tlearn: 1.2750668\ttotal: 20.4ms\tremaining: 2.02s\n",
      "4:\tlearn: 1.2479481\ttotal: 24.8ms\tremaining: 1.96s\n",
      "5:\tlearn: 1.2233134\ttotal: 28.9ms\tremaining: 1.9s\n",
      "6:\tlearn: 1.2021076\ttotal: 33ms\tremaining: 1.85s\n",
      "7:\tlearn: 1.1825096\ttotal: 38.7ms\tremaining: 1.9s\n",
      "8:\tlearn: 1.1594122\ttotal: 42.7ms\tremaining: 1.85s\n",
      "9:\tlearn: 1.1410576\ttotal: 46.7ms\tremaining: 1.82s\n",
      "10:\tlearn: 1.1228305\ttotal: 50.2ms\tremaining: 1.77s\n",
      "11:\tlearn: 1.1058001\ttotal: 54.3ms\tremaining: 1.75s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:\tlearn: 1.0900870\ttotal: 58.9ms\tremaining: 1.75s\n",
      "13:\tlearn: 1.0710292\ttotal: 62.5ms\tremaining: 1.72s\n",
      "14:\tlearn: 1.0559259\ttotal: 66.2ms\tremaining: 1.7s\n",
      "15:\tlearn: 1.0462930\ttotal: 69.9ms\tremaining: 1.68s\n",
      "16:\tlearn: 1.0337405\ttotal: 73.6ms\tremaining: 1.66s\n",
      "17:\tlearn: 1.0180668\ttotal: 76.9ms\tremaining: 1.63s\n",
      "18:\tlearn: 1.0011471\ttotal: 80.4ms\tremaining: 1.61s\n",
      "19:\tlearn: 0.9879225\ttotal: 83.9ms\tremaining: 1.59s\n",
      "20:\tlearn: 0.9756952\ttotal: 88.1ms\tremaining: 1.59s\n",
      "21:\tlearn: 0.9650530\ttotal: 91.5ms\tremaining: 1.57s\n",
      "22:\tlearn: 0.9538666\ttotal: 94.8ms\tremaining: 1.55s\n",
      "23:\tlearn: 0.9415274\ttotal: 99.1ms\tremaining: 1.55s\n",
      "24:\tlearn: 0.9316383\ttotal: 104ms\tremaining: 1.56s\n",
      "25:\tlearn: 0.9194394\ttotal: 107ms\tremaining: 1.54s\n",
      "26:\tlearn: 0.9081129\ttotal: 110ms\tremaining: 1.52s\n",
      "27:\tlearn: 0.8974975\ttotal: 115ms\tremaining: 1.53s\n",
      "28:\tlearn: 0.8859822\ttotal: 119ms\tremaining: 1.53s\n",
      "29:\tlearn: 0.8760175\ttotal: 123ms\tremaining: 1.51s\n",
      "30:\tlearn: 0.8660445\ttotal: 126ms\tremaining: 1.5s\n",
      "31:\tlearn: 0.8575177\ttotal: 129ms\tremaining: 1.48s\n",
      "32:\tlearn: 0.8498020\ttotal: 132ms\tremaining: 1.47s\n",
      "33:\tlearn: 0.8384473\ttotal: 136ms\tremaining: 1.46s\n",
      "34:\tlearn: 0.8314112\ttotal: 139ms\tremaining: 1.45s\n",
      "35:\tlearn: 0.8232039\ttotal: 142ms\tremaining: 1.44s\n",
      "36:\tlearn: 0.8152455\ttotal: 145ms\tremaining: 1.42s\n",
      "37:\tlearn: 0.8045980\ttotal: 148ms\tremaining: 1.41s\n",
      "38:\tlearn: 0.8026300\ttotal: 150ms\tremaining: 1.39s\n",
      "39:\tlearn: 0.7961349\ttotal: 153ms\tremaining: 1.38s\n",
      "40:\tlearn: 0.7861429\ttotal: 156ms\tremaining: 1.37s\n",
      "41:\tlearn: 0.7784827\ttotal: 159ms\tremaining: 1.35s\n",
      "42:\tlearn: 0.7703100\ttotal: 163ms\tremaining: 1.35s\n",
      "43:\tlearn: 0.7629428\ttotal: 167ms\tremaining: 1.35s\n",
      "44:\tlearn: 0.7560264\ttotal: 171ms\tremaining: 1.34s\n",
      "45:\tlearn: 0.7459000\ttotal: 174ms\tremaining: 1.33s\n",
      "46:\tlearn: 0.7382315\ttotal: 178ms\tremaining: 1.34s\n",
      "47:\tlearn: 0.7317793\ttotal: 183ms\tremaining: 1.34s\n",
      "48:\tlearn: 0.7218937\ttotal: 186ms\tremaining: 1.33s\n",
      "49:\tlearn: 0.7160132\ttotal: 189ms\tremaining: 1.32s\n",
      "50:\tlearn: 0.7101896\ttotal: 192ms\tremaining: 1.31s\n",
      "51:\tlearn: 0.7001497\ttotal: 195ms\tremaining: 1.3s\n",
      "52:\tlearn: 0.6938950\ttotal: 199ms\tremaining: 1.3s\n",
      "53:\tlearn: 0.6846415\ttotal: 202ms\tremaining: 1.29s\n",
      "54:\tlearn: 0.6769142\ttotal: 205ms\tremaining: 1.28s\n",
      "55:\tlearn: 0.6696063\ttotal: 208ms\tremaining: 1.28s\n",
      "56:\tlearn: 0.6617699\ttotal: 211ms\tremaining: 1.27s\n",
      "57:\tlearn: 0.6574330\ttotal: 215ms\tremaining: 1.26s\n",
      "58:\tlearn: 0.6509733\ttotal: 218ms\tremaining: 1.26s\n",
      "59:\tlearn: 0.6449199\ttotal: 221ms\tremaining: 1.25s\n",
      "60:\tlearn: 0.6374892\ttotal: 224ms\tremaining: 1.24s\n",
      "61:\tlearn: 0.6332730\ttotal: 227ms\tremaining: 1.24s\n",
      "62:\tlearn: 0.6271306\ttotal: 231ms\tremaining: 1.24s\n",
      "63:\tlearn: 0.6211398\ttotal: 235ms\tremaining: 1.23s\n",
      "64:\tlearn: 0.6134809\ttotal: 238ms\tremaining: 1.23s\n",
      "65:\tlearn: 0.6063793\ttotal: 241ms\tremaining: 1.22s\n",
      "66:\tlearn: 0.6006465\ttotal: 245ms\tremaining: 1.22s\n",
      "67:\tlearn: 0.5946271\ttotal: 248ms\tremaining: 1.21s\n",
      "68:\tlearn: 0.5889671\ttotal: 253ms\tremaining: 1.21s\n",
      "69:\tlearn: 0.5810065\ttotal: 256ms\tremaining: 1.21s\n",
      "70:\tlearn: 0.5773854\ttotal: 260ms\tremaining: 1.2s\n",
      "71:\tlearn: 0.5737567\ttotal: 264ms\tremaining: 1.2s\n",
      "72:\tlearn: 0.5683333\ttotal: 269ms\tremaining: 1.2s\n",
      "73:\tlearn: 0.5622706\ttotal: 273ms\tremaining: 1.2s\n",
      "74:\tlearn: 0.5583585\ttotal: 276ms\tremaining: 1.2s\n",
      "75:\tlearn: 0.5525548\ttotal: 279ms\tremaining: 1.19s\n",
      "76:\tlearn: 0.5496634\ttotal: 282ms\tremaining: 1.18s\n",
      "77:\tlearn: 0.5463085\ttotal: 285ms\tremaining: 1.18s\n",
      "78:\tlearn: 0.5433643\ttotal: 288ms\tremaining: 1.17s\n",
      "79:\tlearn: 0.5385050\ttotal: 291ms\tremaining: 1.17s\n",
      "80:\tlearn: 0.5342810\ttotal: 294ms\tremaining: 1.16s\n",
      "81:\tlearn: 0.5292145\ttotal: 298ms\tremaining: 1.15s\n",
      "82:\tlearn: 0.5259386\ttotal: 301ms\tremaining: 1.15s\n",
      "83:\tlearn: 0.5198678\ttotal: 304ms\tremaining: 1.14s\n",
      "84:\tlearn: 0.5129982\ttotal: 307ms\tremaining: 1.14s\n",
      "85:\tlearn: 0.5088413\ttotal: 310ms\tremaining: 1.13s\n",
      "86:\tlearn: 0.5014771\ttotal: 313ms\tremaining: 1.13s\n",
      "87:\tlearn: 0.4976256\ttotal: 316ms\tremaining: 1.12s\n",
      "88:\tlearn: 0.4930308\ttotal: 319ms\tremaining: 1.12s\n",
      "89:\tlearn: 0.4906674\ttotal: 322ms\tremaining: 1.11s\n",
      "90:\tlearn: 0.4859203\ttotal: 327ms\tremaining: 1.11s\n",
      "91:\tlearn: 0.4804419\ttotal: 330ms\tremaining: 1.1s\n",
      "92:\tlearn: 0.4766605\ttotal: 333ms\tremaining: 1.1s\n",
      "93:\tlearn: 0.4716733\ttotal: 336ms\tremaining: 1.09s\n",
      "94:\tlearn: 0.4655338\ttotal: 342ms\tremaining: 1.1s\n",
      "95:\tlearn: 0.4592964\ttotal: 345ms\tremaining: 1.09s\n",
      "96:\tlearn: 0.4555483\ttotal: 348ms\tremaining: 1.09s\n",
      "97:\tlearn: 0.4513415\ttotal: 351ms\tremaining: 1.08s\n",
      "98:\tlearn: 0.4449174\ttotal: 354ms\tremaining: 1.07s\n",
      "99:\tlearn: 0.4389445\ttotal: 357ms\tremaining: 1.07s\n",
      "100:\tlearn: 0.4340251\ttotal: 360ms\tremaining: 1.07s\n",
      "101:\tlearn: 0.4311396\ttotal: 363ms\tremaining: 1.06s\n",
      "102:\tlearn: 0.4285757\ttotal: 366ms\tremaining: 1.06s\n",
      "103:\tlearn: 0.4243564\ttotal: 369ms\tremaining: 1.05s\n",
      "104:\tlearn: 0.4197729\ttotal: 372ms\tremaining: 1.05s\n",
      "105:\tlearn: 0.4156065\ttotal: 376ms\tremaining: 1.04s\n",
      "106:\tlearn: 0.4133940\ttotal: 379ms\tremaining: 1.04s\n",
      "107:\tlearn: 0.4085748\ttotal: 382ms\tremaining: 1.03s\n",
      "108:\tlearn: 0.4032362\ttotal: 385ms\tremaining: 1.03s\n",
      "109:\tlearn: 0.3992083\ttotal: 388ms\tremaining: 1.02s\n",
      "110:\tlearn: 0.3931320\ttotal: 391ms\tremaining: 1.02s\n",
      "111:\tlearn: 0.3907991\ttotal: 394ms\tremaining: 1.01s\n",
      "112:\tlearn: 0.3864658\ttotal: 398ms\tremaining: 1.01s\n",
      "113:\tlearn: 0.3840438\ttotal: 402ms\tremaining: 1.01s\n",
      "114:\tlearn: 0.3816942\ttotal: 407ms\tremaining: 1.01s\n",
      "115:\tlearn: 0.3784084\ttotal: 410ms\tremaining: 1s\n",
      "116:\tlearn: 0.3767047\ttotal: 415ms\tremaining: 1s\n",
      "117:\tlearn: 0.3726189\ttotal: 418ms\tremaining: 999ms\n",
      "118:\tlearn: 0.3692909\ttotal: 422ms\tremaining: 996ms\n",
      "119:\tlearn: 0.3662481\ttotal: 425ms\tremaining: 992ms\n",
      "120:\tlearn: 0.3631250\ttotal: 429ms\tremaining: 988ms\n",
      "121:\tlearn: 0.3593089\ttotal: 433ms\tremaining: 986ms\n",
      "122:\tlearn: 0.3561736\ttotal: 436ms\tremaining: 982ms\n",
      "123:\tlearn: 0.3527136\ttotal: 440ms\tremaining: 979ms\n",
      "124:\tlearn: 0.3491963\ttotal: 443ms\tremaining: 975ms\n",
      "125:\tlearn: 0.3464566\ttotal: 447ms\tremaining: 971ms\n",
      "126:\tlearn: 0.3433318\ttotal: 450ms\tremaining: 967ms\n",
      "127:\tlearn: 0.3401737\ttotal: 453ms\tremaining: 962ms\n",
      "128:\tlearn: 0.3383664\ttotal: 456ms\tremaining: 958ms\n",
      "129:\tlearn: 0.3347412\ttotal: 459ms\tremaining: 954ms\n",
      "130:\tlearn: 0.3325309\ttotal: 462ms\tremaining: 949ms\n",
      "131:\tlearn: 0.3300065\ttotal: 465ms\tremaining: 945ms\n",
      "132:\tlearn: 0.3262636\ttotal: 468ms\tremaining: 940ms\n",
      "133:\tlearn: 0.3237481\ttotal: 471ms\tremaining: 936ms\n",
      "134:\tlearn: 0.3213703\ttotal: 476ms\tremaining: 933ms\n",
      "135:\tlearn: 0.3186995\ttotal: 479ms\tremaining: 930ms\n",
      "136:\tlearn: 0.3152197\ttotal: 482ms\tremaining: 926ms\n",
      "137:\tlearn: 0.3121543\ttotal: 485ms\tremaining: 921ms\n",
      "138:\tlearn: 0.3097485\ttotal: 489ms\tremaining: 919ms\n",
      "139:\tlearn: 0.3068897\ttotal: 494ms\tremaining: 917ms\n",
      "140:\tlearn: 0.3046136\ttotal: 497ms\tremaining: 913ms\n",
      "141:\tlearn: 0.3021382\ttotal: 500ms\tremaining: 909ms\n",
      "142:\tlearn: 0.2997886\ttotal: 503ms\tremaining: 905ms\n",
      "143:\tlearn: 0.2972857\ttotal: 507ms\tremaining: 900ms\n",
      "144:\tlearn: 0.2948543\ttotal: 509ms\tremaining: 896ms\n",
      "145:\tlearn: 0.2921946\ttotal: 512ms\tremaining: 891ms\n",
      "146:\tlearn: 0.2889881\ttotal: 516ms\tremaining: 889ms\n",
      "147:\tlearn: 0.2868976\ttotal: 520ms\tremaining: 885ms\n",
      "148:\tlearn: 0.2849955\ttotal: 523ms\tremaining: 882ms\n",
      "149:\tlearn: 0.2836921\ttotal: 527ms\tremaining: 879ms\n",
      "150:\tlearn: 0.2824614\ttotal: 531ms\tremaining: 876ms\n",
      "151:\tlearn: 0.2809830\ttotal: 537ms\tremaining: 876ms\n",
      "152:\tlearn: 0.2790072\ttotal: 540ms\tremaining: 872ms\n",
      "153:\tlearn: 0.2766645\ttotal: 543ms\tremaining: 868ms\n",
      "154:\tlearn: 0.2750010\ttotal: 547ms\tremaining: 865ms\n",
      "155:\tlearn: 0.2721423\ttotal: 551ms\tremaining: 861ms\n",
      "156:\tlearn: 0.2697239\ttotal: 554ms\tremaining: 857ms\n",
      "157:\tlearn: 0.2678051\ttotal: 557ms\tremaining: 853ms\n",
      "158:\tlearn: 0.2655078\ttotal: 560ms\tremaining: 849ms\n",
      "159:\tlearn: 0.2635974\ttotal: 564ms\tremaining: 845ms\n",
      "160:\tlearn: 0.2621647\ttotal: 567ms\tremaining: 841ms\n",
      "161:\tlearn: 0.2605182\ttotal: 570ms\tremaining: 837ms\n",
      "162:\tlearn: 0.2589526\ttotal: 573ms\tremaining: 833ms\n",
      "163:\tlearn: 0.2563115\ttotal: 576ms\tremaining: 828ms\n",
      "164:\tlearn: 0.2549869\ttotal: 579ms\tremaining: 825ms\n",
      "165:\tlearn: 0.2533445\ttotal: 583ms\tremaining: 821ms\n",
      "166:\tlearn: 0.2520223\ttotal: 587ms\tremaining: 818ms\n",
      "167:\tlearn: 0.2496780\ttotal: 590ms\tremaining: 815ms\n",
      "168:\tlearn: 0.2473595\ttotal: 595ms\tremaining: 813ms\n",
      "169:\tlearn: 0.2451416\ttotal: 600ms\tremaining: 812ms\n",
      "170:\tlearn: 0.2429834\ttotal: 603ms\tremaining: 808ms\n",
      "171:\tlearn: 0.2411173\ttotal: 606ms\tremaining: 803ms\n",
      "172:\tlearn: 0.2396090\ttotal: 610ms\tremaining: 800ms\n",
      "173:\tlearn: 0.2379246\ttotal: 614ms\tremaining: 797ms\n",
      "174:\tlearn: 0.2359329\ttotal: 618ms\tremaining: 794ms\n",
      "175:\tlearn: 0.2337300\ttotal: 621ms\tremaining: 790ms\n",
      "176:\tlearn: 0.2323407\ttotal: 624ms\tremaining: 787ms\n",
      "177:\tlearn: 0.2314566\ttotal: 629ms\tremaining: 784ms\n",
      "178:\tlearn: 0.2294330\ttotal: 632ms\tremaining: 780ms\n",
      "179:\tlearn: 0.2278544\ttotal: 635ms\tremaining: 777ms\n",
      "180:\tlearn: 0.2267426\ttotal: 638ms\tremaining: 772ms\n",
      "181:\tlearn: 0.2248769\ttotal: 642ms\tremaining: 769ms\n",
      "182:\tlearn: 0.2236335\ttotal: 646ms\tremaining: 765ms\n",
      "183:\tlearn: 0.2218375\ttotal: 649ms\tremaining: 762ms\n",
      "184:\tlearn: 0.2198526\ttotal: 653ms\tremaining: 759ms\n",
      "185:\tlearn: 0.2184815\ttotal: 657ms\tremaining: 755ms\n",
      "186:\tlearn: 0.2173409\ttotal: 662ms\tremaining: 753ms\n",
      "187:\tlearn: 0.2157560\ttotal: 666ms\tremaining: 752ms\n",
      "188:\tlearn: 0.2140010\ttotal: 669ms\tremaining: 747ms\n",
      "189:\tlearn: 0.2119941\ttotal: 673ms\tremaining: 744ms\n",
      "190:\tlearn: 0.2104710\ttotal: 676ms\tremaining: 740ms\n",
      "191:\tlearn: 0.2090700\ttotal: 680ms\tremaining: 737ms\n",
      "192:\tlearn: 0.2082559\ttotal: 683ms\tremaining: 733ms\n",
      "193:\tlearn: 0.2070467\ttotal: 687ms\tremaining: 729ms\n",
      "194:\tlearn: 0.2060381\ttotal: 690ms\tremaining: 726ms\n",
      "195:\tlearn: 0.2046996\ttotal: 694ms\tremaining: 722ms\n",
      "196:\tlearn: 0.2030462\ttotal: 697ms\tremaining: 718ms\n",
      "197:\tlearn: 0.2012263\ttotal: 700ms\tremaining: 714ms\n",
      "198:\tlearn: 0.1997023\ttotal: 703ms\tremaining: 710ms\n",
      "199:\tlearn: 0.1984081\ttotal: 707ms\tremaining: 707ms\n",
      "200:\tlearn: 0.1972339\ttotal: 710ms\tremaining: 703ms\n",
      "201:\tlearn: 0.1957524\ttotal: 714ms\tremaining: 700ms\n",
      "202:\tlearn: 0.1943589\ttotal: 718ms\tremaining: 696ms\n",
      "203:\tlearn: 0.1932710\ttotal: 721ms\tremaining: 693ms\n",
      "204:\tlearn: 0.1921473\ttotal: 724ms\tremaining: 689ms\n",
      "205:\tlearn: 0.1909959\ttotal: 730ms\tremaining: 688ms\n",
      "206:\tlearn: 0.1897357\ttotal: 733ms\tremaining: 684ms\n",
      "207:\tlearn: 0.1887991\ttotal: 738ms\tremaining: 681ms\n",
      "208:\tlearn: 0.1878567\ttotal: 741ms\tremaining: 677ms\n",
      "209:\tlearn: 0.1870536\ttotal: 744ms\tremaining: 673ms\n",
      "210:\tlearn: 0.1858216\ttotal: 747ms\tremaining: 669ms\n",
      "211:\tlearn: 0.1847905\ttotal: 750ms\tremaining: 665ms\n",
      "212:\tlearn: 0.1833712\ttotal: 754ms\tremaining: 662ms\n",
      "213:\tlearn: 0.1822440\ttotal: 757ms\tremaining: 658ms\n",
      "214:\tlearn: 0.1814680\ttotal: 760ms\tremaining: 654ms\n",
      "215:\tlearn: 0.1801130\ttotal: 763ms\tremaining: 650ms\n",
      "216:\tlearn: 0.1793565\ttotal: 766ms\tremaining: 646ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217:\tlearn: 0.1781326\ttotal: 771ms\tremaining: 643ms\n",
      "218:\tlearn: 0.1767134\ttotal: 774ms\tremaining: 640ms\n",
      "219:\tlearn: 0.1761126\ttotal: 778ms\tremaining: 637ms\n",
      "220:\tlearn: 0.1752487\ttotal: 781ms\tremaining: 633ms\n",
      "221:\tlearn: 0.1737166\ttotal: 788ms\tremaining: 632ms\n",
      "222:\tlearn: 0.1723050\ttotal: 793ms\tremaining: 629ms\n",
      "223:\tlearn: 0.1712601\ttotal: 798ms\tremaining: 627ms\n",
      "224:\tlearn: 0.1701711\ttotal: 802ms\tremaining: 624ms\n",
      "225:\tlearn: 0.1691053\ttotal: 806ms\tremaining: 621ms\n",
      "226:\tlearn: 0.1681884\ttotal: 810ms\tremaining: 617ms\n",
      "227:\tlearn: 0.1668497\ttotal: 814ms\tremaining: 614ms\n",
      "228:\tlearn: 0.1657091\ttotal: 818ms\tremaining: 611ms\n",
      "229:\tlearn: 0.1645085\ttotal: 821ms\tremaining: 607ms\n",
      "230:\tlearn: 0.1635774\ttotal: 825ms\tremaining: 603ms\n",
      "231:\tlearn: 0.1625293\ttotal: 828ms\tremaining: 600ms\n",
      "232:\tlearn: 0.1612512\ttotal: 833ms\tremaining: 597ms\n",
      "233:\tlearn: 0.1604957\ttotal: 836ms\tremaining: 593ms\n",
      "234:\tlearn: 0.1597991\ttotal: 840ms\tremaining: 590ms\n",
      "235:\tlearn: 0.1590943\ttotal: 845ms\tremaining: 587ms\n",
      "236:\tlearn: 0.1583483\ttotal: 849ms\tremaining: 584ms\n",
      "237:\tlearn: 0.1576798\ttotal: 853ms\tremaining: 580ms\n",
      "238:\tlearn: 0.1566783\ttotal: 857ms\tremaining: 577ms\n",
      "239:\tlearn: 0.1557728\ttotal: 863ms\tremaining: 575ms\n",
      "240:\tlearn: 0.1549456\ttotal: 866ms\tremaining: 571ms\n",
      "241:\tlearn: 0.1540998\ttotal: 869ms\tremaining: 567ms\n",
      "242:\tlearn: 0.1533263\ttotal: 872ms\tremaining: 563ms\n",
      "243:\tlearn: 0.1524110\ttotal: 875ms\tremaining: 559ms\n",
      "244:\tlearn: 0.1517891\ttotal: 878ms\tremaining: 556ms\n",
      "245:\tlearn: 0.1508093\ttotal: 882ms\tremaining: 552ms\n",
      "246:\tlearn: 0.1497758\ttotal: 885ms\tremaining: 548ms\n",
      "247:\tlearn: 0.1490277\ttotal: 888ms\tremaining: 544ms\n",
      "248:\tlearn: 0.1480910\ttotal: 891ms\tremaining: 540ms\n",
      "249:\tlearn: 0.1475830\ttotal: 894ms\tremaining: 537ms\n",
      "250:\tlearn: 0.1468008\ttotal: 898ms\tremaining: 533ms\n",
      "251:\tlearn: 0.1464071\ttotal: 901ms\tremaining: 529ms\n",
      "252:\tlearn: 0.1457676\ttotal: 904ms\tremaining: 525ms\n",
      "253:\tlearn: 0.1447830\ttotal: 907ms\tremaining: 522ms\n",
      "254:\tlearn: 0.1443104\ttotal: 912ms\tremaining: 519ms\n",
      "255:\tlearn: 0.1436437\ttotal: 916ms\tremaining: 515ms\n",
      "256:\tlearn: 0.1428418\ttotal: 919ms\tremaining: 511ms\n",
      "257:\tlearn: 0.1421517\ttotal: 922ms\tremaining: 507ms\n",
      "258:\tlearn: 0.1414166\ttotal: 928ms\tremaining: 505ms\n",
      "259:\tlearn: 0.1405430\ttotal: 931ms\tremaining: 501ms\n",
      "260:\tlearn: 0.1398263\ttotal: 934ms\tremaining: 498ms\n",
      "261:\tlearn: 0.1391992\ttotal: 937ms\tremaining: 494ms\n",
      "262:\tlearn: 0.1386686\ttotal: 940ms\tremaining: 490ms\n",
      "263:\tlearn: 0.1380428\ttotal: 944ms\tremaining: 486ms\n",
      "264:\tlearn: 0.1371532\ttotal: 948ms\tremaining: 483ms\n",
      "265:\tlearn: 0.1363761\ttotal: 951ms\tremaining: 479ms\n",
      "266:\tlearn: 0.1356607\ttotal: 954ms\tremaining: 475ms\n",
      "267:\tlearn: 0.1348278\ttotal: 958ms\tremaining: 472ms\n",
      "268:\tlearn: 0.1340674\ttotal: 961ms\tremaining: 468ms\n",
      "269:\tlearn: 0.1331625\ttotal: 965ms\tremaining: 465ms\n",
      "270:\tlearn: 0.1324183\ttotal: 969ms\tremaining: 461ms\n",
      "271:\tlearn: 0.1317616\ttotal: 973ms\tremaining: 458ms\n",
      "272:\tlearn: 0.1307635\ttotal: 977ms\tremaining: 455ms\n",
      "273:\tlearn: 0.1303005\ttotal: 981ms\tremaining: 451ms\n",
      "274:\tlearn: 0.1299351\ttotal: 984ms\tremaining: 447ms\n",
      "275:\tlearn: 0.1292410\ttotal: 988ms\tremaining: 444ms\n",
      "276:\tlearn: 0.1288292\ttotal: 993ms\tremaining: 441ms\n",
      "277:\tlearn: 0.1283493\ttotal: 997ms\tremaining: 437ms\n",
      "278:\tlearn: 0.1277296\ttotal: 1000ms\tremaining: 434ms\n",
      "279:\tlearn: 0.1269953\ttotal: 1s\tremaining: 430ms\n",
      "280:\tlearn: 0.1262502\ttotal: 1s\tremaining: 426ms\n",
      "281:\tlearn: 0.1256282\ttotal: 1.01s\tremaining: 422ms\n",
      "282:\tlearn: 0.1248001\ttotal: 1.01s\tremaining: 418ms\n",
      "283:\tlearn: 0.1241063\ttotal: 1.01s\tremaining: 415ms\n",
      "284:\tlearn: 0.1233746\ttotal: 1.02s\tremaining: 411ms\n",
      "285:\tlearn: 0.1228724\ttotal: 1.02s\tremaining: 407ms\n",
      "286:\tlearn: 0.1221183\ttotal: 1.02s\tremaining: 403ms\n",
      "287:\tlearn: 0.1215551\ttotal: 1.03s\tremaining: 400ms\n",
      "288:\tlearn: 0.1210534\ttotal: 1.03s\tremaining: 396ms\n",
      "289:\tlearn: 0.1207690\ttotal: 1.03s\tremaining: 393ms\n",
      "290:\tlearn: 0.1201121\ttotal: 1.04s\tremaining: 389ms\n",
      "291:\tlearn: 0.1197602\ttotal: 1.04s\tremaining: 386ms\n",
      "292:\tlearn: 0.1192429\ttotal: 1.05s\tremaining: 383ms\n",
      "293:\tlearn: 0.1188930\ttotal: 1.05s\tremaining: 379ms\n",
      "294:\tlearn: 0.1185458\ttotal: 1.05s\tremaining: 375ms\n",
      "295:\tlearn: 0.1180293\ttotal: 1.06s\tremaining: 372ms\n",
      "296:\tlearn: 0.1174206\ttotal: 1.06s\tremaining: 368ms\n",
      "297:\tlearn: 0.1168238\ttotal: 1.06s\tremaining: 364ms\n",
      "298:\tlearn: 0.1161964\ttotal: 1.07s\tremaining: 360ms\n",
      "299:\tlearn: 0.1157660\ttotal: 1.07s\tremaining: 357ms\n",
      "300:\tlearn: 0.1154766\ttotal: 1.07s\tremaining: 353ms\n",
      "301:\tlearn: 0.1150046\ttotal: 1.08s\tremaining: 350ms\n",
      "302:\tlearn: 0.1146700\ttotal: 1.08s\tremaining: 346ms\n",
      "303:\tlearn: 0.1141806\ttotal: 1.08s\tremaining: 342ms\n",
      "304:\tlearn: 0.1136149\ttotal: 1.09s\tremaining: 339ms\n",
      "305:\tlearn: 0.1131379\ttotal: 1.09s\tremaining: 335ms\n",
      "306:\tlearn: 0.1127088\ttotal: 1.09s\tremaining: 332ms\n",
      "307:\tlearn: 0.1122009\ttotal: 1.1s\tremaining: 328ms\n",
      "308:\tlearn: 0.1115569\ttotal: 1.1s\tremaining: 325ms\n",
      "309:\tlearn: 0.1109985\ttotal: 1.1s\tremaining: 321ms\n",
      "310:\tlearn: 0.1107265\ttotal: 1.11s\tremaining: 317ms\n",
      "311:\tlearn: 0.1100818\ttotal: 1.11s\tremaining: 314ms\n",
      "312:\tlearn: 0.1096927\ttotal: 1.12s\tremaining: 311ms\n",
      "313:\tlearn: 0.1092877\ttotal: 1.12s\tremaining: 307ms\n",
      "314:\tlearn: 0.1089900\ttotal: 1.13s\tremaining: 304ms\n",
      "315:\tlearn: 0.1084706\ttotal: 1.13s\tremaining: 300ms\n",
      "316:\tlearn: 0.1079075\ttotal: 1.13s\tremaining: 297ms\n",
      "317:\tlearn: 0.1074019\ttotal: 1.14s\tremaining: 293ms\n",
      "318:\tlearn: 0.1071617\ttotal: 1.14s\tremaining: 290ms\n",
      "319:\tlearn: 0.1067978\ttotal: 1.15s\tremaining: 286ms\n",
      "320:\tlearn: 0.1064502\ttotal: 1.15s\tremaining: 283ms\n",
      "321:\tlearn: 0.1059709\ttotal: 1.15s\tremaining: 279ms\n",
      "322:\tlearn: 0.1056023\ttotal: 1.16s\tremaining: 276ms\n",
      "323:\tlearn: 0.1054052\ttotal: 1.16s\tremaining: 272ms\n",
      "324:\tlearn: 0.1049578\ttotal: 1.16s\tremaining: 268ms\n",
      "325:\tlearn: 0.1047687\ttotal: 1.17s\tremaining: 265ms\n",
      "326:\tlearn: 0.1044497\ttotal: 1.17s\tremaining: 261ms\n",
      "327:\tlearn: 0.1037272\ttotal: 1.17s\tremaining: 258ms\n",
      "328:\tlearn: 0.1034071\ttotal: 1.18s\tremaining: 254ms\n",
      "329:\tlearn: 0.1028820\ttotal: 1.18s\tremaining: 251ms\n",
      "330:\tlearn: 0.1023407\ttotal: 1.19s\tremaining: 247ms\n",
      "331:\tlearn: 0.1018373\ttotal: 1.19s\tremaining: 244ms\n",
      "332:\tlearn: 0.1014185\ttotal: 1.19s\tremaining: 240ms\n",
      "333:\tlearn: 0.1011860\ttotal: 1.2s\tremaining: 236ms\n",
      "334:\tlearn: 0.1009274\ttotal: 1.2s\tremaining: 233ms\n",
      "335:\tlearn: 0.1005759\ttotal: 1.2s\tremaining: 229ms\n",
      "336:\tlearn: 0.1002343\ttotal: 1.2s\tremaining: 225ms\n",
      "337:\tlearn: 0.0998458\ttotal: 1.21s\tremaining: 222ms\n",
      "338:\tlearn: 0.0992892\ttotal: 1.21s\tremaining: 218ms\n",
      "339:\tlearn: 0.0989326\ttotal: 1.21s\tremaining: 214ms\n",
      "340:\tlearn: 0.0983302\ttotal: 1.22s\tremaining: 211ms\n",
      "341:\tlearn: 0.0979452\ttotal: 1.22s\tremaining: 207ms\n",
      "342:\tlearn: 0.0976588\ttotal: 1.22s\tremaining: 203ms\n",
      "343:\tlearn: 0.0971688\ttotal: 1.23s\tremaining: 200ms\n",
      "344:\tlearn: 0.0967562\ttotal: 1.23s\tremaining: 197ms\n",
      "345:\tlearn: 0.0963722\ttotal: 1.24s\tremaining: 193ms\n",
      "346:\tlearn: 0.0961051\ttotal: 1.24s\tremaining: 189ms\n",
      "347:\tlearn: 0.0956558\ttotal: 1.24s\tremaining: 186ms\n",
      "348:\tlearn: 0.0953511\ttotal: 1.25s\tremaining: 182ms\n",
      "349:\tlearn: 0.0950801\ttotal: 1.25s\tremaining: 178ms\n",
      "350:\tlearn: 0.0946830\ttotal: 1.25s\tremaining: 175ms\n",
      "351:\tlearn: 0.0944595\ttotal: 1.25s\tremaining: 171ms\n",
      "352:\tlearn: 0.0940072\ttotal: 1.26s\tremaining: 168ms\n",
      "353:\tlearn: 0.0936048\ttotal: 1.26s\tremaining: 164ms\n",
      "354:\tlearn: 0.0931723\ttotal: 1.26s\tremaining: 160ms\n",
      "355:\tlearn: 0.0928223\ttotal: 1.27s\tremaining: 157ms\n",
      "356:\tlearn: 0.0923371\ttotal: 1.27s\tremaining: 153ms\n",
      "357:\tlearn: 0.0919818\ttotal: 1.27s\tremaining: 149ms\n",
      "358:\tlearn: 0.0915277\ttotal: 1.28s\tremaining: 146ms\n",
      "359:\tlearn: 0.0912359\ttotal: 1.28s\tremaining: 142ms\n",
      "360:\tlearn: 0.0909092\ttotal: 1.28s\tremaining: 139ms\n",
      "361:\tlearn: 0.0905871\ttotal: 1.29s\tremaining: 135ms\n",
      "362:\tlearn: 0.0902593\ttotal: 1.29s\tremaining: 132ms\n",
      "363:\tlearn: 0.0899570\ttotal: 1.3s\tremaining: 128ms\n",
      "364:\tlearn: 0.0897731\ttotal: 1.3s\tremaining: 125ms\n",
      "365:\tlearn: 0.0893588\ttotal: 1.3s\tremaining: 121ms\n",
      "366:\tlearn: 0.0888907\ttotal: 1.31s\tremaining: 118ms\n",
      "367:\tlearn: 0.0885985\ttotal: 1.31s\tremaining: 114ms\n",
      "368:\tlearn: 0.0881818\ttotal: 1.31s\tremaining: 111ms\n",
      "369:\tlearn: 0.0878624\ttotal: 1.32s\tremaining: 107ms\n",
      "370:\tlearn: 0.0875711\ttotal: 1.32s\tremaining: 103ms\n",
      "371:\tlearn: 0.0872079\ttotal: 1.33s\tremaining: 99.9ms\n",
      "372:\tlearn: 0.0868435\ttotal: 1.33s\tremaining: 96.3ms\n",
      "373:\tlearn: 0.0865652\ttotal: 1.33s\tremaining: 92.7ms\n",
      "374:\tlearn: 0.0861613\ttotal: 1.34s\tremaining: 89.1ms\n",
      "375:\tlearn: 0.0856407\ttotal: 1.34s\tremaining: 85.6ms\n",
      "376:\tlearn: 0.0852333\ttotal: 1.34s\tremaining: 82ms\n",
      "377:\tlearn: 0.0848940\ttotal: 1.35s\tremaining: 78.4ms\n",
      "378:\tlearn: 0.0847012\ttotal: 1.35s\tremaining: 74.8ms\n",
      "379:\tlearn: 0.0845660\ttotal: 1.35s\tremaining: 71.3ms\n",
      "380:\tlearn: 0.0842410\ttotal: 1.36s\tremaining: 67.7ms\n",
      "381:\tlearn: 0.0839977\ttotal: 1.36s\tremaining: 64.2ms\n",
      "382:\tlearn: 0.0836289\ttotal: 1.36s\tremaining: 60.6ms\n",
      "383:\tlearn: 0.0833796\ttotal: 1.37s\tremaining: 57ms\n",
      "384:\tlearn: 0.0831787\ttotal: 1.37s\tremaining: 53.5ms\n",
      "385:\tlearn: 0.0826864\ttotal: 1.38s\tremaining: 49.9ms\n",
      "386:\tlearn: 0.0823704\ttotal: 1.38s\tremaining: 46.3ms\n",
      "387:\tlearn: 0.0820774\ttotal: 1.38s\tremaining: 42.8ms\n",
      "388:\tlearn: 0.0817374\ttotal: 1.39s\tremaining: 39.2ms\n",
      "389:\tlearn: 0.0815062\ttotal: 1.39s\tremaining: 35.6ms\n",
      "390:\tlearn: 0.0811332\ttotal: 1.39s\tremaining: 32ms\n",
      "391:\tlearn: 0.0808613\ttotal: 1.4s\tremaining: 28.5ms\n",
      "392:\tlearn: 0.0805924\ttotal: 1.4s\tremaining: 24.9ms\n",
      "393:\tlearn: 0.0801789\ttotal: 1.4s\tremaining: 21.4ms\n",
      "394:\tlearn: 0.0797199\ttotal: 1.41s\tremaining: 17.8ms\n",
      "395:\tlearn: 0.0794823\ttotal: 1.41s\tremaining: 14.2ms\n",
      "396:\tlearn: 0.0792397\ttotal: 1.41s\tremaining: 10.7ms\n",
      "397:\tlearn: 0.0789495\ttotal: 1.42s\tremaining: 7.12ms\n",
      "398:\tlearn: 0.0787018\ttotal: 1.42s\tremaining: 3.56ms\n",
      "399:\tlearn: 0.0783777\ttotal: 1.43s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.92762 |  0:00:00s\n",
      "epoch 1  | loss: 1.61629 |  0:00:00s\n",
      "epoch 2  | loss: 1.44294 |  0:00:00s\n",
      "epoch 3  | loss: 1.49889 |  0:00:00s\n",
      "epoch 4  | loss: 1.39614 |  0:00:00s\n",
      "epoch 5  | loss: 1.3572  |  0:00:00s\n",
      "epoch 6  | loss: 1.3052  |  0:00:00s\n",
      "epoch 7  | loss: 1.30067 |  0:00:00s\n",
      "epoch 8  | loss: 1.28736 |  0:00:00s\n",
      "epoch 9  | loss: 1.27142 |  0:00:00s\n",
      "epoch 10 | loss: 1.27026 |  0:00:00s\n",
      "epoch 11 | loss: 1.25585 |  0:00:01s\n",
      "epoch 12 | loss: 1.28808 |  0:00:01s\n",
      "epoch 13 | loss: 1.24789 |  0:00:01s\n",
      "epoch 14 | loss: 1.21314 |  0:00:01s\n",
      "epoch 15 | loss: 1.23225 |  0:00:01s\n",
      "epoch 16 | loss: 1.26399 |  0:00:01s\n",
      "epoch 17 | loss: 1.16756 |  0:00:01s\n",
      "epoch 18 | loss: 1.17659 |  0:00:01s\n",
      "epoch 19 | loss: 1.21937 |  0:00:01s\n",
      "epoch 20 | loss: 1.13962 |  0:00:01s\n",
      "epoch 21 | loss: 1.16693 |  0:00:01s\n",
      "epoch 22 | loss: 1.15275 |  0:00:01s\n",
      "epoch 23 | loss: 1.15447 |  0:00:02s\n",
      "epoch 24 | loss: 1.15739 |  0:00:02s\n",
      "epoch 25 | loss: 1.14726 |  0:00:02s\n",
      "epoch 26 | loss: 1.16512 |  0:00:02s\n",
      "epoch 27 | loss: 1.11132 |  0:00:02s\n",
      "epoch 28 | loss: 1.13275 |  0:00:02s\n",
      "epoch 29 | loss: 1.1141  |  0:00:02s\n",
      "epoch 30 | loss: 1.09523 |  0:00:02s\n",
      "epoch 31 | loss: 1.11327 |  0:00:02s\n",
      "epoch 32 | loss: 1.08857 |  0:00:02s\n",
      "epoch 33 | loss: 1.0979  |  0:00:02s\n",
      "epoch 34 | loss: 1.10941 |  0:00:03s\n",
      "epoch 35 | loss: 1.08603 |  0:00:03s\n",
      "epoch 36 | loss: 1.11738 |  0:00:03s\n",
      "epoch 37 | loss: 1.08819 |  0:00:03s\n",
      "epoch 38 | loss: 1.10427 |  0:00:03s\n",
      "epoch 39 | loss: 1.08862 |  0:00:03s\n",
      "epoch 40 | loss: 1.05348 |  0:00:03s\n",
      "epoch 41 | loss: 1.02223 |  0:00:03s\n",
      "epoch 42 | loss: 1.02828 |  0:00:03s\n",
      "epoch 43 | loss: 1.0402  |  0:00:03s\n",
      "epoch 44 | loss: 1.05486 |  0:00:03s\n",
      "epoch 45 | loss: 1.02075 |  0:00:03s\n",
      "epoch 46 | loss: 1.04055 |  0:00:04s\n",
      "epoch 47 | loss: 1.03934 |  0:00:04s\n",
      "epoch 48 | loss: 1.05488 |  0:00:04s\n",
      "epoch 49 | loss: 0.9863  |  0:00:04s\n",
      "epoch 50 | loss: 1.03165 |  0:00:04s\n",
      "epoch 51 | loss: 1.02097 |  0:00:04s\n",
      "epoch 52 | loss: 1.05599 |  0:00:04s\n",
      "epoch 53 | loss: 0.93444 |  0:00:04s\n",
      "epoch 54 | loss: 1.01417 |  0:00:04s\n",
      "epoch 55 | loss: 1.0073  |  0:00:04s\n",
      "epoch 56 | loss: 1.0271  |  0:00:04s\n",
      "epoch 57 | loss: 0.99451 |  0:00:04s\n",
      "epoch 58 | loss: 0.97879 |  0:00:05s\n",
      "epoch 59 | loss: 0.98719 |  0:00:05s\n",
      "epoch 60 | loss: 1.01545 |  0:00:05s\n",
      "epoch 61 | loss: 0.9595  |  0:00:05s\n",
      "epoch 62 | loss: 0.98545 |  0:00:05s\n",
      "epoch 63 | loss: 0.94587 |  0:00:05s\n",
      "epoch 64 | loss: 0.8913  |  0:00:05s\n",
      "epoch 65 | loss: 0.89079 |  0:00:05s\n",
      "epoch 66 | loss: 0.95677 |  0:00:05s\n",
      "epoch 67 | loss: 0.91162 |  0:00:05s\n",
      "epoch 68 | loss: 0.90898 |  0:00:05s\n",
      "epoch 69 | loss: 0.88737 |  0:00:05s\n",
      "epoch 70 | loss: 0.93652 |  0:00:06s\n",
      "epoch 71 | loss: 0.94738 |  0:00:06s\n",
      "epoch 72 | loss: 0.99241 |  0:00:06s\n",
      "epoch 73 | loss: 0.91976 |  0:00:06s\n",
      "epoch 74 | loss: 0.94276 |  0:00:06s\n",
      "epoch 75 | loss: 0.90096 |  0:00:06s\n",
      "epoch 76 | loss: 0.94503 |  0:00:06s\n",
      "epoch 77 | loss: 0.95778 |  0:00:06s\n",
      "epoch 78 | loss: 0.90302 |  0:00:06s\n",
      "epoch 79 | loss: 0.90927 |  0:00:06s\n",
      "epoch 80 | loss: 0.92103 |  0:00:06s\n",
      "epoch 81 | loss: 0.92271 |  0:00:06s\n",
      "epoch 82 | loss: 0.87191 |  0:00:07s\n",
      "epoch 83 | loss: 0.96643 |  0:00:07s\n",
      "epoch 84 | loss: 0.91321 |  0:00:07s\n",
      "epoch 85 | loss: 0.86891 |  0:00:07s\n",
      "epoch 86 | loss: 0.82726 |  0:00:07s\n",
      "epoch 87 | loss: 0.88886 |  0:00:07s\n",
      "epoch 88 | loss: 0.85578 |  0:00:07s\n",
      "epoch 89 | loss: 0.90327 |  0:00:07s\n",
      "epoch 90 | loss: 0.93443 |  0:00:07s\n",
      "epoch 91 | loss: 0.84451 |  0:00:07s\n",
      "epoch 92 | loss: 0.86823 |  0:00:07s\n",
      "epoch 93 | loss: 0.91105 |  0:00:07s\n",
      "epoch 94 | loss: 0.93549 |  0:00:08s\n",
      "epoch 95 | loss: 0.876   |  0:00:08s\n",
      "epoch 96 | loss: 0.91405 |  0:00:08s\n",
      "epoch 97 | loss: 0.89144 |  0:00:08s\n",
      "epoch 98 | loss: 0.88258 |  0:00:08s\n",
      "epoch 99 | loss: 0.8638  |  0:00:08s\n",
      "epoch 100| loss: 0.89886 |  0:00:08s\n",
      "epoch 101| loss: 0.87426 |  0:00:08s\n",
      "epoch 102| loss: 0.87648 |  0:00:08s\n",
      "epoch 103| loss: 0.91327 |  0:00:08s\n",
      "epoch 104| loss: 0.91017 |  0:00:08s\n",
      "epoch 105| loss: 0.8422  |  0:00:08s\n",
      "epoch 106| loss: 0.86187 |  0:00:09s\n",
      "epoch 107| loss: 0.90287 |  0:00:09s\n",
      "epoch 108| loss: 0.86539 |  0:00:09s\n",
      "epoch 109| loss: 0.8553  |  0:00:09s\n",
      "epoch 110| loss: 0.82755 |  0:00:09s\n",
      "epoch 111| loss: 0.8884  |  0:00:09s\n",
      "epoch 112| loss: 0.93928 |  0:00:09s\n",
      "epoch 113| loss: 0.81214 |  0:00:09s\n",
      "epoch 114| loss: 0.83455 |  0:00:09s\n",
      "epoch 115| loss: 0.88368 |  0:00:09s\n",
      "epoch 116| loss: 0.78609 |  0:00:09s\n",
      "epoch 117| loss: 0.81901 |  0:00:09s\n",
      "epoch 118| loss: 0.83914 |  0:00:10s\n",
      "epoch 119| loss: 0.84999 |  0:00:10s\n",
      "epoch 120| loss: 0.83044 |  0:00:10s\n",
      "epoch 121| loss: 0.78418 |  0:00:10s\n",
      "epoch 122| loss: 0.82043 |  0:00:10s\n",
      "epoch 123| loss: 0.85184 |  0:00:10s\n",
      "epoch 124| loss: 0.85438 |  0:00:10s\n",
      "epoch 125| loss: 0.78787 |  0:00:10s\n",
      "epoch 126| loss: 0.80785 |  0:00:10s\n",
      "epoch 127| loss: 0.87394 |  0:00:10s\n",
      "epoch 128| loss: 0.81433 |  0:00:10s\n",
      "epoch 129| loss: 0.79323 |  0:00:11s\n",
      "epoch 130| loss: 0.76412 |  0:00:11s\n",
      "epoch 131| loss: 0.82232 |  0:00:11s\n",
      "epoch 132| loss: 0.80124 |  0:00:11s\n",
      "epoch 133| loss: 0.79888 |  0:00:11s\n",
      "epoch 134| loss: 0.82985 |  0:00:11s\n",
      "epoch 135| loss: 0.7887  |  0:00:11s\n",
      "epoch 136| loss: 0.83033 |  0:00:11s\n",
      "epoch 137| loss: 0.72763 |  0:00:11s\n",
      "epoch 138| loss: 0.75957 |  0:00:11s\n",
      "epoch 139| loss: 0.78257 |  0:00:11s\n",
      "epoch 140| loss: 0.73559 |  0:00:11s\n",
      "epoch 141| loss: 0.76729 |  0:00:12s\n",
      "epoch 142| loss: 0.71929 |  0:00:12s\n",
      "epoch 143| loss: 0.75942 |  0:00:12s\n",
      "epoch 144| loss: 0.73107 |  0:00:12s\n",
      "epoch 145| loss: 0.74638 |  0:00:12s\n",
      "epoch 146| loss: 0.78902 |  0:00:12s\n",
      "epoch 147| loss: 0.8059  |  0:00:12s\n",
      "epoch 148| loss: 0.78032 |  0:00:12s\n",
      "epoch 149| loss: 0.76043 |  0:00:12s\n",
      "epoch 150| loss: 0.74135 |  0:00:12s\n",
      "epoch 151| loss: 0.75616 |  0:00:12s\n",
      "epoch 152| loss: 0.7399  |  0:00:12s\n",
      "epoch 153| loss: 0.74343 |  0:00:13s\n",
      "epoch 154| loss: 0.76455 |  0:00:13s\n",
      "epoch 155| loss: 0.70581 |  0:00:13s\n",
      "epoch 156| loss: 0.74043 |  0:00:13s\n",
      "epoch 157| loss: 0.76977 |  0:00:13s\n",
      "epoch 158| loss: 0.77275 |  0:00:13s\n",
      "epoch 159| loss: 0.67033 |  0:00:13s\n",
      "epoch 160| loss: 0.73032 |  0:00:13s\n",
      "epoch 161| loss: 0.6768  |  0:00:13s\n",
      "epoch 162| loss: 0.73421 |  0:00:13s\n",
      "epoch 163| loss: 0.70054 |  0:00:13s\n",
      "epoch 164| loss: 0.77515 |  0:00:14s\n",
      "epoch 165| loss: 0.72733 |  0:00:14s\n",
      "epoch 166| loss: 0.72596 |  0:00:14s\n",
      "epoch 167| loss: 0.72075 |  0:00:14s\n",
      "epoch 168| loss: 0.75649 |  0:00:14s\n",
      "epoch 169| loss: 0.66543 |  0:00:14s\n",
      "epoch 170| loss: 0.71945 |  0:00:14s\n",
      "epoch 171| loss: 0.7286  |  0:00:14s\n",
      "epoch 172| loss: 0.72735 |  0:00:14s\n",
      "epoch 173| loss: 0.71662 |  0:00:14s\n",
      "epoch 174| loss: 0.77792 |  0:00:14s\n",
      "epoch 175| loss: 0.67816 |  0:00:15s\n",
      "epoch 176| loss: 0.66392 |  0:00:15s\n",
      "epoch 177| loss: 0.71733 |  0:00:15s\n",
      "epoch 178| loss: 0.75697 |  0:00:15s\n",
      "epoch 179| loss: 0.70813 |  0:00:15s\n",
      "epoch 180| loss: 0.71778 |  0:00:15s\n",
      "epoch 181| loss: 0.73538 |  0:00:15s\n",
      "epoch 182| loss: 0.75416 |  0:00:15s\n",
      "epoch 183| loss: 0.70933 |  0:00:15s\n",
      "epoch 184| loss: 0.73913 |  0:00:15s\n",
      "epoch 185| loss: 0.70727 |  0:00:15s\n",
      "epoch 186| loss: 0.71179 |  0:00:15s\n",
      "epoch 187| loss: 0.64777 |  0:00:16s\n",
      "epoch 188| loss: 0.66507 |  0:00:16s\n",
      "epoch 189| loss: 0.72579 |  0:00:16s\n",
      "epoch 190| loss: 0.67585 |  0:00:16s\n",
      "epoch 191| loss: 0.65394 |  0:00:16s\n",
      "epoch 192| loss: 0.73258 |  0:00:16s\n",
      "epoch 193| loss: 0.69629 |  0:00:16s\n",
      "epoch 194| loss: 0.71641 |  0:00:16s\n",
      "epoch 195| loss: 0.73008 |  0:00:16s\n",
      "epoch 196| loss: 0.65235 |  0:00:16s\n",
      "epoch 197| loss: 0.68996 |  0:00:16s\n",
      "epoch 198| loss: 0.67899 |  0:00:17s\n",
      "epoch 199| loss: 0.69092 |  0:00:17s\n",
      "XGBoost\n",
      "LGBM\n",
      "CatBoost\n",
      "RF\n",
      "GBDT\n",
      "SVR\n",
      "LR\n",
      "ANN\n",
      "TabNet\n",
      "[12:07:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "0:\tlearn: 1.3566617\ttotal: 5.09ms\tremaining: 2.03s\n",
      "1:\tlearn: 1.3294422\ttotal: 8.54ms\tremaining: 1.7s\n",
      "2:\tlearn: 1.2996483\ttotal: 11.9ms\tremaining: 1.57s\n",
      "3:\tlearn: 1.2690751\ttotal: 16.8ms\tremaining: 1.66s\n",
      "4:\tlearn: 1.2415355\ttotal: 21.1ms\tremaining: 1.67s\n",
      "5:\tlearn: 1.2219169\ttotal: 24.5ms\tremaining: 1.61s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6:\tlearn: 1.2040213\ttotal: 29ms\tremaining: 1.63s\n",
      "7:\tlearn: 1.1846447\ttotal: 33.6ms\tremaining: 1.65s\n",
      "8:\tlearn: 1.1617739\ttotal: 38.2ms\tremaining: 1.66s\n",
      "9:\tlearn: 1.1457493\ttotal: 41.9ms\tremaining: 1.64s\n",
      "10:\tlearn: 1.1248920\ttotal: 46.5ms\tremaining: 1.64s\n",
      "11:\tlearn: 1.1105886\ttotal: 51.3ms\tremaining: 1.66s\n",
      "12:\tlearn: 1.0964817\ttotal: 55.4ms\tremaining: 1.65s\n",
      "13:\tlearn: 1.0822459\ttotal: 60.6ms\tremaining: 1.67s\n",
      "14:\tlearn: 1.0686529\ttotal: 65.1ms\tremaining: 1.67s\n",
      "15:\tlearn: 1.0543102\ttotal: 68.6ms\tremaining: 1.65s\n",
      "16:\tlearn: 1.0416934\ttotal: 72.7ms\tremaining: 1.64s\n",
      "17:\tlearn: 1.0259883\ttotal: 76.5ms\tremaining: 1.62s\n",
      "18:\tlearn: 1.0113673\ttotal: 81.1ms\tremaining: 1.63s\n",
      "19:\tlearn: 1.0020374\ttotal: 85.6ms\tremaining: 1.63s\n",
      "20:\tlearn: 0.9911107\ttotal: 89.5ms\tremaining: 1.61s\n",
      "21:\tlearn: 0.9805389\ttotal: 94.6ms\tremaining: 1.63s\n",
      "22:\tlearn: 0.9671264\ttotal: 98.4ms\tremaining: 1.61s\n",
      "23:\tlearn: 0.9570475\ttotal: 102ms\tremaining: 1.6s\n",
      "24:\tlearn: 0.9452575\ttotal: 106ms\tremaining: 1.59s\n",
      "25:\tlearn: 0.9307626\ttotal: 112ms\tremaining: 1.6s\n",
      "26:\tlearn: 0.9187994\ttotal: 117ms\tremaining: 1.61s\n",
      "27:\tlearn: 0.9103874\ttotal: 120ms\tremaining: 1.6s\n",
      "28:\tlearn: 0.9006732\ttotal: 127ms\tremaining: 1.62s\n",
      "29:\tlearn: 0.8878142\ttotal: 131ms\tremaining: 1.62s\n",
      "30:\tlearn: 0.8783787\ttotal: 135ms\tremaining: 1.6s\n",
      "31:\tlearn: 0.8677164\ttotal: 138ms\tremaining: 1.59s\n",
      "32:\tlearn: 0.8581551\ttotal: 143ms\tremaining: 1.59s\n",
      "33:\tlearn: 0.8489265\ttotal: 146ms\tremaining: 1.57s\n",
      "34:\tlearn: 0.8418039\ttotal: 149ms\tremaining: 1.56s\n",
      "35:\tlearn: 0.8348273\ttotal: 153ms\tremaining: 1.54s\n",
      "36:\tlearn: 0.8260027\ttotal: 156ms\tremaining: 1.53s\n",
      "37:\tlearn: 0.8185289\ttotal: 160ms\tremaining: 1.52s\n",
      "38:\tlearn: 0.8091837\ttotal: 163ms\tremaining: 1.51s\n",
      "39:\tlearn: 0.8014447\ttotal: 166ms\tremaining: 1.5s\n",
      "40:\tlearn: 0.7948529\ttotal: 170ms\tremaining: 1.49s\n",
      "41:\tlearn: 0.7851830\ttotal: 175ms\tremaining: 1.49s\n",
      "42:\tlearn: 0.7747241\ttotal: 178ms\tremaining: 1.48s\n",
      "43:\tlearn: 0.7677937\ttotal: 181ms\tremaining: 1.46s\n",
      "44:\tlearn: 0.7605457\ttotal: 184ms\tremaining: 1.45s\n",
      "45:\tlearn: 0.7548576\ttotal: 187ms\tremaining: 1.44s\n",
      "46:\tlearn: 0.7479437\ttotal: 191ms\tremaining: 1.43s\n",
      "47:\tlearn: 0.7414506\ttotal: 194ms\tremaining: 1.43s\n",
      "48:\tlearn: 0.7361545\ttotal: 197ms\tremaining: 1.41s\n",
      "49:\tlearn: 0.7292799\ttotal: 201ms\tremaining: 1.41s\n",
      "50:\tlearn: 0.7236869\ttotal: 208ms\tremaining: 1.43s\n",
      "51:\tlearn: 0.7152444\ttotal: 212ms\tremaining: 1.42s\n",
      "52:\tlearn: 0.7103823\ttotal: 215ms\tremaining: 1.41s\n",
      "53:\tlearn: 0.6977187\ttotal: 218ms\tremaining: 1.39s\n",
      "54:\tlearn: 0.6879098\ttotal: 222ms\tremaining: 1.39s\n",
      "55:\tlearn: 0.6833057\ttotal: 225ms\tremaining: 1.38s\n",
      "56:\tlearn: 0.6762881\ttotal: 229ms\tremaining: 1.38s\n",
      "57:\tlearn: 0.6700252\ttotal: 232ms\tremaining: 1.37s\n",
      "58:\tlearn: 0.6650418\ttotal: 236ms\tremaining: 1.36s\n",
      "59:\tlearn: 0.6602471\ttotal: 240ms\tremaining: 1.36s\n",
      "60:\tlearn: 0.6540160\ttotal: 243ms\tremaining: 1.35s\n",
      "61:\tlearn: 0.6428917\ttotal: 246ms\tremaining: 1.34s\n",
      "62:\tlearn: 0.6396229\ttotal: 249ms\tremaining: 1.33s\n",
      "63:\tlearn: 0.6337777\ttotal: 253ms\tremaining: 1.33s\n",
      "64:\tlearn: 0.6279830\ttotal: 257ms\tremaining: 1.32s\n",
      "65:\tlearn: 0.6196906\ttotal: 260ms\tremaining: 1.32s\n",
      "66:\tlearn: 0.6133490\ttotal: 263ms\tremaining: 1.31s\n",
      "67:\tlearn: 0.6070051\ttotal: 268ms\tremaining: 1.31s\n",
      "68:\tlearn: 0.6003639\ttotal: 273ms\tremaining: 1.31s\n",
      "69:\tlearn: 0.5961075\ttotal: 276ms\tremaining: 1.3s\n",
      "70:\tlearn: 0.5895903\ttotal: 280ms\tremaining: 1.3s\n",
      "71:\tlearn: 0.5830828\ttotal: 284ms\tremaining: 1.29s\n",
      "72:\tlearn: 0.5783494\ttotal: 288ms\tremaining: 1.29s\n",
      "73:\tlearn: 0.5747209\ttotal: 291ms\tremaining: 1.28s\n",
      "74:\tlearn: 0.5699746\ttotal: 295ms\tremaining: 1.28s\n",
      "75:\tlearn: 0.5634698\ttotal: 298ms\tremaining: 1.27s\n",
      "76:\tlearn: 0.5566442\ttotal: 303ms\tremaining: 1.27s\n",
      "77:\tlearn: 0.5520962\ttotal: 307ms\tremaining: 1.26s\n",
      "78:\tlearn: 0.5452408\ttotal: 310ms\tremaining: 1.26s\n",
      "79:\tlearn: 0.5378999\ttotal: 313ms\tremaining: 1.25s\n",
      "80:\tlearn: 0.5321996\ttotal: 320ms\tremaining: 1.26s\n",
      "81:\tlearn: 0.5260975\ttotal: 323ms\tremaining: 1.25s\n",
      "82:\tlearn: 0.5184885\ttotal: 327ms\tremaining: 1.25s\n",
      "83:\tlearn: 0.5160404\ttotal: 331ms\tremaining: 1.25s\n",
      "84:\tlearn: 0.5106069\ttotal: 338ms\tremaining: 1.25s\n",
      "85:\tlearn: 0.5076574\ttotal: 341ms\tremaining: 1.25s\n",
      "86:\tlearn: 0.5020786\ttotal: 345ms\tremaining: 1.24s\n",
      "87:\tlearn: 0.4975540\ttotal: 349ms\tremaining: 1.24s\n",
      "88:\tlearn: 0.4924903\ttotal: 353ms\tremaining: 1.23s\n",
      "89:\tlearn: 0.4870897\ttotal: 357ms\tremaining: 1.23s\n",
      "90:\tlearn: 0.4826014\ttotal: 360ms\tremaining: 1.22s\n",
      "91:\tlearn: 0.4758187\ttotal: 366ms\tremaining: 1.22s\n",
      "92:\tlearn: 0.4710163\ttotal: 369ms\tremaining: 1.22s\n",
      "93:\tlearn: 0.4659257\ttotal: 373ms\tremaining: 1.21s\n",
      "94:\tlearn: 0.4636419\ttotal: 376ms\tremaining: 1.21s\n",
      "95:\tlearn: 0.4586943\ttotal: 381ms\tremaining: 1.21s\n",
      "96:\tlearn: 0.4553281\ttotal: 386ms\tremaining: 1.21s\n",
      "97:\tlearn: 0.4526261\ttotal: 393ms\tremaining: 1.21s\n",
      "98:\tlearn: 0.4476269\ttotal: 397ms\tremaining: 1.21s\n",
      "99:\tlearn: 0.4427458\ttotal: 400ms\tremaining: 1.2s\n",
      "100:\tlearn: 0.4378299\ttotal: 404ms\tremaining: 1.19s\n",
      "101:\tlearn: 0.4320053\ttotal: 408ms\tremaining: 1.19s\n",
      "102:\tlearn: 0.4298065\ttotal: 412ms\tremaining: 1.19s\n",
      "103:\tlearn: 0.4256704\ttotal: 416ms\tremaining: 1.18s\n",
      "104:\tlearn: 0.4211214\ttotal: 419ms\tremaining: 1.18s\n",
      "105:\tlearn: 0.4175066\ttotal: 423ms\tremaining: 1.17s\n",
      "106:\tlearn: 0.4126922\ttotal: 428ms\tremaining: 1.17s\n",
      "107:\tlearn: 0.4092861\ttotal: 432ms\tremaining: 1.17s\n",
      "108:\tlearn: 0.4050903\ttotal: 435ms\tremaining: 1.16s\n",
      "109:\tlearn: 0.4003286\ttotal: 439ms\tremaining: 1.16s\n",
      "110:\tlearn: 0.3968260\ttotal: 445ms\tremaining: 1.16s\n",
      "111:\tlearn: 0.3930661\ttotal: 449ms\tremaining: 1.15s\n",
      "112:\tlearn: 0.3877145\ttotal: 454ms\tremaining: 1.15s\n",
      "113:\tlearn: 0.3847313\ttotal: 460ms\tremaining: 1.15s\n",
      "114:\tlearn: 0.3812011\ttotal: 464ms\tremaining: 1.15s\n",
      "115:\tlearn: 0.3776864\ttotal: 467ms\tremaining: 1.14s\n",
      "116:\tlearn: 0.3743902\ttotal: 471ms\tremaining: 1.14s\n",
      "117:\tlearn: 0.3708630\ttotal: 476ms\tremaining: 1.14s\n",
      "118:\tlearn: 0.3677873\ttotal: 479ms\tremaining: 1.13s\n",
      "119:\tlearn: 0.3645537\ttotal: 483ms\tremaining: 1.13s\n",
      "120:\tlearn: 0.3613090\ttotal: 487ms\tremaining: 1.12s\n",
      "121:\tlearn: 0.3587423\ttotal: 491ms\tremaining: 1.12s\n",
      "122:\tlearn: 0.3548050\ttotal: 495ms\tremaining: 1.11s\n",
      "123:\tlearn: 0.3517954\ttotal: 499ms\tremaining: 1.11s\n",
      "124:\tlearn: 0.3504105\ttotal: 502ms\tremaining: 1.1s\n",
      "125:\tlearn: 0.3479746\ttotal: 506ms\tremaining: 1.1s\n",
      "126:\tlearn: 0.3447768\ttotal: 512ms\tremaining: 1.1s\n",
      "127:\tlearn: 0.3421764\ttotal: 516ms\tremaining: 1.09s\n",
      "128:\tlearn: 0.3407571\ttotal: 519ms\tremaining: 1.09s\n",
      "129:\tlearn: 0.3379147\ttotal: 526ms\tremaining: 1.09s\n",
      "130:\tlearn: 0.3360694\ttotal: 530ms\tremaining: 1.09s\n",
      "131:\tlearn: 0.3326319\ttotal: 533ms\tremaining: 1.08s\n",
      "132:\tlearn: 0.3288695\ttotal: 536ms\tremaining: 1.07s\n",
      "133:\tlearn: 0.3272446\ttotal: 541ms\tremaining: 1.07s\n",
      "134:\tlearn: 0.3252929\ttotal: 545ms\tremaining: 1.07s\n",
      "135:\tlearn: 0.3218873\ttotal: 548ms\tremaining: 1.06s\n",
      "136:\tlearn: 0.3195805\ttotal: 551ms\tremaining: 1.06s\n",
      "137:\tlearn: 0.3160365\ttotal: 556ms\tremaining: 1.05s\n",
      "138:\tlearn: 0.3133876\ttotal: 559ms\tremaining: 1.05s\n",
      "139:\tlearn: 0.3116652\ttotal: 563ms\tremaining: 1.05s\n",
      "140:\tlearn: 0.3088364\ttotal: 566ms\tremaining: 1.04s\n",
      "141:\tlearn: 0.3065665\ttotal: 571ms\tremaining: 1.04s\n",
      "142:\tlearn: 0.3041086\ttotal: 575ms\tremaining: 1.03s\n",
      "143:\tlearn: 0.3018022\ttotal: 579ms\tremaining: 1.03s\n",
      "144:\tlearn: 0.2997138\ttotal: 582ms\tremaining: 1.02s\n",
      "145:\tlearn: 0.2968523\ttotal: 589ms\tremaining: 1.02s\n",
      "146:\tlearn: 0.2945942\ttotal: 593ms\tremaining: 1.02s\n",
      "147:\tlearn: 0.2934917\ttotal: 596ms\tremaining: 1.01s\n",
      "148:\tlearn: 0.2906103\ttotal: 600ms\tremaining: 1.01s\n",
      "149:\tlearn: 0.2885206\ttotal: 604ms\tremaining: 1.01s\n",
      "150:\tlearn: 0.2867866\ttotal: 608ms\tremaining: 1s\n",
      "151:\tlearn: 0.2850413\ttotal: 611ms\tremaining: 997ms\n",
      "152:\tlearn: 0.2825027\ttotal: 614ms\tremaining: 991ms\n",
      "153:\tlearn: 0.2800338\ttotal: 618ms\tremaining: 987ms\n",
      "154:\tlearn: 0.2781000\ttotal: 622ms\tremaining: 983ms\n",
      "155:\tlearn: 0.2759615\ttotal: 625ms\tremaining: 978ms\n",
      "156:\tlearn: 0.2744613\ttotal: 628ms\tremaining: 972ms\n",
      "157:\tlearn: 0.2724845\ttotal: 632ms\tremaining: 968ms\n",
      "158:\tlearn: 0.2700338\ttotal: 636ms\tremaining: 964ms\n",
      "159:\tlearn: 0.2687643\ttotal: 641ms\tremaining: 961ms\n",
      "160:\tlearn: 0.2675292\ttotal: 644ms\tremaining: 956ms\n",
      "161:\tlearn: 0.2655624\ttotal: 648ms\tremaining: 951ms\n",
      "162:\tlearn: 0.2629543\ttotal: 653ms\tremaining: 949ms\n",
      "163:\tlearn: 0.2606680\ttotal: 657ms\tremaining: 945ms\n",
      "164:\tlearn: 0.2587681\ttotal: 660ms\tremaining: 940ms\n",
      "165:\tlearn: 0.2567510\ttotal: 663ms\tremaining: 935ms\n",
      "166:\tlearn: 0.2548326\ttotal: 667ms\tremaining: 931ms\n",
      "167:\tlearn: 0.2532068\ttotal: 671ms\tremaining: 926ms\n",
      "168:\tlearn: 0.2514193\ttotal: 675ms\tremaining: 922ms\n",
      "169:\tlearn: 0.2502248\ttotal: 678ms\tremaining: 917ms\n",
      "170:\tlearn: 0.2480796\ttotal: 683ms\tremaining: 914ms\n",
      "171:\tlearn: 0.2462630\ttotal: 686ms\tremaining: 909ms\n",
      "172:\tlearn: 0.2445865\ttotal: 689ms\tremaining: 904ms\n",
      "173:\tlearn: 0.2428412\ttotal: 692ms\tremaining: 899ms\n",
      "174:\tlearn: 0.2404600\ttotal: 696ms\tremaining: 894ms\n",
      "175:\tlearn: 0.2389593\ttotal: 700ms\tremaining: 891ms\n",
      "176:\tlearn: 0.2370164\ttotal: 705ms\tremaining: 888ms\n",
      "177:\tlearn: 0.2351989\ttotal: 710ms\tremaining: 885ms\n",
      "178:\tlearn: 0.2328494\ttotal: 714ms\tremaining: 881ms\n",
      "179:\tlearn: 0.2314143\ttotal: 717ms\tremaining: 876ms\n",
      "180:\tlearn: 0.2300902\ttotal: 721ms\tremaining: 872ms\n",
      "181:\tlearn: 0.2285495\ttotal: 724ms\tremaining: 867ms\n",
      "182:\tlearn: 0.2271610\ttotal: 727ms\tremaining: 862ms\n",
      "183:\tlearn: 0.2257786\ttotal: 731ms\tremaining: 858ms\n",
      "184:\tlearn: 0.2239753\ttotal: 734ms\tremaining: 853ms\n",
      "185:\tlearn: 0.2224918\ttotal: 738ms\tremaining: 849ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186:\tlearn: 0.2209820\ttotal: 745ms\tremaining: 848ms\n",
      "187:\tlearn: 0.2195460\ttotal: 750ms\tremaining: 845ms\n",
      "188:\tlearn: 0.2186494\ttotal: 754ms\tremaining: 842ms\n",
      "189:\tlearn: 0.2173397\ttotal: 759ms\tremaining: 839ms\n",
      "190:\tlearn: 0.2157889\ttotal: 763ms\tremaining: 835ms\n",
      "191:\tlearn: 0.2142388\ttotal: 768ms\tremaining: 832ms\n",
      "192:\tlearn: 0.2128014\ttotal: 773ms\tremaining: 829ms\n",
      "193:\tlearn: 0.2116733\ttotal: 779ms\tremaining: 827ms\n",
      "194:\tlearn: 0.2095356\ttotal: 784ms\tremaining: 824ms\n",
      "195:\tlearn: 0.2081999\ttotal: 788ms\tremaining: 820ms\n",
      "196:\tlearn: 0.2072227\ttotal: 793ms\tremaining: 817ms\n",
      "197:\tlearn: 0.2064280\ttotal: 798ms\tremaining: 814ms\n",
      "198:\tlearn: 0.2051247\ttotal: 801ms\tremaining: 809ms\n",
      "199:\tlearn: 0.2038189\ttotal: 805ms\tremaining: 805ms\n",
      "200:\tlearn: 0.2025801\ttotal: 810ms\tremaining: 802ms\n",
      "201:\tlearn: 0.2016165\ttotal: 814ms\tremaining: 798ms\n",
      "202:\tlearn: 0.2006633\ttotal: 818ms\tremaining: 793ms\n",
      "203:\tlearn: 0.1994908\ttotal: 821ms\tremaining: 789ms\n",
      "204:\tlearn: 0.1979543\ttotal: 825ms\tremaining: 785ms\n",
      "205:\tlearn: 0.1963532\ttotal: 828ms\tremaining: 780ms\n",
      "206:\tlearn: 0.1947572\ttotal: 831ms\tremaining: 775ms\n",
      "207:\tlearn: 0.1932683\ttotal: 835ms\tremaining: 771ms\n",
      "208:\tlearn: 0.1922773\ttotal: 839ms\tremaining: 766ms\n",
      "209:\tlearn: 0.1912583\ttotal: 843ms\tremaining: 762ms\n",
      "210:\tlearn: 0.1894529\ttotal: 846ms\tremaining: 758ms\n",
      "211:\tlearn: 0.1884061\ttotal: 849ms\tremaining: 753ms\n",
      "212:\tlearn: 0.1868863\ttotal: 852ms\tremaining: 748ms\n",
      "213:\tlearn: 0.1856869\ttotal: 856ms\tremaining: 744ms\n",
      "214:\tlearn: 0.1844396\ttotal: 861ms\tremaining: 740ms\n",
      "215:\tlearn: 0.1833234\ttotal: 864ms\tremaining: 736ms\n",
      "216:\tlearn: 0.1827089\ttotal: 867ms\tremaining: 732ms\n",
      "217:\tlearn: 0.1813107\ttotal: 873ms\tremaining: 729ms\n",
      "218:\tlearn: 0.1803998\ttotal: 876ms\tremaining: 724ms\n",
      "219:\tlearn: 0.1792852\ttotal: 880ms\tremaining: 720ms\n",
      "220:\tlearn: 0.1782977\ttotal: 883ms\tremaining: 715ms\n",
      "221:\tlearn: 0.1770629\ttotal: 886ms\tremaining: 711ms\n",
      "222:\tlearn: 0.1760761\ttotal: 890ms\tremaining: 706ms\n",
      "223:\tlearn: 0.1748581\ttotal: 893ms\tremaining: 702ms\n",
      "224:\tlearn: 0.1741317\ttotal: 896ms\tremaining: 697ms\n",
      "225:\tlearn: 0.1729880\ttotal: 899ms\tremaining: 692ms\n",
      "226:\tlearn: 0.1720057\ttotal: 903ms\tremaining: 688ms\n",
      "227:\tlearn: 0.1711287\ttotal: 906ms\tremaining: 684ms\n",
      "228:\tlearn: 0.1703194\ttotal: 909ms\tremaining: 679ms\n",
      "229:\tlearn: 0.1694915\ttotal: 912ms\tremaining: 674ms\n",
      "230:\tlearn: 0.1685051\ttotal: 915ms\tremaining: 670ms\n",
      "231:\tlearn: 0.1677050\ttotal: 919ms\tremaining: 666ms\n",
      "232:\tlearn: 0.1664536\ttotal: 923ms\tremaining: 661ms\n",
      "233:\tlearn: 0.1652572\ttotal: 927ms\tremaining: 658ms\n",
      "234:\tlearn: 0.1639996\ttotal: 931ms\tremaining: 653ms\n",
      "235:\tlearn: 0.1635841\ttotal: 936ms\tremaining: 651ms\n",
      "236:\tlearn: 0.1627644\ttotal: 940ms\tremaining: 646ms\n",
      "237:\tlearn: 0.1619726\ttotal: 943ms\tremaining: 642ms\n",
      "238:\tlearn: 0.1614336\ttotal: 947ms\tremaining: 638ms\n",
      "239:\tlearn: 0.1604584\ttotal: 950ms\tremaining: 634ms\n",
      "240:\tlearn: 0.1599963\ttotal: 954ms\tremaining: 629ms\n",
      "241:\tlearn: 0.1593624\ttotal: 957ms\tremaining: 625ms\n",
      "242:\tlearn: 0.1581999\ttotal: 961ms\tremaining: 621ms\n",
      "243:\tlearn: 0.1572626\ttotal: 964ms\tremaining: 616ms\n",
      "244:\tlearn: 0.1565865\ttotal: 968ms\tremaining: 612ms\n",
      "245:\tlearn: 0.1555644\ttotal: 971ms\tremaining: 608ms\n",
      "246:\tlearn: 0.1549989\ttotal: 974ms\tremaining: 603ms\n",
      "247:\tlearn: 0.1538385\ttotal: 977ms\tremaining: 599ms\n",
      "248:\tlearn: 0.1529251\ttotal: 981ms\tremaining: 595ms\n",
      "249:\tlearn: 0.1525602\ttotal: 984ms\tremaining: 590ms\n",
      "250:\tlearn: 0.1515902\ttotal: 987ms\tremaining: 586ms\n",
      "251:\tlearn: 0.1505438\ttotal: 991ms\tremaining: 582ms\n",
      "252:\tlearn: 0.1496862\ttotal: 994ms\tremaining: 578ms\n",
      "253:\tlearn: 0.1487186\ttotal: 998ms\tremaining: 574ms\n",
      "254:\tlearn: 0.1480910\ttotal: 1s\tremaining: 570ms\n",
      "255:\tlearn: 0.1473175\ttotal: 1.01s\tremaining: 566ms\n",
      "256:\tlearn: 0.1465967\ttotal: 1.01s\tremaining: 562ms\n",
      "257:\tlearn: 0.1461969\ttotal: 1.01s\tremaining: 557ms\n",
      "258:\tlearn: 0.1451732\ttotal: 1.01s\tremaining: 553ms\n",
      "259:\tlearn: 0.1445598\ttotal: 1.02s\tremaining: 548ms\n",
      "260:\tlearn: 0.1435987\ttotal: 1.02s\tremaining: 544ms\n",
      "261:\tlearn: 0.1427399\ttotal: 1.02s\tremaining: 540ms\n",
      "262:\tlearn: 0.1420839\ttotal: 1.03s\tremaining: 535ms\n",
      "263:\tlearn: 0.1411950\ttotal: 1.03s\tremaining: 531ms\n",
      "264:\tlearn: 0.1402308\ttotal: 1.03s\tremaining: 527ms\n",
      "265:\tlearn: 0.1395906\ttotal: 1.04s\tremaining: 523ms\n",
      "266:\tlearn: 0.1390047\ttotal: 1.04s\tremaining: 518ms\n",
      "267:\tlearn: 0.1384868\ttotal: 1.04s\tremaining: 514ms\n",
      "268:\tlearn: 0.1378405\ttotal: 1.05s\tremaining: 510ms\n",
      "269:\tlearn: 0.1369353\ttotal: 1.05s\tremaining: 506ms\n",
      "270:\tlearn: 0.1361970\ttotal: 1.05s\tremaining: 502ms\n",
      "271:\tlearn: 0.1356254\ttotal: 1.06s\tremaining: 498ms\n",
      "272:\tlearn: 0.1348620\ttotal: 1.06s\tremaining: 494ms\n",
      "273:\tlearn: 0.1341507\ttotal: 1.07s\tremaining: 491ms\n",
      "274:\tlearn: 0.1333316\ttotal: 1.07s\tremaining: 487ms\n",
      "275:\tlearn: 0.1328141\ttotal: 1.07s\tremaining: 483ms\n",
      "276:\tlearn: 0.1322914\ttotal: 1.08s\tremaining: 479ms\n",
      "277:\tlearn: 0.1317006\ttotal: 1.08s\tremaining: 475ms\n",
      "278:\tlearn: 0.1310322\ttotal: 1.08s\tremaining: 470ms\n",
      "279:\tlearn: 0.1300783\ttotal: 1.09s\tremaining: 466ms\n",
      "280:\tlearn: 0.1295117\ttotal: 1.09s\tremaining: 462ms\n",
      "281:\tlearn: 0.1288289\ttotal: 1.09s\tremaining: 458ms\n",
      "282:\tlearn: 0.1282775\ttotal: 1.1s\tremaining: 454ms\n",
      "283:\tlearn: 0.1275629\ttotal: 1.1s\tremaining: 450ms\n",
      "284:\tlearn: 0.1270053\ttotal: 1.1s\tremaining: 446ms\n",
      "285:\tlearn: 0.1263013\ttotal: 1.11s\tremaining: 442ms\n",
      "286:\tlearn: 0.1256148\ttotal: 1.11s\tremaining: 438ms\n",
      "287:\tlearn: 0.1247525\ttotal: 1.12s\tremaining: 435ms\n",
      "288:\tlearn: 0.1241374\ttotal: 1.12s\tremaining: 431ms\n",
      "289:\tlearn: 0.1236448\ttotal: 1.13s\tremaining: 427ms\n",
      "290:\tlearn: 0.1231178\ttotal: 1.13s\tremaining: 423ms\n",
      "291:\tlearn: 0.1222754\ttotal: 1.13s\tremaining: 420ms\n",
      "292:\tlearn: 0.1216922\ttotal: 1.14s\tremaining: 415ms\n",
      "293:\tlearn: 0.1211105\ttotal: 1.14s\tremaining: 412ms\n",
      "294:\tlearn: 0.1207422\ttotal: 1.14s\tremaining: 408ms\n",
      "295:\tlearn: 0.1202946\ttotal: 1.15s\tremaining: 403ms\n",
      "296:\tlearn: 0.1196198\ttotal: 1.15s\tremaining: 399ms\n",
      "297:\tlearn: 0.1190204\ttotal: 1.15s\tremaining: 395ms\n",
      "298:\tlearn: 0.1183832\ttotal: 1.16s\tremaining: 391ms\n",
      "299:\tlearn: 0.1176801\ttotal: 1.16s\tremaining: 387ms\n",
      "300:\tlearn: 0.1172757\ttotal: 1.16s\tremaining: 383ms\n",
      "301:\tlearn: 0.1167726\ttotal: 1.17s\tremaining: 379ms\n",
      "302:\tlearn: 0.1161812\ttotal: 1.17s\tremaining: 375ms\n",
      "303:\tlearn: 0.1155896\ttotal: 1.17s\tremaining: 371ms\n",
      "304:\tlearn: 0.1153310\ttotal: 1.18s\tremaining: 367ms\n",
      "305:\tlearn: 0.1150338\ttotal: 1.18s\tremaining: 363ms\n",
      "306:\tlearn: 0.1146727\ttotal: 1.19s\tremaining: 360ms\n",
      "307:\tlearn: 0.1143791\ttotal: 1.19s\tremaining: 356ms\n",
      "308:\tlearn: 0.1139351\ttotal: 1.19s\tremaining: 352ms\n",
      "309:\tlearn: 0.1133180\ttotal: 1.2s\tremaining: 347ms\n",
      "310:\tlearn: 0.1129612\ttotal: 1.2s\tremaining: 343ms\n",
      "311:\tlearn: 0.1124892\ttotal: 1.2s\tremaining: 339ms\n",
      "312:\tlearn: 0.1119498\ttotal: 1.21s\tremaining: 336ms\n",
      "313:\tlearn: 0.1114631\ttotal: 1.21s\tremaining: 332ms\n",
      "314:\tlearn: 0.1109805\ttotal: 1.21s\tremaining: 328ms\n",
      "315:\tlearn: 0.1104471\ttotal: 1.22s\tremaining: 324ms\n",
      "316:\tlearn: 0.1099197\ttotal: 1.22s\tremaining: 320ms\n",
      "317:\tlearn: 0.1093500\ttotal: 1.22s\tremaining: 316ms\n",
      "318:\tlearn: 0.1088751\ttotal: 1.23s\tremaining: 312ms\n",
      "319:\tlearn: 0.1083947\ttotal: 1.23s\tremaining: 308ms\n",
      "320:\tlearn: 0.1079215\ttotal: 1.23s\tremaining: 304ms\n",
      "321:\tlearn: 0.1072986\ttotal: 1.24s\tremaining: 300ms\n",
      "322:\tlearn: 0.1069548\ttotal: 1.24s\tremaining: 296ms\n",
      "323:\tlearn: 0.1065517\ttotal: 1.25s\tremaining: 292ms\n",
      "324:\tlearn: 0.1062074\ttotal: 1.25s\tremaining: 288ms\n",
      "325:\tlearn: 0.1057781\ttotal: 1.25s\tremaining: 285ms\n",
      "326:\tlearn: 0.1051872\ttotal: 1.26s\tremaining: 281ms\n",
      "327:\tlearn: 0.1046048\ttotal: 1.26s\tremaining: 277ms\n",
      "328:\tlearn: 0.1043093\ttotal: 1.26s\tremaining: 273ms\n",
      "329:\tlearn: 0.1038843\ttotal: 1.27s\tremaining: 269ms\n",
      "330:\tlearn: 0.1032027\ttotal: 1.27s\tremaining: 265ms\n",
      "331:\tlearn: 0.1027572\ttotal: 1.27s\tremaining: 261ms\n",
      "332:\tlearn: 0.1025731\ttotal: 1.28s\tremaining: 257ms\n",
      "333:\tlearn: 0.1021623\ttotal: 1.28s\tremaining: 253ms\n",
      "334:\tlearn: 0.1015747\ttotal: 1.28s\tremaining: 249ms\n",
      "335:\tlearn: 0.1010919\ttotal: 1.29s\tremaining: 246ms\n",
      "336:\tlearn: 0.1005647\ttotal: 1.29s\tremaining: 242ms\n",
      "337:\tlearn: 0.1000778\ttotal: 1.3s\tremaining: 238ms\n",
      "338:\tlearn: 0.0997034\ttotal: 1.3s\tremaining: 234ms\n",
      "339:\tlearn: 0.0991639\ttotal: 1.3s\tremaining: 230ms\n",
      "340:\tlearn: 0.0986806\ttotal: 1.31s\tremaining: 226ms\n",
      "341:\tlearn: 0.0983749\ttotal: 1.31s\tremaining: 223ms\n",
      "342:\tlearn: 0.0980530\ttotal: 1.32s\tremaining: 219ms\n",
      "343:\tlearn: 0.0977108\ttotal: 1.32s\tremaining: 215ms\n",
      "344:\tlearn: 0.0973803\ttotal: 1.32s\tremaining: 211ms\n",
      "345:\tlearn: 0.0968761\ttotal: 1.33s\tremaining: 207ms\n",
      "346:\tlearn: 0.0965163\ttotal: 1.33s\tremaining: 203ms\n",
      "347:\tlearn: 0.0961746\ttotal: 1.33s\tremaining: 199ms\n",
      "348:\tlearn: 0.0959698\ttotal: 1.34s\tremaining: 196ms\n",
      "349:\tlearn: 0.0956077\ttotal: 1.34s\tremaining: 192ms\n",
      "350:\tlearn: 0.0953301\ttotal: 1.34s\tremaining: 188ms\n",
      "351:\tlearn: 0.0949328\ttotal: 1.35s\tremaining: 184ms\n",
      "352:\tlearn: 0.0944025\ttotal: 1.35s\tremaining: 180ms\n",
      "353:\tlearn: 0.0941077\ttotal: 1.35s\tremaining: 176ms\n",
      "354:\tlearn: 0.0937605\ttotal: 1.36s\tremaining: 172ms\n",
      "355:\tlearn: 0.0934601\ttotal: 1.36s\tremaining: 168ms\n",
      "356:\tlearn: 0.0930419\ttotal: 1.36s\tremaining: 164ms\n",
      "357:\tlearn: 0.0925145\ttotal: 1.37s\tremaining: 161ms\n",
      "358:\tlearn: 0.0922496\ttotal: 1.37s\tremaining: 157ms\n",
      "359:\tlearn: 0.0918598\ttotal: 1.38s\tremaining: 153ms\n",
      "360:\tlearn: 0.0915892\ttotal: 1.38s\tremaining: 149ms\n",
      "361:\tlearn: 0.0912333\ttotal: 1.38s\tremaining: 145ms\n",
      "362:\tlearn: 0.0910150\ttotal: 1.39s\tremaining: 141ms\n",
      "363:\tlearn: 0.0906530\ttotal: 1.39s\tremaining: 137ms\n",
      "364:\tlearn: 0.0901368\ttotal: 1.39s\tremaining: 134ms\n",
      "365:\tlearn: 0.0897500\ttotal: 1.4s\tremaining: 130ms\n",
      "366:\tlearn: 0.0894033\ttotal: 1.4s\tremaining: 126ms\n",
      "367:\tlearn: 0.0890419\ttotal: 1.4s\tremaining: 122ms\n",
      "368:\tlearn: 0.0886896\ttotal: 1.41s\tremaining: 118ms\n",
      "369:\tlearn: 0.0883154\ttotal: 1.41s\tremaining: 114ms\n",
      "370:\tlearn: 0.0878883\ttotal: 1.41s\tremaining: 110ms\n",
      "371:\tlearn: 0.0874707\ttotal: 1.42s\tremaining: 107ms\n",
      "372:\tlearn: 0.0870892\ttotal: 1.42s\tremaining: 103ms\n",
      "373:\tlearn: 0.0869112\ttotal: 1.42s\tremaining: 98.9ms\n",
      "374:\tlearn: 0.0865970\ttotal: 1.43s\tremaining: 95.1ms\n",
      "375:\tlearn: 0.0864209\ttotal: 1.43s\tremaining: 91.3ms\n",
      "376:\tlearn: 0.0859735\ttotal: 1.43s\tremaining: 87.5ms\n",
      "377:\tlearn: 0.0855720\ttotal: 1.44s\tremaining: 83.6ms\n",
      "378:\tlearn: 0.0853674\ttotal: 1.44s\tremaining: 79.8ms\n",
      "379:\tlearn: 0.0850748\ttotal: 1.45s\tremaining: 76.1ms\n",
      "380:\tlearn: 0.0846637\ttotal: 1.45s\tremaining: 72.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381:\tlearn: 0.0843816\ttotal: 1.45s\tremaining: 68.4ms\n",
      "382:\tlearn: 0.0840798\ttotal: 1.46s\tremaining: 64.6ms\n",
      "383:\tlearn: 0.0837859\ttotal: 1.46s\tremaining: 60.8ms\n",
      "384:\tlearn: 0.0834283\ttotal: 1.46s\tremaining: 57ms\n",
      "385:\tlearn: 0.0830778\ttotal: 1.47s\tremaining: 53.2ms\n",
      "386:\tlearn: 0.0828390\ttotal: 1.47s\tremaining: 49.4ms\n",
      "387:\tlearn: 0.0824805\ttotal: 1.47s\tremaining: 45.6ms\n",
      "388:\tlearn: 0.0822819\ttotal: 1.48s\tremaining: 41.8ms\n",
      "389:\tlearn: 0.0819088\ttotal: 1.48s\tremaining: 38ms\n",
      "390:\tlearn: 0.0815462\ttotal: 1.48s\tremaining: 34.2ms\n",
      "391:\tlearn: 0.0812878\ttotal: 1.49s\tremaining: 30.4ms\n",
      "392:\tlearn: 0.0811161\ttotal: 1.49s\tremaining: 26.6ms\n",
      "393:\tlearn: 0.0808698\ttotal: 1.5s\tremaining: 22.8ms\n",
      "394:\tlearn: 0.0806880\ttotal: 1.5s\tremaining: 19ms\n",
      "395:\tlearn: 0.0804298\ttotal: 1.5s\tremaining: 15.2ms\n",
      "396:\tlearn: 0.0800562\ttotal: 1.51s\tremaining: 11.4ms\n",
      "397:\tlearn: 0.0797769\ttotal: 1.51s\tremaining: 7.6ms\n",
      "398:\tlearn: 0.0796336\ttotal: 1.51s\tremaining: 3.8ms\n",
      "399:\tlearn: 0.0793788\ttotal: 1.52s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 2.01171 |  0:00:00s\n",
      "epoch 1  | loss: 1.56125 |  0:00:00s\n",
      "epoch 2  | loss: 1.40811 |  0:00:00s\n",
      "epoch 3  | loss: 1.46402 |  0:00:00s\n",
      "epoch 4  | loss: 1.40589 |  0:00:00s\n",
      "epoch 5  | loss: 1.3868  |  0:00:00s\n",
      "epoch 6  | loss: 1.34092 |  0:00:00s\n",
      "epoch 7  | loss: 1.34372 |  0:00:00s\n",
      "epoch 8  | loss: 1.30117 |  0:00:00s\n",
      "epoch 9  | loss: 1.29123 |  0:00:00s\n",
      "epoch 10 | loss: 1.32043 |  0:00:01s\n",
      "epoch 11 | loss: 1.2856  |  0:00:01s\n",
      "epoch 12 | loss: 1.28514 |  0:00:01s\n",
      "epoch 13 | loss: 1.27145 |  0:00:01s\n",
      "epoch 14 | loss: 1.23516 |  0:00:01s\n",
      "epoch 15 | loss: 1.24489 |  0:00:01s\n",
      "epoch 16 | loss: 1.23773 |  0:00:01s\n",
      "epoch 17 | loss: 1.2238  |  0:00:01s\n",
      "epoch 18 | loss: 1.2151  |  0:00:01s\n",
      "epoch 19 | loss: 1.23609 |  0:00:01s\n",
      "epoch 20 | loss: 1.23284 |  0:00:01s\n",
      "epoch 21 | loss: 1.18608 |  0:00:02s\n",
      "epoch 22 | loss: 1.18505 |  0:00:02s\n",
      "epoch 23 | loss: 1.20406 |  0:00:02s\n",
      "epoch 24 | loss: 1.17384 |  0:00:02s\n",
      "epoch 25 | loss: 1.18673 |  0:00:02s\n",
      "epoch 26 | loss: 1.19902 |  0:00:02s\n",
      "epoch 27 | loss: 1.21058 |  0:00:02s\n",
      "epoch 28 | loss: 1.13614 |  0:00:02s\n",
      "epoch 29 | loss: 1.16906 |  0:00:02s\n",
      "epoch 30 | loss: 1.15599 |  0:00:03s\n",
      "epoch 31 | loss: 1.15874 |  0:00:03s\n",
      "epoch 32 | loss: 1.14645 |  0:00:03s\n",
      "epoch 33 | loss: 1.15129 |  0:00:03s\n",
      "epoch 34 | loss: 1.12229 |  0:00:03s\n",
      "epoch 35 | loss: 1.13116 |  0:00:03s\n",
      "epoch 36 | loss: 1.154   |  0:00:03s\n",
      "epoch 37 | loss: 1.11078 |  0:00:03s\n",
      "epoch 38 | loss: 1.10436 |  0:00:03s\n",
      "epoch 39 | loss: 1.09244 |  0:00:03s\n",
      "epoch 40 | loss: 1.05371 |  0:00:04s\n",
      "epoch 41 | loss: 1.09794 |  0:00:04s\n",
      "epoch 42 | loss: 1.06146 |  0:00:04s\n",
      "epoch 43 | loss: 1.10703 |  0:00:04s\n",
      "epoch 44 | loss: 1.12346 |  0:00:04s\n",
      "epoch 45 | loss: 1.12466 |  0:00:04s\n",
      "epoch 46 | loss: 1.04123 |  0:00:04s\n",
      "epoch 47 | loss: 1.08941 |  0:00:04s\n",
      "epoch 48 | loss: 1.07118 |  0:00:04s\n",
      "epoch 49 | loss: 1.08729 |  0:00:04s\n",
      "epoch 50 | loss: 1.05921 |  0:00:04s\n",
      "epoch 51 | loss: 1.11024 |  0:00:04s\n",
      "epoch 52 | loss: 1.06279 |  0:00:04s\n",
      "epoch 53 | loss: 1.06245 |  0:00:05s\n",
      "epoch 54 | loss: 1.05297 |  0:00:05s\n",
      "epoch 55 | loss: 1.04572 |  0:00:05s\n",
      "epoch 56 | loss: 1.06024 |  0:00:05s\n",
      "epoch 57 | loss: 1.01426 |  0:00:05s\n",
      "epoch 58 | loss: 1.03403 |  0:00:05s\n",
      "epoch 59 | loss: 1.05112 |  0:00:05s\n",
      "epoch 60 | loss: 1.06327 |  0:00:05s\n",
      "epoch 61 | loss: 1.07147 |  0:00:05s\n",
      "epoch 62 | loss: 1.11137 |  0:00:05s\n",
      "epoch 63 | loss: 1.02721 |  0:00:05s\n",
      "epoch 64 | loss: 1.02062 |  0:00:05s\n",
      "epoch 65 | loss: 1.00596 |  0:00:06s\n",
      "epoch 66 | loss: 1.0499  |  0:00:06s\n",
      "epoch 67 | loss: 1.03034 |  0:00:06s\n",
      "epoch 68 | loss: 1.02596 |  0:00:06s\n",
      "epoch 69 | loss: 1.01229 |  0:00:06s\n",
      "epoch 70 | loss: 0.9746  |  0:00:06s\n",
      "epoch 71 | loss: 0.95144 |  0:00:06s\n",
      "epoch 72 | loss: 0.99668 |  0:00:06s\n",
      "epoch 73 | loss: 0.94688 |  0:00:06s\n",
      "epoch 74 | loss: 0.97016 |  0:00:06s\n",
      "epoch 75 | loss: 0.97832 |  0:00:06s\n",
      "epoch 76 | loss: 0.97903 |  0:00:06s\n",
      "epoch 77 | loss: 0.97572 |  0:00:07s\n",
      "epoch 78 | loss: 0.9671  |  0:00:07s\n",
      "epoch 79 | loss: 0.94487 |  0:00:07s\n",
      "epoch 80 | loss: 0.94288 |  0:00:07s\n",
      "epoch 81 | loss: 0.89777 |  0:00:07s\n",
      "epoch 82 | loss: 0.9327  |  0:00:07s\n",
      "epoch 83 | loss: 0.89749 |  0:00:07s\n",
      "epoch 84 | loss: 0.93207 |  0:00:07s\n",
      "epoch 85 | loss: 0.95974 |  0:00:07s\n",
      "epoch 86 | loss: 0.92455 |  0:00:07s\n",
      "epoch 87 | loss: 0.93783 |  0:00:07s\n",
      "epoch 88 | loss: 0.95198 |  0:00:07s\n",
      "epoch 89 | loss: 0.88772 |  0:00:08s\n",
      "epoch 90 | loss: 0.94533 |  0:00:08s\n",
      "epoch 91 | loss: 0.88476 |  0:00:08s\n",
      "epoch 92 | loss: 0.88234 |  0:00:08s\n",
      "epoch 93 | loss: 0.88735 |  0:00:08s\n",
      "epoch 94 | loss: 0.89029 |  0:00:08s\n",
      "epoch 95 | loss: 0.87453 |  0:00:08s\n",
      "epoch 96 | loss: 0.81986 |  0:00:08s\n",
      "epoch 97 | loss: 0.87513 |  0:00:08s\n",
      "epoch 98 | loss: 0.91504 |  0:00:08s\n",
      "epoch 99 | loss: 0.85591 |  0:00:08s\n",
      "epoch 100| loss: 0.92134 |  0:00:08s\n",
      "epoch 101| loss: 0.94236 |  0:00:08s\n",
      "epoch 102| loss: 0.86178 |  0:00:09s\n",
      "epoch 103| loss: 0.88997 |  0:00:09s\n",
      "epoch 104| loss: 0.90679 |  0:00:09s\n",
      "epoch 105| loss: 0.88548 |  0:00:09s\n",
      "epoch 106| loss: 0.92016 |  0:00:09s\n",
      "epoch 107| loss: 0.86852 |  0:00:09s\n",
      "epoch 108| loss: 0.87862 |  0:00:09s\n",
      "epoch 109| loss: 0.88647 |  0:00:09s\n",
      "epoch 110| loss: 0.83956 |  0:00:09s\n",
      "epoch 111| loss: 0.85423 |  0:00:09s\n",
      "epoch 112| loss: 0.82345 |  0:00:09s\n",
      "epoch 113| loss: 0.88579 |  0:00:09s\n",
      "epoch 114| loss: 0.86687 |  0:00:10s\n",
      "epoch 115| loss: 0.8563  |  0:00:10s\n",
      "epoch 116| loss: 0.88274 |  0:00:10s\n",
      "epoch 117| loss: 0.83578 |  0:00:10s\n",
      "epoch 118| loss: 0.83399 |  0:00:10s\n",
      "epoch 119| loss: 0.85428 |  0:00:10s\n",
      "epoch 120| loss: 0.81329 |  0:00:10s\n",
      "epoch 121| loss: 0.81291 |  0:00:10s\n",
      "epoch 122| loss: 0.78683 |  0:00:10s\n",
      "epoch 123| loss: 0.81671 |  0:00:10s\n",
      "epoch 124| loss: 0.7899  |  0:00:10s\n",
      "epoch 125| loss: 0.78393 |  0:00:10s\n",
      "epoch 126| loss: 0.85545 |  0:00:11s\n",
      "epoch 127| loss: 0.83658 |  0:00:11s\n",
      "epoch 128| loss: 0.82017 |  0:00:11s\n",
      "epoch 129| loss: 0.79246 |  0:00:11s\n",
      "epoch 130| loss: 0.8038  |  0:00:11s\n",
      "epoch 131| loss: 0.80695 |  0:00:11s\n",
      "epoch 132| loss: 0.79031 |  0:00:11s\n",
      "epoch 133| loss: 0.77873 |  0:00:11s\n",
      "epoch 134| loss: 0.7461  |  0:00:11s\n",
      "epoch 135| loss: 0.76489 |  0:00:11s\n",
      "epoch 136| loss: 0.69375 |  0:00:11s\n",
      "epoch 137| loss: 0.73724 |  0:00:11s\n",
      "epoch 138| loss: 0.71639 |  0:00:12s\n",
      "epoch 139| loss: 0.67845 |  0:00:12s\n",
      "epoch 140| loss: 0.70343 |  0:00:12s\n",
      "epoch 141| loss: 0.69769 |  0:00:12s\n",
      "epoch 142| loss: 0.71431 |  0:00:12s\n",
      "epoch 143| loss: 0.74149 |  0:00:12s\n",
      "epoch 144| loss: 0.72711 |  0:00:12s\n",
      "epoch 145| loss: 0.72372 |  0:00:12s\n",
      "epoch 146| loss: 0.67656 |  0:00:12s\n",
      "epoch 147| loss: 0.78626 |  0:00:12s\n",
      "epoch 148| loss: 0.71294 |  0:00:12s\n",
      "epoch 149| loss: 0.76974 |  0:00:12s\n",
      "epoch 150| loss: 0.68139 |  0:00:12s\n",
      "epoch 151| loss: 0.6608  |  0:00:13s\n",
      "epoch 152| loss: 0.68068 |  0:00:13s\n",
      "epoch 153| loss: 0.70379 |  0:00:13s\n",
      "epoch 154| loss: 0.65842 |  0:00:13s\n",
      "epoch 155| loss: 0.70807 |  0:00:13s\n",
      "epoch 156| loss: 0.72782 |  0:00:13s\n",
      "epoch 157| loss: 0.6755  |  0:00:13s\n",
      "epoch 158| loss: 0.74394 |  0:00:13s\n",
      "epoch 159| loss: 0.73756 |  0:00:13s\n",
      "epoch 160| loss: 0.63869 |  0:00:13s\n",
      "epoch 161| loss: 0.70503 |  0:00:13s\n",
      "epoch 162| loss: 0.69774 |  0:00:13s\n",
      "epoch 163| loss: 0.67849 |  0:00:14s\n",
      "epoch 164| loss: 0.64406 |  0:00:14s\n",
      "epoch 165| loss: 0.66759 |  0:00:14s\n",
      "epoch 166| loss: 0.64215 |  0:00:14s\n",
      "epoch 167| loss: 0.68958 |  0:00:14s\n",
      "epoch 168| loss: 0.63648 |  0:00:14s\n",
      "epoch 169| loss: 0.66428 |  0:00:14s\n",
      "epoch 170| loss: 0.61139 |  0:00:14s\n",
      "epoch 171| loss: 0.60847 |  0:00:14s\n",
      "epoch 172| loss: 0.65025 |  0:00:14s\n",
      "epoch 173| loss: 0.67329 |  0:00:14s\n",
      "epoch 174| loss: 0.66348 |  0:00:14s\n",
      "epoch 175| loss: 0.67358 |  0:00:14s\n",
      "epoch 176| loss: 0.71962 |  0:00:15s\n",
      "epoch 177| loss: 0.65816 |  0:00:15s\n",
      "epoch 178| loss: 0.6873  |  0:00:15s\n",
      "epoch 179| loss: 0.70177 |  0:00:15s\n",
      "epoch 180| loss: 0.65112 |  0:00:15s\n",
      "epoch 181| loss: 0.72899 |  0:00:15s\n",
      "epoch 182| loss: 0.6608  |  0:00:15s\n",
      "epoch 183| loss: 0.63461 |  0:00:15s\n",
      "epoch 184| loss: 0.57607 |  0:00:15s\n",
      "epoch 185| loss: 0.60031 |  0:00:15s\n",
      "epoch 186| loss: 0.5857  |  0:00:15s\n",
      "epoch 187| loss: 0.67365 |  0:00:15s\n",
      "epoch 188| loss: 0.58907 |  0:00:16s\n",
      "epoch 189| loss: 0.71038 |  0:00:16s\n",
      "epoch 190| loss: 0.68075 |  0:00:16s\n",
      "epoch 191| loss: 0.64147 |  0:00:16s\n",
      "epoch 192| loss: 0.58494 |  0:00:16s\n",
      "epoch 193| loss: 0.59909 |  0:00:16s\n",
      "epoch 194| loss: 0.58615 |  0:00:16s\n",
      "epoch 195| loss: 0.5504  |  0:00:16s\n",
      "epoch 196| loss: 0.65041 |  0:00:16s\n",
      "epoch 197| loss: 0.58058 |  0:00:16s\n",
      "epoch 198| loss: 0.61574 |  0:00:16s\n",
      "epoch 199| loss: 0.69436 |  0:00:16s\n",
      "XGBoost\n",
      "LGBM\n",
      "CatBoost\n",
      "RF\n",
      "GBDT\n",
      "SVR\n",
      "LR\n",
      "ANN\n",
      "TabNet\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 划分训练集和测试集，比例为8:2\n",
    "x = tran_x_sm.copy()\n",
    "y = tran_y_sm.copy()\n",
    "# 五折交叉验证\n",
    "kf = KFold(n_splits=5,random_state=seed_index,shuffle=True)\n",
    "\n",
    "df_temp_result=pd.DataFrame()\n",
    "temp_importance_list=[]\n",
    "for train_index, test_index in kf.split(x):\n",
    "    tran_x_kf,test_x_kf,tran_y_kf,test_y_kf=x.values[train_index],x.values[test_index],y.values[train_index],y.values[test_index]\n",
    "    from sklearn.metrics import r2_score,average_precision_score,precision_recall_curve\n",
    "    from sklearn.metrics import precision_score,recall_score,f1_score,roc_auc_score,accuracy_score\n",
    "    import xgboost\n",
    "    # XGBoost模型\n",
    "    xgb_model=xgboost.XGBClassifier(max_depth=8,\n",
    "                            learning_rate=0.03,\n",
    "                            n_estimators=500,\n",
    "                            min_child_weight=0.5,\n",
    "                            eta=0.1,\n",
    "                            gamma=0.5,\n",
    "                            reg_lambda=5,\n",
    "                            subsample=0.8,\n",
    "                            colsample_bytree=0.8,\n",
    "                            nthread=4,\n",
    "                            scale_pos_weight=1,\n",
    "                            random_state=3)\n",
    "    xgb_model.fit(tran_x_kf,tran_y_kf)\n",
    "\n",
    "    import lightgbm\n",
    "    # LightGBM模型\n",
    "    lgbm_model=lightgbm.LGBMClassifier(iterations=300, \n",
    "                                      max_depth=5,\n",
    "                                      min_child_weight=0.5,\n",
    "                                      gamma=0.5,\n",
    "                                       reg_lambda=5,\n",
    "                                      subsample=0.8,\n",
    "                                      learning_rate=0.01, \n",
    "                                      loss_function='CrossEntropy',\n",
    "                                      random_state=3)\n",
    "    lgbm_model.fit(tran_x_kf,tran_y_kf)\n",
    "\n",
    "    import catboost\n",
    "    # CatBoost模型\n",
    "    cat_model=catboost.CatBoostClassifier(iterations=400, \n",
    "                                          learning_rate=0.1,\n",
    "                                          depth=6,\n",
    "                                          l2_leaf_reg=2,\n",
    "                                          loss_function='MultiClass',\n",
    "                                          random_state=3)\n",
    "    cat_model.fit(tran_x_kf,tran_y_kf)\n",
    "    \n",
    "    # 随机森林\n",
    "    from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    # 列出参数列表\n",
    "    tree_grid_parameter = {'n_estimators': list((10, 50, 100, 150, 200))}\n",
    "    # 进行参数的搜索组合\n",
    "    grid = GridSearchCV(RandomForestClassifier(), param_grid=tree_grid_parameter, cv=3)\n",
    "    # 根据已有数据去拟合随机森林模型\n",
    "    grid.fit(tran_x_sm, tran_y_sm)\n",
    "    rf_model = RandomForestClassifier(n_estimators=grid.best_params_['n_estimators'],\n",
    "                                max_depth=8,\n",
    "                                random_state=3)\n",
    "    rf_model.fit(tran_x_kf, tran_y_kf)\n",
    "    # 预测缺失值\n",
    "\n",
    "    # GBDT\n",
    "    # 列出参数列表\n",
    "    gbdt_model = GradientBoostingClassifier(n_estimators=300,\n",
    "                                learning_rate=0.1,\n",
    "                                max_depth=8,\n",
    "                                subsample=0.4,\n",
    "                                random_state=3)\n",
    "    gbdt_model.fit(tran_x_kf,tran_y_kf)\n",
    "    # 预测缺失值\n",
    "\n",
    "    # SVR\n",
    "    from sklearn.svm import SVR,SVC\n",
    "    # 回归模型\n",
    "    # svr = SVR(kernel='linear', C=1.25)\n",
    "    # 分类模型\n",
    "    svr_model = SVC(kernel='rbf',\n",
    "              C=50,\n",
    "              cache_size=200,\n",
    "                probability=True,\n",
    "              random_state=3)\n",
    "    svr_model.fit(tran_x_kf,tran_y_kf)\n",
    "\n",
    "    # Linear回归，Lasso回归，领回归，logistic回归\n",
    "    from sklearn.linear_model import LinearRegression,Lasso,Ridge,ElasticNet,LogisticRegression\n",
    "    lcv_model = LogisticRegression(penalty='l2',\n",
    "                             C=5,\n",
    "                            solver='lbfgs',\n",
    "                             max_iter=100,\n",
    "                            random_state=3)\n",
    "    # lcv = Lasso()\n",
    "    # lcv = Ridge()\n",
    "    lcv_model.fit(tran_x_kf, tran_y_kf)\n",
    "\n",
    "    # ANN\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "    ANN_model = MLPClassifier(alpha=0.1, \n",
    "                        hidden_layer_sizes=[100,], \n",
    "                        solver='adam', \n",
    "                        activation='relu', \n",
    "                        random_state=3)\n",
    "    ANN_model.fit(tran_x_kf, tran_y_kf)\n",
    "\n",
    "    # TabNet\n",
    "    from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "    from pytorch_tabnet.multitask import TabNetMultiTaskClassifier\n",
    "    import torch\n",
    "    TabNet_model = TabNetMultiTaskClassifier(\n",
    "                           cat_emb_dim=1,\n",
    "                           optimizer_fn=torch.optim.Adam,\n",
    "                           optimizer_params=dict(lr=2e-2),\n",
    "                           scheduler_params={\"step_size\":50, # how to use learning rate scheduler\n",
    "                                             \"gamma\":0.9},\n",
    "                           scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                           mask_type='entmax') # \"sparsemax\"\n",
    "    tran_x_x, tran_x_valid, tran_y_y, tran_y_valid = train_test_split(tran_x_kf, tran_y_kf, test_size=0.125, random_state=3)\n",
    "\n",
    "    TabNet_model.fit(X_train=tran_x_kf, \n",
    "            y_train=tran_y_kf.reshape(-1,1),\n",
    "            max_epochs=200, \n",
    "            patience=20,\n",
    "            batch_size=128, \n",
    "            virtual_batch_size=16,\n",
    "            num_workers=0,\n",
    "            drop_last=False,\n",
    "            loss_fn=[torch.nn.functional.cross_entropy]) # Optional, just an example of list usage\n",
    "\n",
    "    # 计算评价指标compute evaluation metrics\n",
    "    from sklearn.metrics import classification_report,confusion_matrix\n",
    "    # 统一模型输出结果\n",
    "    df_model_result=pd.DataFrame(\n",
    "        columns=['model','index','precision','recall','f1-score','support','accuracy','AUC','sensitivity','specificity'])\n",
    "\n",
    "    model_list=[xgb_model,lgbm_model,cat_model,rf_model,gbdt_model,svr_model,lcv_model,ANN_model,TabNet_model]\n",
    "    model_name_list=['XGBoost','LGBM','CatBoost','RF','GBDT','SVR','LR','ANN','TabNet']\n",
    "#     model_list=[cat_model]\n",
    "#     model_name_list=['CatBoost']\n",
    "    \n",
    "    temp_auc=pd.DataFrame(columns=['model','precision','recall','f1','accuracy','AUC'])    \n",
    "    for model,name in zip(model_list,model_name_list):\n",
    "        print(name)\n",
    "        # 计算accuracy和AUC\n",
    "        # tabnet predict_proba结果是三维数组，无法计算auc，需要reshape(-1,6),所有行 x 6列\n",
    "        test_y_score=np.reshape(model.predict_proba(test_x_kf),(-1,4))\n",
    "        auc=roc_auc_score(test_y_kf,test_y_score,multi_class='ovr')\n",
    "        auc=round(auc,2)\n",
    "        # tabnet predict结果是三维数组，无法计算auc，需要reshape\n",
    "        predictions=np.reshape(model.predict(test_x_kf),(-1,1)).astype(str)\n",
    "        accuracy=accuracy_score(test_y_kf.astype(str),predictions)\n",
    "        accuracy=round(accuracy,2)\n",
    "        # 计算precision、recall、F1\n",
    "        precision=precision_score(test_y_kf.astype(str),predictions,average='macro')\n",
    "        precision=round(precision,2)\n",
    "        recall=recall_score(test_y_kf.astype(str),predictions,average='macro')\n",
    "        recall=round(recall,2)\n",
    "        f1=f1_score(test_y_kf.astype(str),predictions,average='macro')\n",
    "        f1=round(f1,2)\n",
    "        temp_auc.loc[temp_auc.shape[0],['model','precision','recall','f1','accuracy','AUC']]=\\\n",
    "                                                                    [name,precision,recall,f1,accuracy,auc]\n",
    "    df_temp_result=pd.concat([df_temp_result,temp_auc],axis=0)\n",
    "                                       \n",
    "    # 变量重要性评分\n",
    "    importance = cat_model.feature_importances_\n",
    "    df_importance_temp=pd.DataFrame(data={'特征':x.columns,'重要性评分':importance})\n",
    "    temp_importance_list.append(df_importance_temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GBDT</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ANN</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TabNet</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GBDT</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ANN</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TabNet</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GBDT</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ANN</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TabNet</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GBDT</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ANN</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TabNet</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GBDT</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ANN</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TabNet</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model precision recall    f1 accuracy   AUC\n",
       "0   XGBoost      0.46   0.45  0.45     0.46  0.76\n",
       "1      LGBM      0.41   0.39   0.4      0.4  0.66\n",
       "2  CatBoost      0.48   0.47  0.47     0.47  0.77\n",
       "3        RF      0.48   0.46  0.47     0.47  0.77\n",
       "4      GBDT      0.53   0.52  0.51     0.52  0.75\n",
       "5       SVR      0.56   0.56  0.56     0.56  0.76\n",
       "6        LR      0.43   0.38  0.38     0.38  0.68\n",
       "7       ANN      0.49   0.48  0.48     0.48  0.71\n",
       "8    TabNet      0.43   0.42  0.42     0.43  0.71\n",
       "0   XGBoost      0.58   0.59  0.58      0.6  0.85\n",
       "1      LGBM      0.52   0.51   0.5     0.52  0.79\n",
       "2  CatBoost      0.66   0.66  0.66     0.67  0.87\n",
       "3        RF      0.62   0.61   0.6     0.62  0.85\n",
       "4      GBDT      0.56   0.57  0.56     0.59  0.84\n",
       "5       SVR      0.54   0.55  0.54     0.56  0.79\n",
       "6        LR       0.5    0.5  0.48     0.51  0.71\n",
       "7       ANN      0.48   0.46  0.46     0.47  0.74\n",
       "8    TabNet      0.54   0.53  0.53     0.54  0.76\n",
       "0   XGBoost      0.61   0.61   0.6      0.6  0.85\n",
       "1      LGBM      0.46   0.47  0.45     0.47   0.8\n",
       "2  CatBoost      0.65   0.64  0.64     0.64  0.86\n",
       "3        RF      0.53   0.51  0.52     0.52  0.83\n",
       "4      GBDT      0.58   0.59  0.58     0.58  0.83\n",
       "5       SVR      0.47   0.47  0.47     0.48  0.77\n",
       "6        LR      0.49    0.5  0.48      0.5  0.76\n",
       "7       ANN      0.51    0.5   0.5     0.52  0.77\n",
       "8    TabNet      0.54   0.54  0.53     0.55  0.75\n",
       "0   XGBoost      0.57   0.59  0.57     0.57   0.8\n",
       "1      LGBM      0.38   0.39  0.36     0.36  0.69\n",
       "2  CatBoost      0.64   0.65  0.64     0.64  0.85\n",
       "3        RF      0.62   0.63   0.6      0.6  0.82\n",
       "4      GBDT      0.61   0.61   0.6      0.6  0.84\n",
       "5       SVR      0.62   0.64  0.61     0.62  0.78\n",
       "6        LR      0.45   0.43  0.43     0.43  0.69\n",
       "7       ANN      0.47   0.43  0.43     0.42  0.71\n",
       "8    TabNet      0.51    0.5   0.5     0.49  0.76\n",
       "0   XGBoost      0.56   0.58  0.55     0.57   0.8\n",
       "1      LGBM      0.43   0.47  0.42     0.47  0.74\n",
       "2  CatBoost      0.59   0.62  0.59      0.6  0.85\n",
       "3        RF      0.56   0.59  0.56     0.58  0.81\n",
       "4      GBDT      0.52   0.54  0.52     0.52  0.81\n",
       "5       SVR      0.68   0.68  0.65     0.66  0.84\n",
       "6        LR      0.57   0.55  0.54     0.55  0.77\n",
       "7       ANN      0.57   0.57  0.54     0.56  0.79\n",
       "8    TabNet      0.48   0.49  0.48     0.49  0.77"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_result['precision']=df_temp_result['precision'].astype('float')\n",
    "df_temp_result['recall']=df_temp_result['recall'].astype('float')\n",
    "df_temp_result['f1']=df_temp_result['f1'].astype('float')\n",
    "df_temp_result['accuracy']=df_temp_result['accuracy'].astype('float')\n",
    "df_temp_result['AUC']=df_temp_result['AUC'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_result=df_temp_result.groupby(['model'])[['precision','recall','f1','accuracy','AUC']].mean().reset_index()\n",
    "df_model_result=df_model_result.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GBDT</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TabNet</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  precision  recall    f1  accuracy   AUC\n",
       "0       ANN       0.50    0.49  0.48      0.49  0.74\n",
       "1  CatBoost       0.60    0.61  0.60      0.60  0.84\n",
       "2      GBDT       0.56    0.57  0.55      0.56  0.81\n",
       "3      LGBM       0.44    0.45  0.43      0.44  0.74\n",
       "4        LR       0.49    0.47  0.46      0.47  0.72\n",
       "5        RF       0.56    0.56  0.55      0.56  0.82\n",
       "6       SVR       0.57    0.58  0.57      0.58  0.79\n",
       "7    TabNet       0.50    0.50  0.49      0.50  0.75\n",
       "8   XGBoost       0.56    0.56  0.55      0.56  0.81"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_result['temp_num']=[8,3,5,2,6,4,7,9,1]\n",
    "df_model_result=df_model_result.sort_values(by=['temp_num'],ascending=True).drop(['temp_num'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GBDT</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TabNet</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  precision  recall    f1  accuracy   AUC\n",
       "8   XGBoost       0.56    0.56  0.55      0.56  0.81\n",
       "3      LGBM       0.44    0.45  0.43      0.44  0.74\n",
       "1  CatBoost       0.60    0.61  0.60      0.60  0.84\n",
       "5        RF       0.56    0.56  0.55      0.56  0.82\n",
       "2      GBDT       0.56    0.57  0.55      0.56  0.81\n",
       "4        LR       0.49    0.47  0.46      0.47  0.72\n",
       "6       SVR       0.57    0.58  0.57      0.58  0.79\n",
       "0       ANN       0.50    0.49  0.48      0.49  0.74\n",
       "7    TabNet       0.50    0.50  0.49      0.50  0.75"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均重要性评分\n",
    "df_importance=pd.concat(temp_importance_list,axis=0)\n",
    "df_importance=df_importance.groupby(['特征'])[['重要性评分']].mean().sort_values(['重要性评分'],ascending=False).reset_index()\n",
    "df_importance=df_importance.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>特征</th>\n",
       "      <th>重要性评分</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tumor_CA19-9</td>\n",
       "      <td>11.596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DB</td>\n",
       "      <td>10.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALT</td>\n",
       "      <td>10.377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tumor_CA125</td>\n",
       "      <td>9.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tumor_CEA</td>\n",
       "      <td>8.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tumor_size</td>\n",
       "      <td>8.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tumor_AFP</td>\n",
       "      <td>7.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>N</td>\n",
       "      <td>5.439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>surgery_result</td>\n",
       "      <td>4.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T</td>\n",
       "      <td>4.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>emaciation</td>\n",
       "      <td>4.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bismuth_C</td>\n",
       "      <td>3.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MSKCC</td>\n",
       "      <td>1.942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gazzaniga_T</td>\n",
       "      <td>1.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Blumgart_T</td>\n",
       "      <td>1.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>biliary_disease</td>\n",
       "      <td>1.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HBsAg</td>\n",
       "      <td>1.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>M</td>\n",
       "      <td>1.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>jaundice</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cardio_disease</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>nbdd</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HCVAb</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 特征   重要性评分\n",
       "0      tumor_CA19-9  11.596\n",
       "1                DB  10.625\n",
       "2               ALT  10.377\n",
       "3       tumor_CA125   9.468\n",
       "4         tumor_CEA   8.963\n",
       "5        tumor_size   8.164\n",
       "6         tumor_AFP   7.325\n",
       "7                 N   5.439\n",
       "8    surgery_result   4.434\n",
       "9                 T   4.330\n",
       "10       emaciation   4.316\n",
       "11        Bismuth_C   3.324\n",
       "12            MSKCC   1.942\n",
       "13      Gazzaniga_T   1.713\n",
       "14       Blumgart_T   1.648\n",
       "15  biliary_disease   1.513\n",
       "16            HBsAg   1.329\n",
       "17                M   1.077\n",
       "18         jaundice   0.860\n",
       "19   cardio_disease   0.842\n",
       "20             nbdd   0.630\n",
       "21            HCVAb   0.085"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importance.to_excel(project_path+'/data/result/modeling/df_1.6_模型重要性评分_术后.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "[12:09:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "LGBM\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "CatBoost\n",
      "0:\tlearn: 1.3618925\ttotal: 5.61ms\tremaining: 2.24s\n",
      "1:\tlearn: 1.3345457\ttotal: 9.73ms\tremaining: 1.94s\n",
      "2:\tlearn: 1.2999076\ttotal: 14ms\tremaining: 1.85s\n",
      "3:\tlearn: 1.2700254\ttotal: 19.9ms\tremaining: 1.97s\n",
      "4:\tlearn: 1.2459134\ttotal: 24.5ms\tremaining: 1.94s\n",
      "5:\tlearn: 1.2259997\ttotal: 29ms\tremaining: 1.9s\n",
      "6:\tlearn: 1.2090571\ttotal: 33.2ms\tremaining: 1.86s\n",
      "7:\tlearn: 1.1910372\ttotal: 37ms\tremaining: 1.81s\n",
      "8:\tlearn: 1.1702162\ttotal: 41.7ms\tremaining: 1.81s\n",
      "9:\tlearn: 1.1474158\ttotal: 45.7ms\tremaining: 1.78s\n",
      "10:\tlearn: 1.1282448\ttotal: 50.2ms\tremaining: 1.77s\n",
      "11:\tlearn: 1.1152083\ttotal: 54.9ms\tremaining: 1.77s\n",
      "12:\tlearn: 1.0982749\ttotal: 59.1ms\tremaining: 1.76s\n",
      "13:\tlearn: 1.0808587\ttotal: 63ms\tremaining: 1.74s\n",
      "14:\tlearn: 1.0687992\ttotal: 66.8ms\tremaining: 1.71s\n",
      "15:\tlearn: 1.0567635\ttotal: 71.2ms\tremaining: 1.71s\n",
      "16:\tlearn: 1.0437180\ttotal: 76.1ms\tremaining: 1.71s\n",
      "17:\tlearn: 1.0272982\ttotal: 80.8ms\tremaining: 1.71s\n",
      "18:\tlearn: 1.0109700\ttotal: 86.8ms\tremaining: 1.74s\n",
      "19:\tlearn: 1.0005361\ttotal: 90.6ms\tremaining: 1.72s\n",
      "20:\tlearn: 0.9894157\ttotal: 94.1ms\tremaining: 1.7s\n",
      "21:\tlearn: 0.9829728\ttotal: 97.5ms\tremaining: 1.68s\n",
      "22:\tlearn: 0.9716539\ttotal: 102ms\tremaining: 1.67s\n",
      "23:\tlearn: 0.9617120\ttotal: 105ms\tremaining: 1.65s\n",
      "24:\tlearn: 0.9471240\ttotal: 109ms\tremaining: 1.64s\n",
      "25:\tlearn: 0.9328486\ttotal: 113ms\tremaining: 1.63s\n",
      "26:\tlearn: 0.9193975\ttotal: 118ms\tremaining: 1.63s\n",
      "27:\tlearn: 0.9077551\ttotal: 122ms\tremaining: 1.61s\n",
      "28:\tlearn: 0.8949972\ttotal: 125ms\tremaining: 1.6s\n",
      "29:\tlearn: 0.8850749\ttotal: 128ms\tremaining: 1.58s\n",
      "30:\tlearn: 0.8748309\ttotal: 133ms\tremaining: 1.58s\n",
      "31:\tlearn: 0.8649251\ttotal: 139ms\tremaining: 1.6s\n",
      "32:\tlearn: 0.8563827\ttotal: 143ms\tremaining: 1.59s\n",
      "33:\tlearn: 0.8468901\ttotal: 147ms\tremaining: 1.58s\n",
      "34:\tlearn: 0.8383882\ttotal: 151ms\tremaining: 1.57s\n",
      "35:\tlearn: 0.8302665\ttotal: 154ms\tremaining: 1.56s\n",
      "36:\tlearn: 0.8239165\ttotal: 157ms\tremaining: 1.54s\n",
      "37:\tlearn: 0.8139397\ttotal: 161ms\tremaining: 1.53s\n",
      "38:\tlearn: 0.8034517\ttotal: 164ms\tremaining: 1.52s\n",
      "39:\tlearn: 0.7956111\ttotal: 167ms\tremaining: 1.51s\n",
      "40:\tlearn: 0.7892672\ttotal: 171ms\tremaining: 1.49s\n",
      "41:\tlearn: 0.7783328\ttotal: 174ms\tremaining: 1.48s\n",
      "42:\tlearn: 0.7708142\ttotal: 177ms\tremaining: 1.47s\n",
      "43:\tlearn: 0.7619035\ttotal: 182ms\tremaining: 1.47s\n",
      "44:\tlearn: 0.7527166\ttotal: 185ms\tremaining: 1.46s\n",
      "45:\tlearn: 0.7430976\ttotal: 188ms\tremaining: 1.45s\n",
      "46:\tlearn: 0.7346939\ttotal: 191ms\tremaining: 1.44s\n",
      "47:\tlearn: 0.7307587\ttotal: 195ms\tremaining: 1.43s\n",
      "48:\tlearn: 0.7262259\ttotal: 199ms\tremaining: 1.43s\n",
      "49:\tlearn: 0.7219297\ttotal: 205ms\tremaining: 1.44s\n",
      "50:\tlearn: 0.7185066\ttotal: 208ms\tremaining: 1.43s\n",
      "51:\tlearn: 0.7121708\ttotal: 212ms\tremaining: 1.42s\n",
      "52:\tlearn: 0.7067919\ttotal: 215ms\tremaining: 1.41s\n",
      "53:\tlearn: 0.7031980\ttotal: 218ms\tremaining: 1.4s\n",
      "54:\tlearn: 0.6941002\ttotal: 222ms\tremaining: 1.39s\n",
      "55:\tlearn: 0.6888758\ttotal: 225ms\tremaining: 1.38s\n",
      "56:\tlearn: 0.6804002\ttotal: 229ms\tremaining: 1.38s\n",
      "57:\tlearn: 0.6730892\ttotal: 233ms\tremaining: 1.38s\n",
      "58:\tlearn: 0.6691272\ttotal: 237ms\tremaining: 1.37s\n",
      "59:\tlearn: 0.6648647\ttotal: 241ms\tremaining: 1.36s\n",
      "60:\tlearn: 0.6583777\ttotal: 244ms\tremaining: 1.35s\n",
      "61:\tlearn: 0.6515513\ttotal: 248ms\tremaining: 1.35s\n",
      "62:\tlearn: 0.6435638\ttotal: 251ms\tremaining: 1.34s\n",
      "63:\tlearn: 0.6387732\ttotal: 255ms\tremaining: 1.34s\n",
      "64:\tlearn: 0.6305893\ttotal: 260ms\tremaining: 1.34s\n",
      "65:\tlearn: 0.6245352\ttotal: 264ms\tremaining: 1.33s\n",
      "66:\tlearn: 0.6182300\ttotal: 270ms\tremaining: 1.34s\n",
      "67:\tlearn: 0.6122321\ttotal: 273ms\tremaining: 1.33s\n",
      "68:\tlearn: 0.6058432\ttotal: 277ms\tremaining: 1.33s\n",
      "69:\tlearn: 0.5995678\ttotal: 281ms\tremaining: 1.32s\n",
      "70:\tlearn: 0.5916991\ttotal: 285ms\tremaining: 1.32s\n",
      "71:\tlearn: 0.5841304\ttotal: 288ms\tremaining: 1.31s\n",
      "72:\tlearn: 0.5775629\ttotal: 292ms\tremaining: 1.31s\n",
      "73:\tlearn: 0.5730012\ttotal: 296ms\tremaining: 1.3s\n",
      "74:\tlearn: 0.5701050\ttotal: 300ms\tremaining: 1.3s\n",
      "75:\tlearn: 0.5657472\ttotal: 304ms\tremaining: 1.3s\n",
      "76:\tlearn: 0.5607636\ttotal: 309ms\tremaining: 1.3s\n",
      "77:\tlearn: 0.5562376\ttotal: 313ms\tremaining: 1.29s\n",
      "78:\tlearn: 0.5501682\ttotal: 317ms\tremaining: 1.29s\n",
      "79:\tlearn: 0.5472717\ttotal: 321ms\tremaining: 1.28s\n",
      "80:\tlearn: 0.5434754\ttotal: 327ms\tremaining: 1.29s\n",
      "81:\tlearn: 0.5375045\ttotal: 331ms\tremaining: 1.28s\n",
      "82:\tlearn: 0.5322275\ttotal: 336ms\tremaining: 1.28s\n",
      "83:\tlearn: 0.5267654\ttotal: 340ms\tremaining: 1.28s\n",
      "84:\tlearn: 0.5226733\ttotal: 343ms\tremaining: 1.27s\n",
      "85:\tlearn: 0.5172665\ttotal: 347ms\tremaining: 1.26s\n",
      "86:\tlearn: 0.5126452\ttotal: 350ms\tremaining: 1.26s\n",
      "87:\tlearn: 0.5076247\ttotal: 353ms\tremaining: 1.25s\n",
      "88:\tlearn: 0.5028872\ttotal: 357ms\tremaining: 1.25s\n",
      "89:\tlearn: 0.4981018\ttotal: 361ms\tremaining: 1.24s\n",
      "90:\tlearn: 0.4941074\ttotal: 364ms\tremaining: 1.24s\n",
      "91:\tlearn: 0.4908301\ttotal: 367ms\tremaining: 1.23s\n",
      "92:\tlearn: 0.4853390\ttotal: 371ms\tremaining: 1.22s\n",
      "93:\tlearn: 0.4825442\ttotal: 374ms\tremaining: 1.22s\n",
      "94:\tlearn: 0.4790235\ttotal: 377ms\tremaining: 1.21s\n",
      "95:\tlearn: 0.4762235\ttotal: 380ms\tremaining: 1.2s\n",
      "96:\tlearn: 0.4731887\ttotal: 384ms\tremaining: 1.2s\n",
      "97:\tlearn: 0.4698885\ttotal: 387ms\tremaining: 1.19s\n",
      "98:\tlearn: 0.4659366\ttotal: 390ms\tremaining: 1.19s\n",
      "99:\tlearn: 0.4611974\ttotal: 393ms\tremaining: 1.18s\n",
      "100:\tlearn: 0.4566728\ttotal: 397ms\tremaining: 1.18s\n",
      "101:\tlearn: 0.4531291\ttotal: 401ms\tremaining: 1.17s\n",
      "102:\tlearn: 0.4484553\ttotal: 406ms\tremaining: 1.17s\n",
      "103:\tlearn: 0.4439195\ttotal: 412ms\tremaining: 1.17s\n",
      "104:\tlearn: 0.4399197\ttotal: 416ms\tremaining: 1.17s\n",
      "105:\tlearn: 0.4361355\ttotal: 420ms\tremaining: 1.16s\n",
      "106:\tlearn: 0.4328866\ttotal: 424ms\tremaining: 1.16s\n",
      "107:\tlearn: 0.4307290\ttotal: 428ms\tremaining: 1.16s\n",
      "108:\tlearn: 0.4279791\ttotal: 431ms\tremaining: 1.15s\n",
      "109:\tlearn: 0.4254736\ttotal: 435ms\tremaining: 1.15s\n",
      "110:\tlearn: 0.4208100\ttotal: 439ms\tremaining: 1.14s\n",
      "111:\tlearn: 0.4161544\ttotal: 443ms\tremaining: 1.14s\n",
      "112:\tlearn: 0.4121819\ttotal: 447ms\tremaining: 1.13s\n",
      "113:\tlearn: 0.4075155\ttotal: 450ms\tremaining: 1.13s\n",
      "114:\tlearn: 0.4036134\ttotal: 454ms\tremaining: 1.12s\n",
      "115:\tlearn: 0.3989210\ttotal: 457ms\tremaining: 1.12s\n",
      "116:\tlearn: 0.3961246\ttotal: 461ms\tremaining: 1.12s\n",
      "117:\tlearn: 0.3922265\ttotal: 465ms\tremaining: 1.11s\n",
      "118:\tlearn: 0.3896663\ttotal: 468ms\tremaining: 1.11s\n",
      "119:\tlearn: 0.3872477\ttotal: 473ms\tremaining: 1.1s\n",
      "120:\tlearn: 0.3858480\ttotal: 477ms\tremaining: 1.1s\n",
      "121:\tlearn: 0.3828069\ttotal: 480ms\tremaining: 1.09s\n",
      "122:\tlearn: 0.3790158\ttotal: 486ms\tremaining: 1.09s\n",
      "123:\tlearn: 0.3761165\ttotal: 491ms\tremaining: 1.09s\n",
      "124:\tlearn: 0.3741833\ttotal: 494ms\tremaining: 1.09s\n",
      "125:\tlearn: 0.3711214\ttotal: 497ms\tremaining: 1.08s\n",
      "126:\tlearn: 0.3675439\ttotal: 502ms\tremaining: 1.08s\n",
      "127:\tlearn: 0.3634845\ttotal: 505ms\tremaining: 1.07s\n",
      "128:\tlearn: 0.3614681\ttotal: 508ms\tremaining: 1.07s\n",
      "129:\tlearn: 0.3592816\ttotal: 512ms\tremaining: 1.06s\n",
      "130:\tlearn: 0.3569801\ttotal: 515ms\tremaining: 1.06s\n",
      "131:\tlearn: 0.3541029\ttotal: 519ms\tremaining: 1.05s\n",
      "132:\tlearn: 0.3518150\ttotal: 522ms\tremaining: 1.05s\n",
      "133:\tlearn: 0.3498668\ttotal: 526ms\tremaining: 1.04s\n",
      "134:\tlearn: 0.3476366\ttotal: 529ms\tremaining: 1.04s\n",
      "135:\tlearn: 0.3450229\ttotal: 532ms\tremaining: 1.03s\n",
      "136:\tlearn: 0.3429081\ttotal: 536ms\tremaining: 1.03s\n",
      "137:\tlearn: 0.3401552\ttotal: 539ms\tremaining: 1.02s\n",
      "138:\tlearn: 0.3372992\ttotal: 543ms\tremaining: 1.02s\n",
      "139:\tlearn: 0.3341310\ttotal: 548ms\tremaining: 1.02s\n",
      "140:\tlearn: 0.3304537\ttotal: 551ms\tremaining: 1.01s\n",
      "141:\tlearn: 0.3277551\ttotal: 555ms\tremaining: 1.01s\n",
      "142:\tlearn: 0.3252180\ttotal: 559ms\tremaining: 1s\n",
      "143:\tlearn: 0.3235452\ttotal: 564ms\tremaining: 1s\n",
      "144:\tlearn: 0.3214784\ttotal: 567ms\tremaining: 997ms\n",
      "145:\tlearn: 0.3185475\ttotal: 570ms\tremaining: 992ms\n",
      "146:\tlearn: 0.3165363\ttotal: 574ms\tremaining: 987ms\n",
      "147:\tlearn: 0.3142817\ttotal: 577ms\tremaining: 982ms\n",
      "148:\tlearn: 0.3120288\ttotal: 580ms\tremaining: 977ms\n",
      "149:\tlearn: 0.3100940\ttotal: 584ms\tremaining: 973ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150:\tlearn: 0.3082251\ttotal: 588ms\tremaining: 969ms\n",
      "151:\tlearn: 0.3058282\ttotal: 591ms\tremaining: 964ms\n",
      "152:\tlearn: 0.3035010\ttotal: 594ms\tremaining: 960ms\n",
      "153:\tlearn: 0.3011473\ttotal: 598ms\tremaining: 955ms\n",
      "154:\tlearn: 0.2990461\ttotal: 602ms\tremaining: 951ms\n",
      "155:\tlearn: 0.2979175\ttotal: 606ms\tremaining: 948ms\n",
      "156:\tlearn: 0.2955072\ttotal: 611ms\tremaining: 946ms\n",
      "157:\tlearn: 0.2932128\ttotal: 615ms\tremaining: 942ms\n",
      "158:\tlearn: 0.2917152\ttotal: 618ms\tremaining: 937ms\n",
      "159:\tlearn: 0.2896491\ttotal: 623ms\tremaining: 935ms\n",
      "160:\tlearn: 0.2889337\ttotal: 628ms\tremaining: 933ms\n",
      "161:\tlearn: 0.2863391\ttotal: 632ms\tremaining: 928ms\n",
      "162:\tlearn: 0.2844555\ttotal: 636ms\tremaining: 924ms\n",
      "163:\tlearn: 0.2834312\ttotal: 639ms\tremaining: 919ms\n",
      "164:\tlearn: 0.2821143\ttotal: 642ms\tremaining: 915ms\n",
      "165:\tlearn: 0.2805106\ttotal: 646ms\tremaining: 910ms\n",
      "166:\tlearn: 0.2775137\ttotal: 649ms\tremaining: 906ms\n",
      "167:\tlearn: 0.2757528\ttotal: 652ms\tremaining: 901ms\n",
      "168:\tlearn: 0.2746263\ttotal: 656ms\tremaining: 896ms\n",
      "169:\tlearn: 0.2720334\ttotal: 660ms\tremaining: 893ms\n",
      "170:\tlearn: 0.2701669\ttotal: 664ms\tremaining: 889ms\n",
      "171:\tlearn: 0.2685833\ttotal: 667ms\tremaining: 884ms\n",
      "172:\tlearn: 0.2667366\ttotal: 671ms\tremaining: 880ms\n",
      "173:\tlearn: 0.2650039\ttotal: 676ms\tremaining: 878ms\n",
      "174:\tlearn: 0.2634212\ttotal: 681ms\tremaining: 876ms\n",
      "175:\tlearn: 0.2617138\ttotal: 684ms\tremaining: 871ms\n",
      "176:\tlearn: 0.2593534\ttotal: 688ms\tremaining: 867ms\n",
      "177:\tlearn: 0.2572728\ttotal: 692ms\tremaining: 863ms\n",
      "178:\tlearn: 0.2553126\ttotal: 695ms\tremaining: 858ms\n",
      "179:\tlearn: 0.2537575\ttotal: 698ms\tremaining: 853ms\n",
      "180:\tlearn: 0.2523547\ttotal: 702ms\tremaining: 849ms\n",
      "181:\tlearn: 0.2507711\ttotal: 706ms\tremaining: 846ms\n",
      "182:\tlearn: 0.2485377\ttotal: 710ms\tremaining: 842ms\n",
      "183:\tlearn: 0.2462016\ttotal: 713ms\tremaining: 837ms\n",
      "184:\tlearn: 0.2449842\ttotal: 717ms\tremaining: 833ms\n",
      "185:\tlearn: 0.2429585\ttotal: 720ms\tremaining: 829ms\n",
      "186:\tlearn: 0.2419152\ttotal: 724ms\tremaining: 824ms\n",
      "187:\tlearn: 0.2397209\ttotal: 727ms\tremaining: 820ms\n",
      "188:\tlearn: 0.2383381\ttotal: 730ms\tremaining: 815ms\n",
      "189:\tlearn: 0.2377299\ttotal: 734ms\tremaining: 811ms\n",
      "190:\tlearn: 0.2359094\ttotal: 737ms\tremaining: 807ms\n",
      "191:\tlearn: 0.2344914\ttotal: 742ms\tremaining: 804ms\n",
      "192:\tlearn: 0.2326946\ttotal: 746ms\tremaining: 800ms\n",
      "193:\tlearn: 0.2319794\ttotal: 749ms\tremaining: 795ms\n",
      "194:\tlearn: 0.2307908\ttotal: 753ms\tremaining: 791ms\n",
      "195:\tlearn: 0.2289468\ttotal: 758ms\tremaining: 789ms\n",
      "196:\tlearn: 0.2273613\ttotal: 762ms\tremaining: 785ms\n",
      "197:\tlearn: 0.2263197\ttotal: 766ms\tremaining: 782ms\n",
      "198:\tlearn: 0.2248980\ttotal: 770ms\tremaining: 778ms\n",
      "199:\tlearn: 0.2235601\ttotal: 774ms\tremaining: 774ms\n",
      "200:\tlearn: 0.2222167\ttotal: 777ms\tremaining: 769ms\n",
      "201:\tlearn: 0.2213319\ttotal: 781ms\tremaining: 766ms\n",
      "202:\tlearn: 0.2202589\ttotal: 785ms\tremaining: 762ms\n",
      "203:\tlearn: 0.2189840\ttotal: 788ms\tremaining: 758ms\n",
      "204:\tlearn: 0.2181568\ttotal: 792ms\tremaining: 753ms\n",
      "205:\tlearn: 0.2164373\ttotal: 796ms\tremaining: 749ms\n",
      "206:\tlearn: 0.2145941\ttotal: 799ms\tremaining: 745ms\n",
      "207:\tlearn: 0.2134556\ttotal: 803ms\tremaining: 741ms\n",
      "208:\tlearn: 0.2128440\ttotal: 807ms\tremaining: 737ms\n",
      "209:\tlearn: 0.2117518\ttotal: 810ms\tremaining: 733ms\n",
      "210:\tlearn: 0.2110590\ttotal: 813ms\tremaining: 729ms\n",
      "211:\tlearn: 0.2092959\ttotal: 817ms\tremaining: 725ms\n",
      "212:\tlearn: 0.2081370\ttotal: 820ms\tremaining: 720ms\n",
      "213:\tlearn: 0.2073158\ttotal: 824ms\tremaining: 716ms\n",
      "214:\tlearn: 0.2061553\ttotal: 827ms\tremaining: 712ms\n",
      "215:\tlearn: 0.2055711\ttotal: 830ms\tremaining: 707ms\n",
      "216:\tlearn: 0.2049139\ttotal: 834ms\tremaining: 703ms\n",
      "217:\tlearn: 0.2036298\ttotal: 837ms\tremaining: 699ms\n",
      "218:\tlearn: 0.2025342\ttotal: 842ms\tremaining: 696ms\n",
      "219:\tlearn: 0.2009303\ttotal: 845ms\tremaining: 691ms\n",
      "220:\tlearn: 0.1988551\ttotal: 849ms\tremaining: 687ms\n",
      "221:\tlearn: 0.1977856\ttotal: 855ms\tremaining: 685ms\n",
      "222:\tlearn: 0.1967621\ttotal: 858ms\tremaining: 681ms\n",
      "223:\tlearn: 0.1954387\ttotal: 861ms\tremaining: 677ms\n",
      "224:\tlearn: 0.1944838\ttotal: 864ms\tremaining: 672ms\n",
      "225:\tlearn: 0.1938012\ttotal: 868ms\tremaining: 668ms\n",
      "226:\tlearn: 0.1923437\ttotal: 871ms\tremaining: 664ms\n",
      "227:\tlearn: 0.1909533\ttotal: 874ms\tremaining: 660ms\n",
      "228:\tlearn: 0.1899627\ttotal: 878ms\tremaining: 655ms\n",
      "229:\tlearn: 0.1891717\ttotal: 882ms\tremaining: 652ms\n",
      "230:\tlearn: 0.1883631\ttotal: 886ms\tremaining: 648ms\n",
      "231:\tlearn: 0.1874751\ttotal: 889ms\tremaining: 644ms\n",
      "232:\tlearn: 0.1864029\ttotal: 892ms\tremaining: 639ms\n",
      "233:\tlearn: 0.1858085\ttotal: 895ms\tremaining: 635ms\n",
      "234:\tlearn: 0.1847788\ttotal: 899ms\tremaining: 631ms\n",
      "235:\tlearn: 0.1835026\ttotal: 902ms\tremaining: 627ms\n",
      "236:\tlearn: 0.1823631\ttotal: 905ms\tremaining: 623ms\n",
      "237:\tlearn: 0.1809307\ttotal: 909ms\tremaining: 619ms\n",
      "238:\tlearn: 0.1799787\ttotal: 914ms\tremaining: 616ms\n",
      "239:\tlearn: 0.1786680\ttotal: 919ms\tremaining: 613ms\n",
      "240:\tlearn: 0.1775489\ttotal: 923ms\tremaining: 609ms\n",
      "241:\tlearn: 0.1765611\ttotal: 926ms\tremaining: 604ms\n",
      "242:\tlearn: 0.1753363\ttotal: 930ms\tremaining: 601ms\n",
      "243:\tlearn: 0.1740016\ttotal: 933ms\tremaining: 597ms\n",
      "244:\tlearn: 0.1736337\ttotal: 936ms\tremaining: 592ms\n",
      "245:\tlearn: 0.1726558\ttotal: 940ms\tremaining: 588ms\n",
      "246:\tlearn: 0.1717753\ttotal: 943ms\tremaining: 584ms\n",
      "247:\tlearn: 0.1708513\ttotal: 947ms\tremaining: 581ms\n",
      "248:\tlearn: 0.1700972\ttotal: 951ms\tremaining: 577ms\n",
      "249:\tlearn: 0.1690905\ttotal: 954ms\tremaining: 572ms\n",
      "250:\tlearn: 0.1681925\ttotal: 957ms\tremaining: 568ms\n",
      "251:\tlearn: 0.1672854\ttotal: 961ms\tremaining: 564ms\n",
      "252:\tlearn: 0.1666309\ttotal: 965ms\tremaining: 561ms\n",
      "253:\tlearn: 0.1657077\ttotal: 968ms\tremaining: 557ms\n",
      "254:\tlearn: 0.1649403\ttotal: 972ms\tremaining: 553ms\n",
      "255:\tlearn: 0.1640393\ttotal: 977ms\tremaining: 550ms\n",
      "256:\tlearn: 0.1630310\ttotal: 983ms\tremaining: 547ms\n",
      "257:\tlearn: 0.1619977\ttotal: 986ms\tremaining: 543ms\n",
      "258:\tlearn: 0.1611345\ttotal: 990ms\tremaining: 539ms\n",
      "259:\tlearn: 0.1606032\ttotal: 994ms\tremaining: 535ms\n",
      "260:\tlearn: 0.1596430\ttotal: 998ms\tremaining: 531ms\n",
      "261:\tlearn: 0.1588157\ttotal: 1s\tremaining: 527ms\n",
      "262:\tlearn: 0.1580152\ttotal: 1s\tremaining: 523ms\n",
      "263:\tlearn: 0.1569061\ttotal: 1.01s\tremaining: 519ms\n",
      "264:\tlearn: 0.1561680\ttotal: 1.01s\tremaining: 515ms\n",
      "265:\tlearn: 0.1556949\ttotal: 1.01s\tremaining: 511ms\n",
      "266:\tlearn: 0.1552701\ttotal: 1.02s\tremaining: 507ms\n",
      "267:\tlearn: 0.1544067\ttotal: 1.02s\tremaining: 503ms\n",
      "268:\tlearn: 0.1535599\ttotal: 1.02s\tremaining: 499ms\n",
      "269:\tlearn: 0.1525671\ttotal: 1.03s\tremaining: 495ms\n",
      "270:\tlearn: 0.1517796\ttotal: 1.03s\tremaining: 491ms\n",
      "271:\tlearn: 0.1510017\ttotal: 1.03s\tremaining: 487ms\n",
      "272:\tlearn: 0.1503084\ttotal: 1.04s\tremaining: 483ms\n",
      "273:\tlearn: 0.1494355\ttotal: 1.04s\tremaining: 479ms\n",
      "274:\tlearn: 0.1483789\ttotal: 1.05s\tremaining: 476ms\n",
      "275:\tlearn: 0.1477499\ttotal: 1.05s\tremaining: 472ms\n",
      "276:\tlearn: 0.1472355\ttotal: 1.05s\tremaining: 468ms\n",
      "277:\tlearn: 0.1463565\ttotal: 1.06s\tremaining: 464ms\n",
      "278:\tlearn: 0.1454402\ttotal: 1.06s\tremaining: 460ms\n",
      "279:\tlearn: 0.1446983\ttotal: 1.06s\tremaining: 456ms\n",
      "280:\tlearn: 0.1441736\ttotal: 1.07s\tremaining: 452ms\n",
      "281:\tlearn: 0.1434060\ttotal: 1.07s\tremaining: 449ms\n",
      "282:\tlearn: 0.1424461\ttotal: 1.07s\tremaining: 445ms\n",
      "283:\tlearn: 0.1416872\ttotal: 1.08s\tremaining: 441ms\n",
      "284:\tlearn: 0.1409988\ttotal: 1.08s\tremaining: 437ms\n",
      "285:\tlearn: 0.1400576\ttotal: 1.08s\tremaining: 433ms\n",
      "286:\tlearn: 0.1393515\ttotal: 1.09s\tremaining: 429ms\n",
      "287:\tlearn: 0.1390437\ttotal: 1.09s\tremaining: 425ms\n",
      "288:\tlearn: 0.1381072\ttotal: 1.09s\tremaining: 421ms\n",
      "289:\tlearn: 0.1373948\ttotal: 1.1s\tremaining: 417ms\n",
      "290:\tlearn: 0.1370988\ttotal: 1.1s\tremaining: 414ms\n",
      "291:\tlearn: 0.1366418\ttotal: 1.11s\tremaining: 410ms\n",
      "292:\tlearn: 0.1362343\ttotal: 1.11s\tremaining: 406ms\n",
      "293:\tlearn: 0.1353975\ttotal: 1.12s\tremaining: 402ms\n",
      "294:\tlearn: 0.1350502\ttotal: 1.12s\tremaining: 399ms\n",
      "295:\tlearn: 0.1345758\ttotal: 1.12s\tremaining: 395ms\n",
      "296:\tlearn: 0.1340280\ttotal: 1.13s\tremaining: 391ms\n",
      "297:\tlearn: 0.1335842\ttotal: 1.13s\tremaining: 387ms\n",
      "298:\tlearn: 0.1329367\ttotal: 1.13s\tremaining: 383ms\n",
      "299:\tlearn: 0.1321177\ttotal: 1.14s\tremaining: 379ms\n",
      "300:\tlearn: 0.1314730\ttotal: 1.14s\tremaining: 375ms\n",
      "301:\tlearn: 0.1308685\ttotal: 1.14s\tremaining: 371ms\n",
      "302:\tlearn: 0.1303112\ttotal: 1.15s\tremaining: 368ms\n",
      "303:\tlearn: 0.1297927\ttotal: 1.15s\tremaining: 364ms\n",
      "304:\tlearn: 0.1292112\ttotal: 1.16s\tremaining: 360ms\n",
      "305:\tlearn: 0.1287679\ttotal: 1.16s\tremaining: 356ms\n",
      "306:\tlearn: 0.1279525\ttotal: 1.16s\tremaining: 353ms\n",
      "307:\tlearn: 0.1275274\ttotal: 1.17s\tremaining: 349ms\n",
      "308:\tlearn: 0.1268037\ttotal: 1.17s\tremaining: 345ms\n",
      "309:\tlearn: 0.1260436\ttotal: 1.18s\tremaining: 342ms\n",
      "310:\tlearn: 0.1257762\ttotal: 1.18s\tremaining: 338ms\n",
      "311:\tlearn: 0.1251242\ttotal: 1.19s\tremaining: 334ms\n",
      "312:\tlearn: 0.1244670\ttotal: 1.19s\tremaining: 331ms\n",
      "313:\tlearn: 0.1237640\ttotal: 1.19s\tremaining: 327ms\n",
      "314:\tlearn: 0.1231920\ttotal: 1.2s\tremaining: 323ms\n",
      "315:\tlearn: 0.1226937\ttotal: 1.2s\tremaining: 319ms\n",
      "316:\tlearn: 0.1217797\ttotal: 1.2s\tremaining: 315ms\n",
      "317:\tlearn: 0.1213104\ttotal: 1.21s\tremaining: 312ms\n",
      "318:\tlearn: 0.1209665\ttotal: 1.21s\tremaining: 308ms\n",
      "319:\tlearn: 0.1205391\ttotal: 1.22s\tremaining: 304ms\n",
      "320:\tlearn: 0.1201876\ttotal: 1.22s\tremaining: 300ms\n",
      "321:\tlearn: 0.1198134\ttotal: 1.22s\tremaining: 296ms\n",
      "322:\tlearn: 0.1191770\ttotal: 1.23s\tremaining: 293ms\n",
      "323:\tlearn: 0.1186756\ttotal: 1.23s\tremaining: 289ms\n",
      "324:\tlearn: 0.1182849\ttotal: 1.24s\tremaining: 285ms\n",
      "325:\tlearn: 0.1178208\ttotal: 1.24s\tremaining: 281ms\n",
      "326:\tlearn: 0.1174315\ttotal: 1.24s\tremaining: 278ms\n",
      "327:\tlearn: 0.1170869\ttotal: 1.25s\tremaining: 274ms\n",
      "328:\tlearn: 0.1164264\ttotal: 1.25s\tremaining: 270ms\n",
      "329:\tlearn: 0.1160053\ttotal: 1.25s\tremaining: 266ms\n",
      "330:\tlearn: 0.1154878\ttotal: 1.26s\tremaining: 262ms\n",
      "331:\tlearn: 0.1149993\ttotal: 1.26s\tremaining: 259ms\n",
      "332:\tlearn: 0.1143322\ttotal: 1.27s\tremaining: 255ms\n",
      "333:\tlearn: 0.1139161\ttotal: 1.27s\tremaining: 251ms\n",
      "334:\tlearn: 0.1134799\ttotal: 1.27s\tremaining: 247ms\n",
      "335:\tlearn: 0.1132675\ttotal: 1.28s\tremaining: 243ms\n",
      "336:\tlearn: 0.1127685\ttotal: 1.28s\tremaining: 239ms\n",
      "337:\tlearn: 0.1121489\ttotal: 1.28s\tremaining: 236ms\n",
      "338:\tlearn: 0.1116341\ttotal: 1.29s\tremaining: 232ms\n",
      "339:\tlearn: 0.1113092\ttotal: 1.29s\tremaining: 228ms\n",
      "340:\tlearn: 0.1108934\ttotal: 1.29s\tremaining: 224ms\n",
      "341:\tlearn: 0.1104464\ttotal: 1.3s\tremaining: 220ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342:\tlearn: 0.1100620\ttotal: 1.3s\tremaining: 216ms\n",
      "343:\tlearn: 0.1096118\ttotal: 1.31s\tremaining: 213ms\n",
      "344:\tlearn: 0.1092683\ttotal: 1.31s\tremaining: 209ms\n",
      "345:\tlearn: 0.1086294\ttotal: 1.32s\tremaining: 205ms\n",
      "346:\tlearn: 0.1081793\ttotal: 1.32s\tremaining: 202ms\n",
      "347:\tlearn: 0.1077369\ttotal: 1.32s\tremaining: 198ms\n",
      "348:\tlearn: 0.1071484\ttotal: 1.33s\tremaining: 194ms\n",
      "349:\tlearn: 0.1066810\ttotal: 1.33s\tremaining: 190ms\n",
      "350:\tlearn: 0.1063224\ttotal: 1.33s\tremaining: 187ms\n",
      "351:\tlearn: 0.1058194\ttotal: 1.34s\tremaining: 183ms\n",
      "352:\tlearn: 0.1052882\ttotal: 1.34s\tremaining: 179ms\n",
      "353:\tlearn: 0.1049555\ttotal: 1.35s\tremaining: 175ms\n",
      "354:\tlearn: 0.1045904\ttotal: 1.35s\tremaining: 171ms\n",
      "355:\tlearn: 0.1041621\ttotal: 1.37s\tremaining: 169ms\n",
      "356:\tlearn: 0.1037747\ttotal: 1.38s\tremaining: 166ms\n",
      "357:\tlearn: 0.1033546\ttotal: 1.38s\tremaining: 162ms\n",
      "358:\tlearn: 0.1030124\ttotal: 1.39s\tremaining: 159ms\n",
      "359:\tlearn: 0.1026233\ttotal: 1.39s\tremaining: 155ms\n",
      "360:\tlearn: 0.1023504\ttotal: 1.4s\tremaining: 151ms\n",
      "361:\tlearn: 0.1019932\ttotal: 1.4s\tremaining: 147ms\n",
      "362:\tlearn: 0.1015236\ttotal: 1.41s\tremaining: 144ms\n",
      "363:\tlearn: 0.1011457\ttotal: 1.41s\tremaining: 140ms\n",
      "364:\tlearn: 0.1007144\ttotal: 1.41s\tremaining: 136ms\n",
      "365:\tlearn: 0.1002662\ttotal: 1.42s\tremaining: 132ms\n",
      "366:\tlearn: 0.0999054\ttotal: 1.42s\tremaining: 128ms\n",
      "367:\tlearn: 0.0994028\ttotal: 1.43s\tremaining: 124ms\n",
      "368:\tlearn: 0.0990768\ttotal: 1.43s\tremaining: 120ms\n",
      "369:\tlearn: 0.0987265\ttotal: 1.44s\tremaining: 116ms\n",
      "370:\tlearn: 0.0983020\ttotal: 1.44s\tremaining: 113ms\n",
      "371:\tlearn: 0.0979961\ttotal: 1.44s\tremaining: 109ms\n",
      "372:\tlearn: 0.0976018\ttotal: 1.45s\tremaining: 105ms\n",
      "373:\tlearn: 0.0971157\ttotal: 1.45s\tremaining: 101ms\n",
      "374:\tlearn: 0.0967228\ttotal: 1.46s\tremaining: 97ms\n",
      "375:\tlearn: 0.0964198\ttotal: 1.46s\tremaining: 93.1ms\n",
      "376:\tlearn: 0.0959377\ttotal: 1.46s\tremaining: 89.2ms\n",
      "377:\tlearn: 0.0957011\ttotal: 1.47s\tremaining: 85.3ms\n",
      "378:\tlearn: 0.0952105\ttotal: 1.47s\tremaining: 81.4ms\n",
      "379:\tlearn: 0.0945959\ttotal: 1.47s\tremaining: 77.5ms\n",
      "380:\tlearn: 0.0942864\ttotal: 1.48s\tremaining: 73.6ms\n",
      "381:\tlearn: 0.0938768\ttotal: 1.48s\tremaining: 69.7ms\n",
      "382:\tlearn: 0.0935840\ttotal: 1.48s\tremaining: 65.9ms\n",
      "383:\tlearn: 0.0931761\ttotal: 1.49s\tremaining: 62ms\n",
      "384:\tlearn: 0.0927283\ttotal: 1.49s\tremaining: 58.2ms\n",
      "385:\tlearn: 0.0923288\ttotal: 1.5s\tremaining: 54.4ms\n",
      "386:\tlearn: 0.0921089\ttotal: 1.5s\tremaining: 50.5ms\n",
      "387:\tlearn: 0.0916829\ttotal: 1.51s\tremaining: 46.6ms\n",
      "388:\tlearn: 0.0912424\ttotal: 1.51s\tremaining: 42.7ms\n",
      "389:\tlearn: 0.0906661\ttotal: 1.51s\tremaining: 38.8ms\n",
      "390:\tlearn: 0.0904399\ttotal: 1.52s\tremaining: 35ms\n",
      "391:\tlearn: 0.0901919\ttotal: 1.52s\tremaining: 31.1ms\n",
      "392:\tlearn: 0.0900113\ttotal: 1.52s\tremaining: 27.2ms\n",
      "393:\tlearn: 0.0896727\ttotal: 1.53s\tremaining: 23.3ms\n",
      "394:\tlearn: 0.0893925\ttotal: 1.53s\tremaining: 19.4ms\n",
      "395:\tlearn: 0.0890780\ttotal: 1.53s\tremaining: 15.5ms\n",
      "396:\tlearn: 0.0888063\ttotal: 1.54s\tremaining: 11.6ms\n",
      "397:\tlearn: 0.0883896\ttotal: 1.54s\tremaining: 7.75ms\n",
      "398:\tlearn: 0.0881525\ttotal: 1.55s\tremaining: 3.88ms\n",
      "399:\tlearn: 0.0878343\ttotal: 1.55s\tremaining: 0us\n",
      "RF\n",
      "GBDT\n",
      "SVR\n",
      "LR\n",
      "ANN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabNet\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.86285 |  0:00:00s\n",
      "epoch 1  | loss: 0.7591  |  0:00:00s\n",
      "epoch 2  | loss: 0.85526 |  0:00:00s\n",
      "epoch 3  | loss: 0.78511 |  0:00:00s\n",
      "epoch 4  | loss: 0.77312 |  0:00:00s\n",
      "epoch 5  | loss: 0.75338 |  0:00:00s\n",
      "epoch 6  | loss: 0.72196 |  0:00:01s\n",
      "epoch 7  | loss: 0.72713 |  0:00:01s\n",
      "epoch 8  | loss: 0.77857 |  0:00:01s\n",
      "epoch 9  | loss: 0.78046 |  0:00:01s\n",
      "epoch 10 | loss: 0.72913 |  0:00:01s\n",
      "epoch 11 | loss: 0.73749 |  0:00:01s\n",
      "epoch 12 | loss: 0.68676 |  0:00:02s\n",
      "epoch 13 | loss: 0.77451 |  0:00:02s\n",
      "epoch 14 | loss: 0.74895 |  0:00:02s\n",
      "epoch 15 | loss: 0.71032 |  0:00:02s\n",
      "epoch 16 | loss: 0.71855 |  0:00:02s\n",
      "epoch 17 | loss: 0.73271 |  0:00:02s\n",
      "epoch 18 | loss: 0.74809 |  0:00:03s\n",
      "epoch 19 | loss: 0.735   |  0:00:03s\n",
      "epoch 20 | loss: 0.74003 |  0:00:03s\n",
      "epoch 21 | loss: 0.71158 |  0:00:03s\n",
      "epoch 22 | loss: 0.71527 |  0:00:03s\n",
      "epoch 23 | loss: 0.6856  |  0:00:03s\n",
      "epoch 24 | loss: 0.65044 |  0:00:04s\n",
      "epoch 25 | loss: 0.73632 |  0:00:04s\n",
      "epoch 26 | loss: 0.69698 |  0:00:04s\n",
      "epoch 27 | loss: 0.71432 |  0:00:04s\n",
      "epoch 28 | loss: 0.65694 |  0:00:04s\n",
      "epoch 29 | loss: 0.69742 |  0:00:04s\n",
      "epoch 30 | loss: 0.66822 |  0:00:05s\n",
      "epoch 31 | loss: 0.73318 |  0:00:05s\n",
      "epoch 32 | loss: 0.61835 |  0:00:05s\n",
      "epoch 33 | loss: 0.53942 |  0:00:05s\n",
      "epoch 34 | loss: 0.62676 |  0:00:05s\n",
      "epoch 35 | loss: 0.59198 |  0:00:05s\n",
      "epoch 36 | loss: 0.70686 |  0:00:06s\n",
      "epoch 37 | loss: 0.67319 |  0:00:06s\n",
      "epoch 38 | loss: 0.65581 |  0:00:06s\n",
      "epoch 39 | loss: 0.70636 |  0:00:06s\n",
      "epoch 40 | loss: 0.60203 |  0:00:06s\n",
      "epoch 41 | loss: 0.64286 |  0:00:06s\n",
      "epoch 42 | loss: 0.63522 |  0:00:07s\n",
      "epoch 43 | loss: 0.60013 |  0:00:07s\n",
      "epoch 44 | loss: 0.57521 |  0:00:07s\n",
      "epoch 45 | loss: 0.56487 |  0:00:07s\n",
      "epoch 46 | loss: 0.61695 |  0:00:07s\n",
      "epoch 47 | loss: 0.53546 |  0:00:07s\n",
      "epoch 48 | loss: 0.65137 |  0:00:07s\n",
      "epoch 49 | loss: 0.60378 |  0:00:08s\n",
      "epoch 50 | loss: 0.56925 |  0:00:08s\n",
      "epoch 51 | loss: 0.61798 |  0:00:08s\n",
      "epoch 52 | loss: 0.63026 |  0:00:08s\n",
      "epoch 53 | loss: 0.59731 |  0:00:08s\n",
      "epoch 54 | loss: 0.61365 |  0:00:08s\n",
      "epoch 55 | loss: 0.66776 |  0:00:09s\n",
      "epoch 56 | loss: 0.62742 |  0:00:09s\n",
      "epoch 57 | loss: 0.59584 |  0:00:09s\n",
      "epoch 58 | loss: 0.65926 |  0:00:09s\n",
      "epoch 59 | loss: 0.64749 |  0:00:09s\n",
      "epoch 60 | loss: 0.5767  |  0:00:09s\n",
      "epoch 61 | loss: 0.61037 |  0:00:09s\n",
      "epoch 62 | loss: 0.62813 |  0:00:10s\n",
      "epoch 63 | loss: 0.60677 |  0:00:10s\n",
      "epoch 64 | loss: 0.69196 |  0:00:10s\n",
      "epoch 65 | loss: 0.58106 |  0:00:10s\n",
      "epoch 66 | loss: 0.56494 |  0:00:10s\n",
      "epoch 67 | loss: 0.68623 |  0:00:10s\n",
      "epoch 68 | loss: 0.55372 |  0:00:10s\n",
      "epoch 69 | loss: 0.5687  |  0:00:11s\n",
      "epoch 70 | loss: 0.62747 |  0:00:11s\n",
      "epoch 71 | loss: 0.62097 |  0:00:11s\n",
      "epoch 72 | loss: 0.5992  |  0:00:11s\n",
      "epoch 73 | loss: 0.51644 |  0:00:11s\n",
      "epoch 74 | loss: 0.6096  |  0:00:11s\n",
      "epoch 75 | loss: 0.57486 |  0:00:11s\n",
      "epoch 76 | loss: 0.58166 |  0:00:12s\n",
      "epoch 77 | loss: 0.57295 |  0:00:12s\n",
      "epoch 78 | loss: 0.60432 |  0:00:12s\n",
      "epoch 79 | loss: 0.6058  |  0:00:12s\n",
      "epoch 80 | loss: 0.54652 |  0:00:12s\n",
      "epoch 81 | loss: 0.61409 |  0:00:12s\n",
      "epoch 82 | loss: 0.57712 |  0:00:12s\n",
      "epoch 83 | loss: 0.56717 |  0:00:13s\n",
      "epoch 84 | loss: 0.63084 |  0:00:13s\n",
      "epoch 85 | loss: 0.58475 |  0:00:13s\n",
      "epoch 86 | loss: 0.59641 |  0:00:13s\n",
      "epoch 87 | loss: 0.5874  |  0:00:13s\n",
      "epoch 88 | loss: 0.63151 |  0:00:13s\n",
      "epoch 89 | loss: 0.55266 |  0:00:13s\n",
      "epoch 90 | loss: 0.60525 |  0:00:14s\n",
      "epoch 91 | loss: 0.61723 |  0:00:14s\n",
      "epoch 92 | loss: 0.55495 |  0:00:14s\n",
      "epoch 93 | loss: 0.62909 |  0:00:14s\n",
      "epoch 94 | loss: 0.5578  |  0:00:14s\n",
      "epoch 95 | loss: 0.49624 |  0:00:14s\n",
      "epoch 96 | loss: 0.52763 |  0:00:14s\n",
      "epoch 97 | loss: 0.53906 |  0:00:15s\n",
      "epoch 98 | loss: 0.52516 |  0:00:15s\n",
      "epoch 99 | loss: 0.55538 |  0:00:15s\n",
      "epoch 100| loss: 0.53289 |  0:00:15s\n",
      "epoch 101| loss: 0.52773 |  0:00:15s\n",
      "epoch 102| loss: 0.53944 |  0:00:15s\n",
      "epoch 103| loss: 0.51854 |  0:00:15s\n",
      "epoch 104| loss: 0.55094 |  0:00:16s\n",
      "epoch 105| loss: 0.50446 |  0:00:16s\n",
      "epoch 106| loss: 0.52956 |  0:00:16s\n",
      "epoch 107| loss: 0.5268  |  0:00:16s\n",
      "epoch 108| loss: 0.55254 |  0:00:16s\n",
      "epoch 109| loss: 0.57805 |  0:00:16s\n",
      "epoch 110| loss: 0.60104 |  0:00:16s\n",
      "epoch 111| loss: 0.54981 |  0:00:17s\n",
      "epoch 112| loss: 0.58386 |  0:00:17s\n",
      "epoch 113| loss: 0.54057 |  0:00:17s\n",
      "epoch 114| loss: 0.5021  |  0:00:17s\n",
      "epoch 115| loss: 0.52073 |  0:00:17s\n",
      "epoch 116| loss: 0.60311 |  0:00:17s\n",
      "epoch 117| loss: 0.50051 |  0:00:17s\n",
      "epoch 118| loss: 0.54413 |  0:00:18s\n",
      "epoch 119| loss: 0.52678 |  0:00:18s\n",
      "epoch 120| loss: 0.52334 |  0:00:18s\n",
      "epoch 121| loss: 0.53513 |  0:00:18s\n",
      "epoch 122| loss: 0.46733 |  0:00:18s\n",
      "epoch 123| loss: 0.49077 |  0:00:18s\n",
      "epoch 124| loss: 0.50125 |  0:00:19s\n",
      "epoch 125| loss: 0.53144 |  0:00:19s\n",
      "epoch 126| loss: 0.54281 |  0:00:19s\n",
      "epoch 127| loss: 0.46875 |  0:00:19s\n",
      "epoch 128| loss: 0.49901 |  0:00:19s\n",
      "epoch 129| loss: 0.57557 |  0:00:19s\n",
      "epoch 130| loss: 0.50832 |  0:00:19s\n",
      "epoch 131| loss: 0.53431 |  0:00:20s\n",
      "epoch 132| loss: 0.5539  |  0:00:20s\n",
      "epoch 133| loss: 0.50854 |  0:00:20s\n",
      "epoch 134| loss: 0.50624 |  0:00:20s\n",
      "epoch 135| loss: 0.57698 |  0:00:20s\n",
      "epoch 136| loss: 0.50907 |  0:00:20s\n",
      "epoch 137| loss: 0.50007 |  0:00:20s\n",
      "epoch 138| loss: 0.48329 |  0:00:21s\n",
      "epoch 139| loss: 0.46816 |  0:00:21s\n",
      "epoch 140| loss: 0.56659 |  0:00:21s\n",
      "epoch 141| loss: 0.54847 |  0:00:21s\n",
      "epoch 142| loss: 0.51725 |  0:00:21s\n",
      "epoch 143| loss: 0.46739 |  0:00:21s\n",
      "epoch 144| loss: 0.48042 |  0:00:21s\n",
      "epoch 145| loss: 0.52589 |  0:00:22s\n",
      "epoch 146| loss: 0.4433  |  0:00:22s\n",
      "epoch 147| loss: 0.47857 |  0:00:22s\n",
      "epoch 148| loss: 0.46063 |  0:00:22s\n",
      "epoch 149| loss: 0.48013 |  0:00:22s\n",
      "epoch 150| loss: 0.45411 |  0:00:22s\n",
      "epoch 151| loss: 0.53575 |  0:00:22s\n",
      "epoch 152| loss: 0.4535  |  0:00:23s\n",
      "epoch 153| loss: 0.48309 |  0:00:23s\n",
      "epoch 154| loss: 0.54323 |  0:00:23s\n",
      "epoch 155| loss: 0.46631 |  0:00:23s\n",
      "epoch 156| loss: 0.47907 |  0:00:23s\n",
      "epoch 157| loss: 0.47146 |  0:00:23s\n",
      "epoch 158| loss: 0.44015 |  0:00:23s\n",
      "epoch 159| loss: 0.44053 |  0:00:24s\n",
      "epoch 160| loss: 0.43162 |  0:00:24s\n",
      "epoch 161| loss: 0.5176  |  0:00:24s\n",
      "epoch 162| loss: 0.46432 |  0:00:24s\n",
      "epoch 163| loss: 0.46964 |  0:00:24s\n",
      "epoch 164| loss: 0.40918 |  0:00:24s\n",
      "epoch 165| loss: 0.46204 |  0:00:24s\n",
      "epoch 166| loss: 0.49607 |  0:00:25s\n",
      "epoch 167| loss: 0.51562 |  0:00:25s\n",
      "epoch 168| loss: 0.43349 |  0:00:25s\n",
      "epoch 169| loss: 0.48501 |  0:00:25s\n",
      "epoch 170| loss: 0.46514 |  0:00:25s\n",
      "epoch 171| loss: 0.46317 |  0:00:25s\n",
      "epoch 172| loss: 0.48236 |  0:00:25s\n",
      "epoch 173| loss: 0.45728 |  0:00:26s\n",
      "epoch 174| loss: 0.39695 |  0:00:26s\n",
      "epoch 175| loss: 0.43234 |  0:00:26s\n",
      "epoch 176| loss: 0.42707 |  0:00:26s\n",
      "epoch 177| loss: 0.44129 |  0:00:26s\n",
      "epoch 178| loss: 0.43146 |  0:00:26s\n",
      "epoch 179| loss: 0.45481 |  0:00:26s\n",
      "epoch 180| loss: 0.43694 |  0:00:27s\n",
      "epoch 181| loss: 0.48701 |  0:00:27s\n",
      "epoch 182| loss: 0.44707 |  0:00:27s\n",
      "epoch 183| loss: 0.43138 |  0:00:27s\n",
      "epoch 184| loss: 0.44948 |  0:00:27s\n",
      "epoch 185| loss: 0.45976 |  0:00:27s\n",
      "epoch 186| loss: 0.43708 |  0:00:27s\n",
      "epoch 187| loss: 0.40271 |  0:00:28s\n",
      "epoch 188| loss: 0.39433 |  0:00:28s\n",
      "epoch 189| loss: 0.42739 |  0:00:28s\n",
      "epoch 190| loss: 0.42279 |  0:00:28s\n",
      "epoch 191| loss: 0.4201  |  0:00:28s\n",
      "epoch 192| loss: 0.41198 |  0:00:28s\n",
      "epoch 193| loss: 0.44184 |  0:00:28s\n",
      "epoch 194| loss: 0.4562  |  0:00:29s\n",
      "epoch 195| loss: 0.42736 |  0:00:29s\n",
      "epoch 196| loss: 0.43376 |  0:00:29s\n",
      "epoch 197| loss: 0.43478 |  0:00:29s\n",
      "epoch 198| loss: 0.48294 |  0:00:29s\n",
      "epoch 199| loss: 0.44584 |  0:00:29s\n"
     ]
    }
   ],
   "source": [
    "model_list=[xgb_model,lgbm_model,cat_model,rf_model,gbdt_model,svr_model,lcv_model,ANN_model,TabNet_model]\n",
    "model_name_list=['XGBoost','LGBM','CatBoost','RF','GBDT','SVR','LR','ANN','TabNet']\n",
    "for i,j in zip(model_name_list,model_list):\n",
    "    print(i)\n",
    "    if i == 'TabNet':\n",
    "        j.fit(X_train=tran_x_sm.to_numpy(), \n",
    "            y_train=tran_y_sm.to_numpy().reshape(-1,1),\n",
    "            max_epochs=200, \n",
    "            patience=50,\n",
    "            batch_size=64, \n",
    "            virtual_batch_size=16,\n",
    "            num_workers=0,\n",
    "            drop_last=False)\n",
    "    else:\n",
    "        j.fit(tran_x_sm,tran_y_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "LGBM\n",
      "CatBoost\n",
      "RF\n",
      "GBDT\n",
      "SVR\n",
      "LR\n",
      "ANN\n",
      "TabNet\n"
     ]
    }
   ],
   "source": [
    "# 计算评价指标compute evaluation metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "# 统一模型输出结果\n",
    "df_model_result=pd.DataFrame(columns=[['model','precision','recall','f1','accuracy','AUC']])\n",
    "model_list=[xgb_model,lgbm_model,cat_model,rf_model,gbdt_model,svr_model,lcv_model,ANN_model,TabNet_model]\n",
    "model_name_list=['XGBoost','LGBM','CatBoost','RF','GBDT','SVR','LR','ANN','TabNet']\n",
    "\n",
    "for model,name in zip(model_list,model_name_list):\n",
    "    print(name)\n",
    "    # 计算accuracy和AUC\n",
    "    # tabnet predict_proba结果是三维数组，无法计算auc，需要reshape(-1,6),所有行 x 6列\n",
    "    if name == 'TabNet':\n",
    "        test_temp=test_x.copy()\n",
    "        test_x=test_x.to_numpy()\n",
    "    test_y_score=np.reshape(model.predict_proba(test_x),(-1,4))\n",
    "    auc=roc_auc_score(test_y,test_y_score,multi_class='ovr')\n",
    "    auc=round(auc,2)\n",
    "    # tabnet predict结果是三维数组，无法计算auc，需要reshape\n",
    "    predictions=np.reshape(model.predict(test_x),(-1,1)).astype(str)\n",
    "    accuracy=accuracy_score(test_y.astype(str),predictions)\n",
    "    accuracy=round(accuracy,2)\n",
    "    # 计算precision、recall、F1\n",
    "    precision=precision_score(test_y.astype(str),predictions,average='macro')\n",
    "    precision=round(precision,2)\n",
    "    recall=recall_score(test_y.astype(str),predictions,average='macro')\n",
    "    recall=round(recall,2)\n",
    "    f1=f1_score(test_y.astype(str),predictions,average='macro')\n",
    "    f1=round(f1,2)\n",
    "    if name == 'TabNet':\n",
    "        test_x=test_temp\n",
    "        \n",
    "    df_model_result.loc[df_model_result.shape[0],['model','precision','recall','f1','accuracy','AUC']]=\\\n",
    "                                                                [name,precision,recall,f1,accuracy,auc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GBDT</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ANN</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TabNet</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model precision recall    f1 accuracy   AUC\n",
       "0   XGBoost      0.61   0.57  0.58     0.58  0.79\n",
       "1      LGBM      0.55   0.54  0.54     0.55  0.75\n",
       "2  CatBoost      0.66    0.6  0.61     0.61  0.77\n",
       "3        RF      0.62   0.57  0.57     0.58  0.79\n",
       "4      GBDT      0.54   0.52  0.53     0.52  0.75\n",
       "5       SVR      0.48   0.47  0.47     0.48  0.75\n",
       "6        LR      0.48   0.48  0.47     0.49  0.75\n",
       "7       ANN      0.49    0.5  0.48     0.51  0.76\n",
       "8    TabNet      0.47   0.46  0.46     0.48   0.7"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型测试效果\n",
    "df_model_result.to_excel(project_path+'/data/result/modeling/df_1.6_多分类模型测试效果_5折 on training dataset_术后.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 术后风险评分数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建术后生存分析数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importance =pd.read_excel(project_path +'/data/result/modeling/df_1.6_模型重要性评分_术后.xlsx',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_col=df_importance['特征'].to_list()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tumor_CA19-9',\n",
       " 'DB',\n",
       " 'ALT',\n",
       " 'tumor_CA125',\n",
       " 'tumor_CEA',\n",
       " 'tumor_size',\n",
       " 'tumor_AFP',\n",
       " 'N',\n",
       " 'surgery_result',\n",
       " 'T',\n",
       " 'emaciation',\n",
       " 'Bismuth_C',\n",
       " 'MSKCC',\n",
       " 'Gazzaniga_T',\n",
       " 'Blumgart_T',\n",
       " 'biliary_disease',\n",
       " 'HBsAg',\n",
       " 'M',\n",
       " 'jaundice',\n",
       " 'cardio_disease']"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(importance_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加入生存期和标签\n",
    "survival_col=['target_3Y_death','target_survival_month']\n",
    "importance_col.extend(survival_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tumor_CA19-9',\n",
       " 'DB',\n",
       " 'ALT',\n",
       " 'tumor_CA125',\n",
       " 'tumor_CEA',\n",
       " 'tumor_size',\n",
       " 'tumor_AFP',\n",
       " 'N',\n",
       " 'surgery_result',\n",
       " 'T',\n",
       " 'emaciation',\n",
       " 'Bismuth_C',\n",
       " 'MSKCC',\n",
       " 'Gazzaniga_T',\n",
       " 'Blumgart_T',\n",
       " 'biliary_disease',\n",
       " 'HBsAg',\n",
       " 'M',\n",
       " 'jaundice',\n",
       " 'cardio_disease',\n",
       " 'target_3Y_death',\n",
       " 'target_survival_month']"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_cox_after =pd.read_excel(project_path +'/data/processed_data/df_3.1.1_术后预后cox数据集.xlsx',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(451, 75)"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset_cox_after.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_cox_after_importance=df_dataset_cox_after[importance_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(451, 22)"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset_cox_after_importance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tumor_CA19-9', 'DB', 'ALT', 'tumor_CA125', 'tumor_CEA', 'tumor_size',\n",
       "       'tumor_AFP', 'N', 'surgery_result', 'T', 'emaciation', 'Bismuth_C',\n",
       "       'MSKCC', 'Gazzaniga_T', 'Blumgart_T', 'biliary_disease', 'HBsAg', 'M',\n",
       "       'jaundice', 'cardio_disease', 'target_3Y_death',\n",
       "       'target_survival_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset_cox_after_importance.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练集与测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_col=['N', 'surgery_result', 'T', 'emaciation', 'Bismuth_C',\n",
    "       'MSKCC', 'Gazzaniga_T', 'Blumgart_T', 'biliary_disease', 'HBsAg', 'M',\n",
    "       'jaundice', 'cardio_disease']\n",
    "continuous_col=[x for x in df_dataset_cox_after_importance.columns if x not in discrete_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 筛选随机数种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kstest,shapiro\n",
    "##检验是否正态\n",
    "def norm_test(data):\n",
    "    if len(data) > 30:\n",
    "        norm, p = kstest(data, 'norm')\n",
    "    else:\n",
    "        norm, p = shapiro(data)\n",
    "    #print(t,p)\n",
    "    if p>=0.05:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "# 连续变量的显著性检验\n",
    "def test2(data_b, data_p):\n",
    "    if norm_test(data_b) and norm_test(data_p):\n",
    "        x = 1\n",
    "        y = '独立样本T检验'\n",
    "        t, p = st.ttest_ind(list(data_b),list(data_p), nan_policy='omit')\n",
    "    else:\n",
    "        x = 0\n",
    "        y = 'Mann-Whitney U检验'\n",
    "        t,p = st.mannwhitneyu(list(data_b),list(data_p))\n",
    "    return x,y,t,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_test(df_high,df_low,list1):\n",
    "\n",
    "    feature_list=[]  # 特征列表\n",
    "    y_list=[]  # 显著性检验方法\n",
    "    t_list=[]  # 统计量\n",
    "    p_list=[]  # p值\n",
    "    result_list=[]  # 是否显著\n",
    "    high_mean_list=[]\n",
    "    low_mean_list=[]\n",
    "\n",
    "    for i in list1:\n",
    "        print(i)\n",
    "        # 高剂量组统计\n",
    "        df_high_nt=df_high[df_high[i].notnull()]\n",
    "        data_high=df_high_nt[i]\n",
    "        high_mean=round(data_high.mean(),2)\n",
    "        \n",
    "        df_low_nt=df_low[df_low[i].notnull()]\n",
    "        data_low=df_low_nt[i]\n",
    "        low_mean=round(data_low.mean(),2)\n",
    "\n",
    "        # 计算高低剂量组显著性差异\n",
    "        if data_high.shape[0] >= 10 and data_low.shape[0]>=10:\n",
    "            # 连续变量检验\n",
    "            x,y,t,p = test2(data_high, data_low)\n",
    "            t=round(t,2)\n",
    "            p=round(p,3)\n",
    "            if p <=0.05:\n",
    "                sig='显著'\n",
    "            else:\n",
    "                sig='不显著'\n",
    "            # 显著性 \n",
    "            feature_list.append(i)\n",
    "            y_list.append(y)\n",
    "            t_list.append(t)\n",
    "            p_list.append(p)\n",
    "            result_list.append(sig)\n",
    "            high_mean_list.append(high_mean)\n",
    "            low_mean_list.append(low_mean)\n",
    "\n",
    "    df_result=pd.DataFrame({'特征':feature_list,\n",
    "                            '高剂量均值':high_mean_list,\n",
    "                            '低剂量均值':low_mean_list,\n",
    "                            '检验指标':y_list,\n",
    "                            't值':t_list,\n",
    "                            'p值':p_list,\n",
    "                            '显著性结果':result_list})\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n",
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n"
     ]
    }
   ],
   "source": [
    "# 筛选出划分效果最均衡的随机数种子\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 划分训练集和测试集，比例为8:2\n",
    "seed_index_list=[]\n",
    "p_mean_list=[]\n",
    "for i in range(100):\n",
    "    df_after_tran, df_after_test = train_test_split(df_dataset_cox_after_importance, test_size=0.2, random_state=i)\n",
    "    df_continuous_sig = sig_test(df_after_tran,df_after_test,continuous_col)\n",
    "    p_mean=df_continuous_sig['p值'].mean() + df_continuous_sig['p值'].std()\n",
    "    seed_index_list.append(i)\n",
    "    p_mean_list.append(p_mean)\n",
    "    \n",
    "df_p_mean=pd.DataFrame(data={'seed_index':seed_index_list,\n",
    "                            'p_mean':p_mean_list})\n",
    "df_p_mean=df_p_mean.sort_values(['p_mean'],ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed_index</th>\n",
       "      <th>p_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>0.999911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>0.956901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96</td>\n",
       "      <td>0.956517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98</td>\n",
       "      <td>0.951422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>0.949338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>13</td>\n",
       "      <td>0.587451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>94</td>\n",
       "      <td>0.583727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>59</td>\n",
       "      <td>0.576886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3</td>\n",
       "      <td>0.566953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>10</td>\n",
       "      <td>0.541650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    seed_index    p_mean\n",
       "0           75  0.999911\n",
       "1           15  0.956901\n",
       "2           96  0.956517\n",
       "3           98  0.951422\n",
       "4           55  0.949338\n",
       "..         ...       ...\n",
       "95          13  0.587451\n",
       "96          94  0.583727\n",
       "97          59  0.576886\n",
       "98           3  0.566953\n",
       "99          10  0.541650\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_index= 15 #df_p_mean.loc[0,'seed_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 划分训练集和测试集，比例为8:2\n",
    "df_after_ML_tran, df_after_ML_test = train_test_split(df_dataset_cox_after_importance, test_size=0.2,\n",
    "                                                                random_state=seed_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 22)\n",
      "(91, 22)\n"
     ]
    }
   ],
   "source": [
    "print(df_after_ML_tran.shape)\n",
    "print(df_after_ML_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_after_ML_tran.to_excel(project_path+'/data/result/cox/df_1.7.2.2_after_ML_tran.xlsx')\n",
    "df_after_ML_test.to_excel(project_path+'/data/result/cox/df_1.7.2.2_after_ML_test.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据集同分布检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N',\n",
       " 'surgery_result',\n",
       " 'T',\n",
       " 'emaciation',\n",
       " 'Bismuth_C',\n",
       " 'MSKCC',\n",
       " 'Gazzaniga_T',\n",
       " 'Blumgart_T',\n",
       " 'biliary_disease',\n",
       " 'HBsAg',\n",
       " 'M',\n",
       " 'jaundice',\n",
       " 'cardio_disease']"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n",
      "surgery_result\n",
      "T\n",
      "emaciation\n",
      "Bismuth_C\n",
      "MSKCC\n",
      "Gazzaniga_T\n",
      "Blumgart_T\n",
      "biliary_disease\n",
      "HBsAg\n",
      "M\n",
      "jaundice\n",
      "cardio_disease\n"
     ]
    }
   ],
   "source": [
    "# 判断训练集与测试集是否独立同分布\n",
    "# 分类变量显著性分析\n",
    "from scipy.stats import chi2_contingency\n",
    "feature_list=[]\n",
    "y_list=[]\n",
    "t_list=[]\n",
    "p_list=[]\n",
    "sig_list=[]\n",
    "for i in discrete_col:\n",
    "    print(i)\n",
    "    result = chi2_contingency(pd.DataFrame([df_after_ML_tran[i].value_counts().to_list(),\n",
    "                               df_after_ML_test[i].value_counts().to_list()]).fillna(0))\n",
    "    t,p=result[0:2]\n",
    "    t=round(t,2)\n",
    "    p=round(p,3)\n",
    "    feature_list.append(i)\n",
    "    y_list.append('卡方检验')\n",
    "    t_list.append(t)\n",
    "    p_list.append(p)\n",
    "    if p <=0.05:\n",
    "        sig='显著'\n",
    "    else:\n",
    "        sig='不显著'\n",
    "    sig_list.append(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discrete_sig=pd.DataFrame(data={'feature':discrete_col,\n",
    "                                        'method':y_list,\n",
    "                                        't':t_list,\n",
    "                                        'p':p_list,\n",
    "                                        'result':sig_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>method</th>\n",
       "      <th>t</th>\n",
       "      <th>p</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>卡方检验</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.252</td>\n",
       "      <td>不显著</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>surgery_result</td>\n",
       "      <td>卡方检验</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.806</td>\n",
       "      <td>不显著</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T</td>\n",
       "      <td>卡方检验</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.575</td>\n",
       "      <td>不显著</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>emaciation</td>\n",
       "      <td>卡方检验</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.910</td>\n",
       "      <td>不显著</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bismuth_C</td>\n",
       "      <td>卡方检验</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.805</td>\n",
       "      <td>不显著</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MSKCC</td>\n",
       "      <td>卡方检验</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.519</td>\n",
       "      <td>不显著</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gazzaniga_T</td>\n",
       "      <td>卡方检验</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.915</td>\n",
       "      <td>不显著</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Blumgart_T</td>\n",
       "      <td>卡方检验</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.726</td>\n",
       "      <td>不显著</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>biliary_disease</td>\n",
       "      <td>卡方检验</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.411</td>\n",
       "      <td>不显著</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HBsAg</td>\n",
       "      <td>卡方检验</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>不显著</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>M</td>\n",
       "      <td>卡方检验</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.766</td>\n",
       "      <td>不显著</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>jaundice</td>\n",
       "      <td>卡方检验</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.997</td>\n",
       "      <td>不显著</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cardio_disease</td>\n",
       "      <td>卡方检验</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.977</td>\n",
       "      <td>不显著</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature method     t      p result\n",
       "0                 N   卡方检验  2.76  0.252    不显著\n",
       "1    surgery_result   卡方检验  0.43  0.806    不显著\n",
       "2                 T   卡方检验  2.90  0.575    不显著\n",
       "3        emaciation   卡方检验  0.19  0.910    不显著\n",
       "4         Bismuth_C   卡方检验  0.98  0.805    不显著\n",
       "5             MSKCC   卡方检验  1.31  0.519    不显著\n",
       "6       Gazzaniga_T   卡方检验  0.52  0.915    不显著\n",
       "7        Blumgart_T   卡方检验  1.31  0.726    不显著\n",
       "8   biliary_disease   卡方检验  0.68  0.411    不显著\n",
       "9             HBsAg   卡方检验  0.00  1.000    不显著\n",
       "10                M   卡方检验  0.09  0.766    不显著\n",
       "11         jaundice   卡方检验  0.00  0.997    不显著\n",
       "12   cardio_disease   卡方检验  0.00  0.977    不显著"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_discrete_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discrete_sig.to_excel(project_path+'/data/result/cox/df_1.7.2.3_after_分类变量数据同分布检验.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tumor_CA19-9\n",
      "DB\n",
      "ALT\n",
      "tumor_CA125\n",
      "tumor_CEA\n",
      "tumor_size\n",
      "tumor_AFP\n",
      "target_3Y_death\n",
      "target_survival_month\n"
     ]
    }
   ],
   "source": [
    "# 连续变量显著性分析\n",
    "df_continuous_sig = sig_test(df_after_ML_tran,df_after_ML_test,continuous_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>特征</th>\n",
       "      <th>高剂量均值</th>\n",
       "      <th>低剂量均值</th>\n",
       "      <th>检验指标</th>\n",
       "      <th>t值</th>\n",
       "      <th>p值</th>\n",
       "      <th>显著性结果</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tumor_CA19-9</td>\n",
       "      <td>377.04</td>\n",
       "      <td>369.89</td>\n",
       "      <td>Mann-Whitney U检验</td>\n",
       "      <td>16230.5</td>\n",
       "      <td>0.910</td>\n",
       "      <td>不显著</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DB</td>\n",
       "      <td>146.32</td>\n",
       "      <td>138.52</td>\n",
       "      <td>Mann-Whitney U检验</td>\n",
       "      <td>13057.0</td>\n",
       "      <td>0.745</td>\n",
       "      <td>不显著</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALT</td>\n",
       "      <td>157.50</td>\n",
       "      <td>184.45</td>\n",
       "      <td>Mann-Whitney U检验</td>\n",
       "      <td>11682.0</td>\n",
       "      <td>0.336</td>\n",
       "      <td>不显著</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tumor_CA125</td>\n",
       "      <td>35.20</td>\n",
       "      <td>34.87</td>\n",
       "      <td>Mann-Whitney U检验</td>\n",
       "      <td>5880.5</td>\n",
       "      <td>0.028</td>\n",
       "      <td>显著</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tumor_CEA</td>\n",
       "      <td>6.73</td>\n",
       "      <td>4.36</td>\n",
       "      <td>Mann-Whitney U检验</td>\n",
       "      <td>17505.0</td>\n",
       "      <td>0.103</td>\n",
       "      <td>不显著</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tumor_size</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.87</td>\n",
       "      <td>Mann-Whitney U检验</td>\n",
       "      <td>9621.0</td>\n",
       "      <td>0.996</td>\n",
       "      <td>不显著</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tumor_AFP</td>\n",
       "      <td>4.96</td>\n",
       "      <td>16.74</td>\n",
       "      <td>Mann-Whitney U检验</td>\n",
       "      <td>16782.0</td>\n",
       "      <td>0.202</td>\n",
       "      <td>不显著</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>target_3Y_death</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>Mann-Whitney U检验</td>\n",
       "      <td>8872.5</td>\n",
       "      <td>1.000</td>\n",
       "      <td>不显著</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>target_survival_month</td>\n",
       "      <td>23.79</td>\n",
       "      <td>24.74</td>\n",
       "      <td>Mann-Whitney U检验</td>\n",
       "      <td>8640.0</td>\n",
       "      <td>0.743</td>\n",
       "      <td>不显著</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      特征   高剂量均值   低剂量均值              检验指标       t值     p值  \\\n",
       "0           tumor_CA19-9  377.04  369.89  Mann-Whitney U检验  16230.5  0.910   \n",
       "1                     DB  146.32  138.52  Mann-Whitney U检验  13057.0  0.745   \n",
       "2                    ALT  157.50  184.45  Mann-Whitney U检验  11682.0  0.336   \n",
       "3            tumor_CA125   35.20   34.87  Mann-Whitney U检验   5880.5  0.028   \n",
       "4              tumor_CEA    6.73    4.36  Mann-Whitney U检验  17505.0  0.103   \n",
       "5             tumor_size    2.90    2.87  Mann-Whitney U检验   9621.0  0.996   \n",
       "6              tumor_AFP    4.96   16.74  Mann-Whitney U检验  16782.0  0.202   \n",
       "7        target_3Y_death    0.77    0.77  Mann-Whitney U检验   8872.5  1.000   \n",
       "8  target_survival_month   23.79   24.74  Mann-Whitney U检验   8640.0  0.743   \n",
       "\n",
       "  显著性结果  \n",
       "0   不显著  \n",
       "1   不显著  \n",
       "2   不显著  \n",
       "3    显著  \n",
       "4   不显著  \n",
       "5   不显著  \n",
       "6   不显著  \n",
       "7   不显著  \n",
       "8   不显著  "
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_continuous_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_continuous_sig.to_excel(project_path+'/data/result/cox/df_1.7.2.3_after_连续变量数据同分布检验.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据统计分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分类变量数据统计\n",
    "def stats_discrete(df_model,discrete_col):\n",
    "    # 求分类变量比例\n",
    "    df_discrete_stat=pd.DataFrame(columns=['变量名称','所有事件(%d)' % df_model.shape[0],'缺失率(%)'])\n",
    "    for i in discrete_col:\n",
    "        print(i)\n",
    "        # 缺失率\n",
    "        if df_model[i].isnull().sum()==0:\n",
    "            miss_rate='0%'\n",
    "        else:\n",
    "            miss_rate=df_model[i].isnull().sum()/df_model.shape[0]\n",
    "            miss_rate=\"%.2f%%\" % (miss_rate * 100)      # 百分数输出\n",
    "        df_discrete_stat.loc[df_discrete_stat.shape[0],['变量名称','缺失率(%)']]=[i+'，n(%)',miss_rate]\n",
    "\n",
    "        # 分类变量单独统计\n",
    "        name_list=[]\n",
    "        num_perc_list=[]\n",
    "        df_model_stat=df_model[df_model[i].notnull()].sort_values([i],ascending=True)\n",
    "\n",
    "        # 二分类还是多分类变量\n",
    "        if df_model_stat[i].nunique() <=2:\n",
    "            if re.match('gender|性别',i):\n",
    "                name_list=['男','女']\n",
    "            else:\n",
    "                name_list=['是','否']\n",
    "            for name,value in zip(name_list,[1,0]):\n",
    "                print(name)\n",
    "                num=df_model_stat[df_model_stat[i]==value].shape[0]\n",
    "                percent=num/df_model.shape[0]\n",
    "                percent=\"%.2f%%\" % (percent * 100)\n",
    "                num_percent=str(num)+'('+percent+')'\n",
    "                num_perc_list.append(num_percent)\n",
    "        else:\n",
    "            for value in sorted(df_model_stat[i].unique()):\n",
    "                print(value)\n",
    "                name_list.append(value)\n",
    "                num=df_model_stat[df_model_stat[i]==value].shape[0]\n",
    "                percent=num/df_model.shape[0]\n",
    "                percent=\"%.2f%%\" % (percent * 100)\n",
    "                num_percent=str(num)+'('+percent+')'\n",
    "                num_perc_list.append(num_percent)\n",
    "\n",
    "\n",
    "        df_temp = pd.DataFrame(data={'变量名称':name_list,\n",
    "                                     '所有事件(%d)' % df_model.shape[0]:num_perc_list})\n",
    "\n",
    "        df_discrete_stat=pd.concat([df_discrete_stat,df_temp],axis=0)\n",
    "        df_discrete_stat=df_discrete_stat.reset_index(drop=True)\n",
    "    return df_discrete_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n",
      "0.0\n",
      "1.0\n",
      "2.0\n",
      "surgery_result\n",
      "0.0\n",
      "1.0\n",
      "2.0\n",
      "T\n",
      "0.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "emaciation\n",
      "0.0\n",
      "1.0\n",
      "2.0\n",
      "Bismuth_C\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "MSKCC\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "Gazzaniga_T\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "Blumgart_T\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "biliary_disease\n",
      "是\n",
      "否\n",
      "HBsAg\n",
      "是\n",
      "否\n",
      "M\n",
      "是\n",
      "否\n",
      "jaundice\n",
      "是\n",
      "否\n",
      "cardio_disease\n",
      "是\n",
      "否\n",
      "N\n",
      "0.0\n",
      "1.0\n",
      "2.0\n",
      "surgery_result\n",
      "0.0\n",
      "1.0\n",
      "2.0\n",
      "T\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "emaciation\n",
      "0.0\n",
      "1.0\n",
      "2.0\n",
      "Bismuth_C\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "MSKCC\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "Gazzaniga_T\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "Blumgart_T\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "biliary_disease\n",
      "是\n",
      "否\n",
      "HBsAg\n",
      "是\n",
      "否\n",
      "M\n",
      "是\n",
      "否\n",
      "jaundice\n",
      "是\n",
      "否\n",
      "cardio_disease\n",
      "是\n",
      "否\n"
     ]
    }
   ],
   "source": [
    "df_discrete_stat_tran=stats_discrete(df_after_ML_tran,discrete_col)\n",
    "df_discrete_stat_tran.to_excel(project_path+'/data/result/cox/df_1.7.2.4_after_分类_tran_数据统计.xlsx')\n",
    "df_discrete_stat_test=stats_discrete(df_after_ML_test,discrete_col)\n",
    "df_discrete_stat_test.to_excel(project_path+'/data/result/cox/df_1.7.2.4_after_分类_test_数据统计.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连续变量数据统计\n",
    "def stats_continuous(df_model,continuous_col):\n",
    "    # 统计全变量体系各变量的平均数、上下四分位数、缺失率\n",
    "    feature_quarter_list=[]\n",
    "    mean_quarter_list=[]\n",
    "    feature_std_list=[]\n",
    "    mean_std_list=[]\n",
    "    miss_list=[]\n",
    "    for i in continuous_col:\n",
    "        # 计算上下四分位、均值、标准差\n",
    "        try:\n",
    "            data = df_model[i].astype('float')\n",
    "            stat_result = pd.DataFrame(data.describe())\n",
    "            mean_value=stat_result.loc['mean',i]\n",
    "            up_quarter=stat_result.loc['25%',i]\n",
    "            down_quarter=stat_result.loc['75%',i]\n",
    "            std_value=stat_result.loc['std',i]\n",
    "        except:\n",
    "            mean_value=np.nan\n",
    "            up_quarter=np.nan\n",
    "            down_quarter=np.nan\n",
    "        # 计算缺失率\n",
    "        if df_model[i].isnull().sum()==0:\n",
    "            miss_rate='0%'\n",
    "        else:\n",
    "            miss_rate=df_model[i].isnull().sum()/df_model.shape[0]\n",
    "            miss_rate=\"%.2f%%\" % (miss_rate * 100)      # 百分数输出\n",
    "        miss_list.append(miss_rate)\n",
    "        # mean(quarter)\n",
    "        feature_quarter_list.append(i+'，mean（IQR）')\n",
    "        mean_quarter_list.append('%.2f(%.2f-%.2f)' % (mean_value,up_quarter,down_quarter))\n",
    "        # mean(std)\n",
    "        feature_std_list.append(i+'，mean±std')\n",
    "        mean_std_list.append('%.2f±%.2f' % (mean_value,std_value))\n",
    "\n",
    "    df_continuous_quarter=pd.DataFrame(data={'特征':feature_quarter_list,\n",
    "                            'mean_quarter_list':mean_quarter_list,\n",
    "                            'miss_list':miss_list})\n",
    "    df_continuous_std=pd.DataFrame(data={'特征':feature_std_list,\n",
    "                            'mean_std_list':mean_std_list,\n",
    "                            'miss_list':miss_list})\n",
    "    return df_continuous_quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_continuous_stat_tran=stats_continuous(df_after_ML_tran,continuous_col)\n",
    "df_continuous_stat_tran.to_excel(project_path+'/data/result/cox/df_1.7.2.4_after_连续_tran_数据统计.xlsx')\n",
    "df_continuous_stat_test=stats_continuous(df_after_ML_test,continuous_col)\n",
    "df_continuous_stat_test.to_excel(project_path+'/data/result/cox/df_1.7.2.4_after_连续_test_数据统计.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 处理Ml变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每列缺失率: tumor_CA19-9 1.33%\n",
      "每列缺失率: DB 12.20%\n",
      "每列缺失率: ALT 11.97%\n",
      "每列缺失率: tumor_CA125 34.15%\n",
      "每列缺失率: tumor_CEA 2.44%\n",
      "每列缺失率: tumor_size 22.84%\n",
      "每列缺失率: tumor_AFP 3.99%\n",
      "每列缺失率: N 8.87%\n",
      "每列缺失率: surgery_result 10.20%\n",
      "每列缺失率: T 6.65%\n",
      "每列缺失率: emaciation 14.19%\n",
      "每列缺失率: Bismuth_C 7.10%\n",
      "每列缺失率: MSKCC 7.54%\n",
      "每列缺失率: Gazzaniga_T 7.54%\n",
      "每列缺失率: Blumgart_T 7.54%\n",
      "每列缺失率: biliary_disease 0.44%\n",
      "每列缺失率: HBsAg 9.53%\n",
      "每列缺失率: M 6.65%\n",
      "每列缺失率: jaundice 0.00%\n",
      "每列缺失率: cardio_disease 0.22%\n",
      "每列缺失率: target_3Y_death 25.06%\n",
      "每列缺失率: target_survival_month 25.06%\n"
     ]
    }
   ],
   "source": [
    "# 查看缺失率\n",
    "for i in df_dataset_cox_after_importance.columns:\n",
    "    percent_col= df_dataset_cox_after_importance[i].isnull().sum()/df_dataset_cox_after_importance.shape[0]\n",
    "    percent_col=\"%.2f%%\" % (percent_col * 100)\n",
    "    print('每列缺失率:',i,percent_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除缺失超过20%的变量\n",
    "df_after_ML_tran_cox=df_after_ML_tran.drop(['tumor_CA125','tumor_size'],axis=1)\n",
    "df_after_ML_test_cox=df_after_ML_test.drop(['tumor_CA125','tumor_size'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 20)"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_after_ML_tran_cox.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 剔除缺失值\n",
    "for i in df_after_ML_tran_cox.columns:\n",
    "    df_after_ML_tran_cox = df_after_ML_tran_cox[df_after_ML_tran_cox[i].notnull()]\n",
    "    df_after_ML_test_cox = df_after_ML_test_cox[df_after_ML_test_cox[i].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174, 20)"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_after_ML_tran_cox.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分类不平衡变量\n",
    "for i in df_dataset_cox_after_importance.columns:\n",
    "    if df_dataset_cox_after_importance[i].nunique() < 2:\n",
    "        print(i)\n",
    "        del df_after_ML_tran_cox[i]\n",
    "        del df_after_ML_test_cox[i]\n",
    "        continue\n",
    "    if df_dataset_cox_after_importance[i].nunique() == 2:\n",
    "        # 如果分类变量中某一变量的占比超过90%，则删除该指标\n",
    "        num_1 = df_dataset_cox_after_importance[i].value_counts()  # df一列中不同变量的数目\n",
    "        num_2 = num_1.div(df_dataset_cox_after_importance.shape[0])  # div除法，所有元素都除以相同数值\n",
    "        num_3 = num_2.max()  # 取出最大值\n",
    "        if num_3 >= 0.9:\n",
    "            print(i)\n",
    "            del df_after_ML_tran_cox[i]\n",
    "            del df_after_ML_test_cox[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tumor_CA19-9', 'DB', 'ALT', 'tumor_CEA', 'tumor_AFP', 'N',\n",
       "       'surgery_result', 'T', 'emaciation', 'Bismuth_C', 'MSKCC',\n",
       "       'Gazzaniga_T', 'Blumgart_T', 'biliary_disease', 'HBsAg', 'M',\n",
       "       'jaundice', 'cardio_disease', 'target_3Y_death',\n",
       "       'target_survival_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_after_ML_tran_cox.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_after_ML_tran_cox.to_excel(project_path+'/data/result/cox/df_1.7.2.5_after_ML_tran_cox.xlsx')\n",
    "df_after_ML_test_cox.to_excel(project_path+'/data/result/cox/df_1.7.2.5_after_ML_test_cox.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 处理全部变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每列缺失率: sampling 0.00%\n",
      "每列缺失率: gender 0.22%\n",
      "每列缺失率: age 0.22%\n",
      "每列缺失率: height 31.93%\n",
      "每列缺失率: weight 31.93%\n",
      "每列缺失率: BMI 31.93%\n",
      "每列缺失率: jaundice 0.00%\n",
      "每列缺失率: emaciation 14.19%\n",
      "每列缺失率: breath_disease 0.22%\n",
      "每列缺失率: cardio_disease 0.22%\n",
      "每列缺失率: nbdd 0.22%\n",
      "每列缺失率: urinary_disease 0.67%\n",
      "每列缺失率: endocrine_disease 0.44%\n",
      "每列缺失率: biliary_disease 0.44%\n",
      "每列缺失率: other_disease 0.89%\n",
      "每列缺失率: smoke 0.00%\n",
      "每列缺失率: drinking 4.88%\n",
      "每列缺失率: family_history 1.55%\n",
      "每列缺失率: blood_type 71.18%\n",
      "每列缺失率: WBC 12.42%\n",
      "每列缺失率: HGB 13.08%\n",
      "每列缺失率: PLT 15.30%\n",
      "每列缺失率: TB 1.11%\n",
      "每列缺失率: DB 12.20%\n",
      "每列缺失率: TBA 31.93%\n",
      "每列缺失率: TP 16.63%\n",
      "每列缺失率: ALB 3.77%\n",
      "每列缺失率: LG 66.30%\n",
      "每列缺失率: AG 32.59%\n",
      "每列缺失率: PAB 23.06%\n",
      "每列缺失率: ALT 11.97%\n",
      "每列缺失率: AST 18.63%\n",
      "每列缺失率: GT 28.60%\n",
      "每列缺失率: ALP 30.60%\n",
      "每列缺失率: tumor_AFP 3.99%\n",
      "每列缺失率: tumor_CEA 2.44%\n",
      "每列缺失率: tumor_CA19-9 1.33%\n",
      "每列缺失率: tumor_CA125 34.15%\n",
      "每列缺失率: TF 78.71%\n",
      "每列缺失率: tumor_size 22.84%\n",
      "每列缺失率: HBsAg 9.53%\n",
      "每列缺失率: HBeAg 15.08%\n",
      "每列缺失率: HBeAb 15.08%\n",
      "每列缺失率: HBcAb 15.30%\n",
      "每列缺失率: HCVAb 15.96%\n",
      "每列缺失率: LC 25.28%\n",
      "每列缺失率: T 6.65%\n",
      "每列缺失率: N 8.87%\n",
      "每列缺失率: M 6.65%\n",
      "每列缺失率: AJCC_8 6.87%\n",
      "每列缺失率: Gazzaniga_T 7.54%\n",
      "每列缺失率: MSKCC 7.54%\n",
      "每列缺失率: Blumgart_T 7.54%\n",
      "每列缺失率: Bismuth_C 7.10%\n",
      "每列缺失率: PTCD_ERCP 5.76%\n",
      "每列缺失率: 手术日期 5.54%\n",
      "每列缺失率: surgery_bleeding 9.76%\n",
      "每列缺失率: surgery_CRCS 9.98%\n",
      "每列缺失率: surgery_plasm 10.42%\n",
      "每列缺失率: surgery_CP 26.83%\n",
      "每列缺失率: surgery_result 10.20%\n",
      "每列缺失率: gene_MSI 94.01%\n",
      "每列缺失率: TMB 98.45%\n",
      "每列缺失率: IHC_cdx2 78.71%\n",
      "每列缺失率: IHC_cea 86.70%\n",
      "每列缺失率: IHC_ck5 79.82%\n",
      "每列缺失率: IHC_ck7 76.27%\n",
      "每列缺失率: IHC_ck19 75.83%\n",
      "每列缺失率: IHC_ck20 78.27%\n",
      "每列缺失率: IHC_muc1 77.61%\n",
      "每列缺失率: IHC_moc31 88.25%\n",
      "每列缺失率: IHC_pd1 98.00%\n",
      "每列缺失率: IHC_pdl1 96.67%\n",
      "每列缺失率: target_survival_month 25.06%\n",
      "每列缺失率: target_3Y_death 25.06%\n"
     ]
    }
   ],
   "source": [
    "# 查看缺失率\n",
    "for i in df_dataset_cox_after.columns:\n",
    "    percent_col= df_dataset_cox_after[i].isnull().sum()/df_dataset_cox_after.shape[0]\n",
    "    percent_col=\"%.2f%%\" % (percent_col * 100)\n",
    "    print('每列缺失率:',i,percent_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(451, 75)"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset_cox_after.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除无效变量\n",
    "df_dataset_cox_after=df_dataset_cox_after.drop(['sampling','手术日期','AJCC_8'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除缺失超过20%的变量\n",
    "df_dataset_cox_after=df_dataset_cox_after.drop(['height','weight','BMI','blood_type','TBA','LG','AG','PAB',\n",
    "                                               'GT','ALP','tumor_CA125','TF','tumor_size','LC','surgery_CP','gene_MSI',\n",
    "                                               'TMB','IHC_cdx2','IHC_cea','IHC_ck5','IHC_ck7','IHC_ck19','IHC_ck20',\n",
    "                                               'IHC_muc1','IHC_moc31','IHC_pd1','IHC_pdl1'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breath_disease\n",
      "urinary_disease\n",
      "family_history\n"
     ]
    }
   ],
   "source": [
    "# 分类不平衡变量\n",
    "for i in df_dataset_cox_after.columns:\n",
    "    if df_dataset_cox_after[i].nunique() < 2:\n",
    "        print(i)\n",
    "        del df_dataset_cox_after[i]\n",
    "        continue\n",
    "    if df_dataset_cox_after[i].nunique() == 2:\n",
    "        # 如果分类变量中某一变量的占比超过90%，则删除该指标\n",
    "        num_1 = df_dataset_cox_after[i].value_counts()  # df一列中不同变量的数目\n",
    "        num_2 = num_1.div(df_dataset_cox_after.shape[0])  # div除法，所有元素都除以相同数值\n",
    "        num_3 = num_2.max()  # 取出最大值\n",
    "        if num_3 >= 0.9:\n",
    "            print(i)\n",
    "            del df_dataset_cox_after[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'age', 'jaundice', 'emaciation', 'cardio_disease', 'nbdd',\n",
       "       'endocrine_disease', 'biliary_disease', 'other_disease', 'smoke',\n",
       "       'drinking', 'WBC', 'HGB', 'PLT', 'TB', 'DB', 'TP', 'ALB', 'ALT', 'AST',\n",
       "       'tumor_AFP', 'tumor_CEA', 'tumor_CA19-9', 'HBsAg', 'HBeAg', 'HBeAb',\n",
       "       'HBcAb', 'HCVAb', 'T', 'N', 'M', 'Gazzaniga_T', 'MSKCC', 'Blumgart_T',\n",
       "       'Bismuth_C', 'PTCD_ERCP', 'surgery_bleeding', 'surgery_CRCS',\n",
       "       'surgery_plasm', 'surgery_result', 'target_survival_month',\n",
       "       'target_3Y_death'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset_cox_after.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全部数据集划分\n",
    "df_after_all_tran_cox, df_after_all_test_cox = train_test_split(df_dataset_cox_after, test_size=0.2, random_state=seed_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 剔除缺失值\n",
    "for i in df_dataset_cox_after.columns:\n",
    "    df_after_all_tran_cox = df_after_all_tran_cox[df_after_all_tran_cox[i].notnull()]\n",
    "    df_after_all_test_cox = df_after_all_test_cox[df_after_all_test_cox[i].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(451, 42)"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset_cox_after.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_after_all_tran_cox.to_excel(project_path+'/data/result/cox/df_1.7.2.6_after_all_tran_cox.xlsx')\n",
    "df_after_all_test_cox.to_excel(project_path+'/data/result/cox/df_1.7.2.6_after_all_test_cox.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R: ML + backward stepwise for postoperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n手术结果\\t0.419\\nAJCC_8分期\\t0.760\\n肿瘤指标CA19-9\\t0.001\\n肿瘤指标CEA\\t0.053\\n'"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "手术结果\t0.419\n",
    "AJCC_8分期\t0.760\n",
    "肿瘤指标CA19-9\t0.001\n",
    "肿瘤指标CEA\t0.053\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R: 模型筛选能力对比，c_index和BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n全部变量\\n全部变量+backward stepwise\\n机器学习变量\\n机器学习变量 + backward stepwise\\n'"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "全部变量\n",
    "全部变量+backward stepwise\n",
    "机器学习变量\n",
    "机器学习变量 + backward stepwise\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### python: 计算c_index和BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### 术后预后3年生存期\n",
    "\n",
    "# # 删除1年生存期的空值\n",
    "# df_dataset_cox_after_3Y=df_dataset_cox_after_importance[df_dataset_cox_after_importance.target_3Y_survival.notnull()]\n",
    "# # 删除无用变量\n",
    "# df_dataset_cox_after_3Y=df_dataset_cox_after_3Y.drop(['target_1Y_survival','target_1Y_death', 'target_5Y_death',\n",
    "#                                             'LC','target_5Y_survival', 'target_8Y_death', 'target_8Y_survival'],axis=1)\n",
    "\n",
    "# df_dataset_cox_after_3Y.shape\n",
    "\n",
    "# df_dataset_cox_after_3Y.columns\n",
    "\n",
    "# # 剔除缺失值\n",
    "# for i in df_dataset_cox_after_3Y.columns:\n",
    "#     df_dataset_cox_after_3Y = df_dataset_cox_after_3Y[df_dataset_cox_after_3Y[i].notnull()]\n",
    "\n",
    "# df_dataset_cox_after_3Y.sampling.value_counts()\n",
    "\n",
    "# df_dataset_cox_after_3Y.to_excel(project_path+'/data/result/cox/df_1.7.1_dataset_cox_after_3Y_ML.xlsx')\n",
    "\n",
    "# # 计算c_index of ML\n",
    "# from lifelines import CoxPHFitter\n",
    "# from lifelines.utils import concordance_index\n",
    "\n",
    "# cph = CoxPHFitter()\n",
    "# cph.fit(df_dataset_cox_after_3Y, duration_col='target_3Y_survival',event_col='target_3Y_death',cluster_col='sampling',show_progress=True)\n",
    "# c_index_3Y = cph.concordance_index_\n",
    "# print(c_index_3Y)\n",
    "\n",
    "# # 术后3年SPSS：backward再次筛选\n",
    "# col_backward_3Y=['surgery_result','AJCC_8','tumor_CA199','biliary_disease']\n",
    "# col_backward_3Y.insert(0,'sampling')\n",
    "# col_backward_3Y.extend(['target_3Y_death','target_3Y_survival'])\n",
    "# df_dataset_cox_after_3Y_backward=df_dataset_cox_after_3Y[col_backward_3Y]\n",
    "\n",
    "# # 计算c_index of ML+SPSS\n",
    "# from lifelines import CoxPHFitter\n",
    "# from lifelines.utils import concordance_index\n",
    "\n",
    "# cph = CoxPHFitter()\n",
    "# cph.fit(df_dataset_cox_after_3Y_backward, duration_col='target_3Y_survival',event_col='target_3Y_death',cluster_col='sampling',show_progress=True)\n",
    "# c_index_3Y_backward = cph.concordance_index_\n",
    "# print(c_index_3Y_backward)\n",
    "\n",
    "# # 计算3年生存期的BS\n",
    "# from sksurv.metrics import brier_score\n",
    "# from sksurv.datasets import load_gbsg2\n",
    "# from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "# from sksurv.metrics import brier_score\n",
    "# from sksurv.preprocessing import OneHotEncoder\n",
    "\n",
    "# #### 术后预后3年生存期\n",
    "\n",
    "# df_dataset_cox_after_3Y =pd.read_excel(project_path +'/data/result/cox/df_1.7.1_dataset_cox_after_3Y_ML.xlsx')\n",
    "# if 'Unnamed: 0' in df_dataset_cox_after_3Y.columns:\n",
    "#     df_dataset_cox_after_3Y = df_dataset_cox_after_3Y.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "# # 转换成boolean值\n",
    "# df_dataset_cox_after_3Y['target_death_binary']=df_dataset_cox_after_3Y.target_3Y_death.astype(bool)\n",
    "# # 构建BStrain_data和test_data\n",
    "# bs_y = [(d,s) for d,s in zip(df_dataset_cox_after_3Y.target_death_binary,df_dataset_cox_after_3Y.target_3Y_survival)]\n",
    "# bs_y=np.array(bs_y,dtype=[('cens', '?'), ('time', '<f8')])\n",
    "\n",
    "# df_dataset_cox_after_3Y.columns\n",
    "\n",
    "# # 术后3年BS_after_3Y\n",
    "# bs_x_after_3Y = df_dataset_cox_after_3Y.drop(['target_3Y_death','target_3Y_survival','sampling'],axis=1)\n",
    "# est_after_3Y = CoxPHSurvivalAnalysis(ties=\"efron\").fit(bs_x_after_3Y, bs_y)\n",
    "# survs_after_3Y = est_after_3Y.predict_survival_function(bs_x_after_3Y)\n",
    "# preds_after_3Y = [fn(10) for fn in survs_after_3Y]\n",
    "# times, bs_after_3Y = brier_score(bs_y, bs_y, preds_after_3Y, 10)\n",
    "# print(bs_after_3Y)\n",
    "\n",
    "# # 术后3年SPSS：backward再次筛选\n",
    "# bs_x_after_3Y_backward=bs_x_after_3Y[['surgery_result','AJCC_8','tumor_CA199','biliary_disease']]\n",
    "# est_after_3Y_backward=CoxPHSurvivalAnalysis(ties=\"efron\").fit(bs_x_after_3Y_backward, bs_y)\n",
    "# survs_after_3Y_backward = est_after_3Y_backward.predict_survival_function(bs_x_after_3Y_backward)\n",
    "# preds_after_3Y_backward = [fn(10) for fn in survs_after_3Y_backward]\n",
    "# times, bs_after_3Y_backward = brier_score(bs_y, bs_y, preds_after_3Y_backward, 10)\n",
    "# print(bs_after_3Y_backward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 术后风险评分模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPSS-cox回归分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nML+SPSS:backward筛选的变量计算风险评分：\\n1年生存期cox系数：\\n    surgery_result 0.734\\n    AJCC_8 0.879\\n    tumor_CA199 0.001\\n    smoke 0.607\\n    emaciation -0.756\\n3年生存期cox系数：\\n    surgery_result 0.486\\n    AJCC_8 0.561\\n    tumor_CA199 0.001\\n    biliary_disease 0.491\\n5年生存期cox系数\\n    surgery_result 0.574\\n    AJCC_8 0.486\\n    tumor_CA199 0.001\\n    biliary_disease 0.436\\n8年生存期cox系数\\n    surgery_result 0.606\\n    AJCC_8 0.482\\n    tumor_CA199 0.001\\n    biliary_disease 0.444\\n'"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ML+SPSS:backward筛选的变量计算风险评分：\n",
    "1年生存期cox系数：\n",
    "    surgery_result 0.734\n",
    "    AJCC_8 0.879\n",
    "    tumor_CA199 0.001\n",
    "    smoke 0.607\n",
    "    emaciation -0.756\n",
    "3年生存期cox系数：\n",
    "    surgery_result 0.486\n",
    "    AJCC_8 0.561\n",
    "    tumor_CA199 0.001\n",
    "    biliary_disease 0.491\n",
    "5年生存期cox系数\n",
    "    surgery_result 0.574\n",
    "    AJCC_8 0.486\n",
    "    tumor_CA199 0.001\n",
    "    biliary_disease 0.436\n",
    "8年生存期cox系数\n",
    "    surgery_result 0.606\n",
    "    AJCC_8 0.482\n",
    "    tumor_CA199 0.001\n",
    "    biliary_disease 0.444\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1年生存期cox-LR回归\n",
    "# col_cox_select_1Y=['surgery_result','AJCC_8','tumor_CA199','smoke','emaciation']\n",
    "# # 3年生存期cox-LR回归\n",
    "# col_cox_select_3Y=['surgery_result','AJCC_8','tumor_CA199','biliary_disease']\n",
    "# # 5年生存期cox-LR回归\n",
    "# col_cox_select_5Y=['surgery_result','AJCC_8','tumor_CA199','biliary_disease']\n",
    "# # 8年生存期cox-LR回归\n",
    "# col_cox_select_8Y=['surgery_result','AJCC_8','tumor_CA199','biliary_disease']\n",
    "# # 合并风险模型变量\n",
    "# col_cox_select=list(set(col_cox_select_1Y + col_cox_select_3Y + col_cox_select_5Y + col_cox_select_8Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['surgery_result',\n",
       " 'tumor_CA19-9',\n",
       " 'tumor_CEA',\n",
       " 'surgery_plasm',\n",
       " 'biliary_disease',\n",
       " 'PLT',\n",
       " 'AJCC_8',\n",
       " 'emaciation',\n",
       " 'smoke']"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_cox_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute risk-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_risk_after =pd.read_excel(project_path +'/data/processed_data/df_3.1.1_术后预后cox数据集.xlsx',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(451, 75)"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_risk_after.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# 计算风险评分\n",
    "df_model_risk_after=df_model_risk_after.reset_index(drop=True)\n",
    "# 缺失项补充为0\n",
    "col_cox_select=['tumor_CA19-9','tumor_CEA','DB','N','M','MSKCC']\n",
    "df_model_risk_after[col_cox_select]=df_model_risk_after[col_cox_select].fillna(0)\n",
    "for i in range(df_model_risk_after.shape[0]):\n",
    "    ca199=float(df_model_risk_after.loc[i,'tumor_CA19-9'])\n",
    "    cea=float(df_model_risk_after.loc[i,'tumor_CEA'])\n",
    "    db=float(df_model_risk_after.loc[i,'DB'])\n",
    "    n=float(df_model_risk_after.loc[i,'N'])\n",
    "    m=float(df_model_risk_after.loc[i,'M'])\n",
    "    mskcc=float(df_model_risk_after.loc[i,'MSKCC'])\n",
    "\n",
    "#     # 术后1年生存期risk_score计算\n",
    "#     df_model_risk_after.loc[i,'risk_score_1Y']=0.734*surgery_result+0.001*ca199+0.879*ajcc+0.607*smoke-0.756*emaciation\n",
    "#     # 术后3年生存期risk_score计算\n",
    "    df_model_risk_after.loc[i,'risk_score_3Y']=0.001*ca199+0.002*db+0.028*cea+0.492*n+0.505*mskcc+1.19*m\n",
    "#     # 术后8年生存期risk_score计算\n",
    "#     df_model_risk_after.loc[i,'risk_score_8Y']=0.606*surgery_result+0.001*ca199+0.482*ajcc+0.444*biliary\n",
    "#     # 现有方法3年生存期risk_score计算\n",
    "#     if plt_value <=0:\n",
    "#         df_model_risk_after.loc[i,'risk_score_existing']=ajcc*0.58+0.59*surgery_result+0.0004*surgery_plasm\n",
    "#     else:\n",
    "#         df_model_risk_after.loc[i,'risk_score_existing']=math.log(plt_value)*0.002+ajcc*0.58+0.59*surgery_result+\\\n",
    "#                                                     0.0004*surgery_plasm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(451, 76)"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_risk_after.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    451.000000\n",
       "mean       1.839347\n",
       "std        1.129807\n",
       "min        0.000000\n",
       "25%        1.030000\n",
       "50%        1.622000\n",
       "75%        2.340400\n",
       "max       11.474200\n",
       "Name: risk_score_3Y, dtype: float64"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_risk_after.risk_score_3Y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_risk_after.to_excel(project_path+'/data/result/cox/df_1.8.2_risk_score_after.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 术后分期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nR语言：风险评分分布直方图\\n根据风险评分分布直方图和中位数、四分卫点划分病理分期\\n'"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "R语言：风险评分分布直方图\n",
    "根据风险评分分布直方图和中位数、四分卫点划分病理分期\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 术后3年生存期风险评分分期\n",
    "df_model_risk_after['staging_after_3Y']=df_model_risk_after.risk_score_3Y.apply(lambda x: 1 if x<=1 else\n",
    "                                                                         2 if 1<x<=1.5 else\n",
    "                                                                         3 if 1.5<x<=2 else\n",
    "                                                                         4 if 2<x<=2.5 else\n",
    "                                                                         5 if x>2.5 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    105\n",
       "5     99\n",
       "2     95\n",
       "3     87\n",
       "4     65\n",
       "Name: staging_after_3Y, dtype: int64"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_risk_after.staging_after_3Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_risk_after.to_excel(project_path+'/data/result/cox/df_1.8.3_术后分期.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(451, 77)"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_risk_after.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 划分训练集和测试集，比例为8:2\n",
    "\n",
    "df_after_staging_tran, df_after_staging_test = train_test_split(df_model_risk_after, test_size=0.2, random_state=seed_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 77)\n",
      "(91, 77)\n"
     ]
    }
   ],
   "source": [
    "print(df_after_staging_tran.shape)\n",
    "print(df_after_staging_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_after_staging_tran.to_excel(project_path+'/data/result/cox/df_1.8.3_术后分期_训练集.xlsx')\n",
    "df_after_staging_test.to_excel(project_path+'/data/result/cox/df_1.8.3_术后分期_测试集.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R语言: 风险评分直方画图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R语言：术后分期生存分析图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R语言：术后分期比较"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### python比较术后分期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'sampling', 'gender', 'age', 'height', 'weight', 'BMI',\n",
       "       'jaundice', 'emaciation', 'breath_disease', 'cardio_disease', 'nbdd',\n",
       "       'urinary_disease', 'endocrine_disease', 'biliary_disease',\n",
       "       'other_disease', 'smoke', 'drinking', 'family_history', 'blood_type',\n",
       "       'WBC', 'HGB', 'PLT', 'TB', 'DB', 'TP', 'ALB', 'LG', 'AG', 'PAB', 'ALT',\n",
       "       'AST', 'GT', 'ALP', 'tumor_AFP', 'tumor_CEA', 'tumor_CA19-9',\n",
       "       'tumor_CA125', 'TF', 'tumor_size', 'HBsAg', 'HBeAg', 'HBeAb', 'HBcAb',\n",
       "       'HCVAb', 'LC', 'AJCC_8', 'Gazzaniga_T', 'MSKCC', 'Blumgart_T',\n",
       "       'Bismuth_C', 'PTCD_ERCP', '手术日期', 'surgery_bleeding', 'surgery_CRCS',\n",
       "       'surgery_plasm', 'surgery_CP', 'surgery_result', 'gene_mutation',\n",
       "       'gene_MSI', 'TMB', 'IHC_cdx2', 'IHC_cea', 'IHC_ck5', 'IHC_ck7',\n",
       "       'IHC_ck19', 'IHC_ck20', 'IHC_muc1', 'IHC_moc31', 'IHC_pd1', 'IHC_pdl1',\n",
       "       'target_death', 'target_survival_month', 'target_1Y_death',\n",
       "       'target_3Y_death', 'risk_score_3Y', 'risk_score_existing',\n",
       "       'staging_after_3Y', 'staging_after_existing'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_risk_after.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lifelines import CoxPHFitter\n",
    "# from lifelines.utils import concordance_index\n",
    "# # 计算1年生存期分期的c_index_us\n",
    "# df_C_index_us = df_model_risk_after[['staging_after_1Y','target_1Y_death','target_1Y_survival']]\n",
    "# df_C_index_us = df_C_index_us[df_C_index_us.target_1Y_survival.notnull()]\n",
    "# cph = CoxPHFitter()\n",
    "# cph.fit(df_C_index_us, duration_col='target_1Y_survival', event_col='target_1Y_death', show_progress=True)\n",
    "# C_index_us_1Y = cph.concordance_index_\n",
    "# print(C_index_us_1Y)\n",
    "\n",
    "# # 计算3年生存期分期的c_index_us\n",
    "# df_C_index_us = df_model_risk_after[['staging_after_3Y','target_3Y_death','target_3Y_survival']]\n",
    "# df_C_index_us = df_C_index_us[df_C_index_us.target_3Y_survival.notnull()]\n",
    "# cph = CoxPHFitter()\n",
    "# cph.fit(df_C_index_us, duration_col='target_3Y_survival', event_col='target_3Y_death', show_progress=True)\n",
    "# C_index_us_3Y = cph.concordance_index_\n",
    "# print(C_index_us_3Y)\n",
    "\n",
    "# # 计算5年生存期分期的c_index_us\n",
    "# df_C_index_us = df_model_risk_after[['staging_after_5Y','target_5Y_death','target_5Y_survival']]\n",
    "# df_C_index_us = df_C_index_us[df_C_index_us.target_5Y_survival.notnull()]\n",
    "# cph = CoxPHFitter()\n",
    "# cph.fit(df_C_index_us, duration_col='target_5Y_survival', event_col='target_5Y_death', show_progress=True)\n",
    "# C_index_us_5Y = cph.concordance_index_\n",
    "# print(C_index_us_5Y)\n",
    "\n",
    "# # 计算8年生存期分期的c_index_us\n",
    "# df_C_index_us = df_model_risk_after[['staging_after_8Y','target_8Y_death','target_8Y_survival']]\n",
    "# df_C_index_us = df_C_index_us[df_C_index_us.target_8Y_survival.notnull()]\n",
    "# cph = CoxPHFitter()\n",
    "# cph.fit(df_C_index_us, duration_col='target_8Y_survival', event_col='target_8Y_death', show_progress=True)\n",
    "# C_index_us_8Y = cph.concordance_index_\n",
    "# print(C_index_us_8Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### python: sksurv计算BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sksurv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-525-10ccf9004a4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msksurv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbrier_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msksurv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_gbsg2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msksurv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCoxPHSurvivalAnalysis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msksurv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbrier_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msksurv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sksurv'"
     ]
    }
   ],
   "source": [
    "from sksurv.metrics import brier_score\n",
    "from sksurv.datasets import load_gbsg2\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.metrics import brier_score\n",
    "from sksurv.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_bs=pd.read_excel(project_path+'/data/result/modeling/df_1.7.2_术后分期.xlsx')\n",
    "if 'Unnamed: 0' in df_model_bs.columns:\n",
    "    df_model_bs = df_model_bs.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_bs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_bs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除分期缺失值\n",
    "col_bs_select=['staging_after_1Y','staging_after_3Y','staging_after_5Y','staging_after_8Y','AJCC_8','Gazzaniga_T','MSKCC','Blumgart_T']\n",
    "for i in col_bs_select:\n",
    "    df_model_bs=df_model_bs[df_model_bs[i].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_bs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_bs[col_bs_select].isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3Y--BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 术后预后3年生存期BS，生成布尔型True、False\n",
    "df_model_bs_3Y=df_model_bs[df_model_bs.target_3Y_survival.notnull()]\n",
    "df_model_bs_3Y['target_death_binary']=df_model_bs_3Y.target_3Y_death.astype(bool)\n",
    "# 构建BStrain_data和test_data\n",
    "bs_y = [(d,s) for d,s in zip(df_model_bs_3Y.target_death_binary,df_model_bs_3Y.target_3Y_survival)]\n",
    "bs_y=np.array(bs_y,dtype=[('cens', '?'), ('time', '<f8')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 术后3年BS_us\n",
    "bs_x_us = df_model_bs_3Y[['staging_after_3Y']]\n",
    "est_us = CoxPHSurvivalAnalysis(ties=\"efron\").fit(bs_x_us, bs_y)\n",
    "survs_us = est_us.predict_survival_function(bs_x_us)\n",
    "preds_us = [fn(10) for fn in survs_us]\n",
    "times, bs_3Y_us = brier_score(bs_y, bs_y, preds_us, 10)\n",
    "print(bs_3Y_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 术后3年BS_ajcc\n",
    "bs_x_ajcc=df_model_bs_3Y[['AJCC_8']]\n",
    "est_ajcc = CoxPHSurvivalAnalysis(ties=\"efron\").fit(bs_x_ajcc, bs_y)\n",
    "survs_ajcc = est_ajcc.predict_survival_function(bs_x_ajcc)\n",
    "preds_ajcc = [fn(10) for fn in survs_ajcc]\n",
    "times, bs_3Y_ajcc = brier_score(bs_y, bs_y, preds_ajcc, 10)\n",
    "print(bs_3Y_ajcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 术后3年BS_gazz\n",
    "bs_x_gazz=df_model_bs_3Y[['Gazzaniga_T']]\n",
    "est_gazz = CoxPHSurvivalAnalysis(ties=\"efron\").fit(bs_x_gazz, bs_y)\n",
    "survs_gazz = est_gazz.predict_survival_function(bs_x_gazz)\n",
    "preds_gazz = [fn(10) for fn in survs_gazz]\n",
    "times, bs_3Y_gazz = brier_score(bs_y, bs_y, preds_gazz, 10)\n",
    "print(bs_3Y_gazz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 术后3年BS_mskcc\n",
    "bs_x_mskcc=df_model_bs_3Y[['MSKCC']]\n",
    "est_mskcc = CoxPHSurvivalAnalysis(ties=\"efron\").fit(bs_x_mskcc, bs_y)\n",
    "survs_mskcc = est_mskcc.predict_survival_function(bs_x_mskcc)\n",
    "preds_mskcc = [fn(10) for fn in survs_mskcc]\n",
    "times, bs_3Y_mskcc = brier_score(bs_y, bs_y, preds_mskcc, 10)\n",
    "print(bs_3Y_mskcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 术后3年BS_blumgart\n",
    "bs_x_blumgart=df_model_bs_3Y[['Blumgart_T']]\n",
    "est_blumgart = CoxPHSurvivalAnalysis(ties=\"efron\").fit(bs_x_blumgart, bs_y)\n",
    "survs_blumgart = est_blumgart.predict_survival_function(bs_x_blumgart)\n",
    "preds_blumgart = [fn(10) for fn in survs_blumgart]\n",
    "times, bs_3Y_blumgart = brier_score(bs_y, bs_y, preds_blumgart, 10)\n",
    "print(bs_3Y_blumgart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多分类模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 未插补模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,average_precision_score,precision_recall_curve\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,roc_auc_score,accuracy_score\n",
    "\n",
    "import xgboost\n",
    "# XGBoost模型\n",
    "xgb_model=xgboost.XGBClassifier(max_depth=5,\n",
    "                        learning_rate=0.018,\n",
    "                        n_estimators=500,\n",
    "                        min_child_weight=0.6,\n",
    "                        eta=0.1,\n",
    "                        gamma=0.5,\n",
    "                        reg_lambda=5,\n",
    "                        subsample=0.8,\n",
    "                        colsample_bytree=0.6,\n",
    "                        nthread=4,\n",
    "                        scale_pos_weight=1,\n",
    "                        random_state=3)\n",
    "\n",
    "xgb_model.fit(tran_x_sm,tran_y_sm)\n",
    "xgb_predictions=xgb_model.predict(test_x)\n",
    "\n",
    "\n",
    "import lightgbm\n",
    "# LightGBM模型\n",
    "lgbm_model=lightgbm.LGBMClassifier(iterations=300, \n",
    "                                  max_depth=8,\n",
    "                                  min_child_weight=0.9,\n",
    "                                  gamma=0.5,\n",
    "                                   reg_lambda=5,\n",
    "                                  subsample=0.4,\n",
    "                                  learning_rate=0.2, \n",
    "                                  loss_function='CrossEntropy',\n",
    "                                  random_state=3)\n",
    "lgbm_model.fit(tran_x_sm,tran_y_sm)\n",
    "lgbm_predictions=lgbm_model.predict(test_x)\n",
    "\n",
    "\n",
    "import catboost\n",
    "# CatBoost模型\n",
    "cat_model=catboost.CatBoostClassifier(iterations=300, \n",
    "                                      learning_rate=0.2, \n",
    "                                      depth=6,\n",
    "                                      l2_leaf_reg=2,\n",
    "                                      loss_function='MultiClass',\n",
    "                                      random_state=3)\n",
    "cat_model.fit(tran_x_sm,tran_y_sm)\n",
    "cat_predictions=cat_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "# 统一模型输出结果\n",
    "df_model_result=pd.DataFrame(\n",
    "    columns=['model','index','precision','recall','f1-score','support','accuracy','AUC','sensitivity','specificity'])\n",
    "\n",
    "model_list=[xgb_model,lgbm_model,cat_model]\n",
    "model_name_list=['XGBoost','LGBM','CatBoost']\n",
    "for model,name in zip(model_list,model_name_list):\n",
    "#     print(name)\n",
    "    # 计算accuracy和AUC\n",
    "    if name == 'TabNet':\n",
    "        test_x=test_x.to_numpy()\n",
    "    test_y_score=model.predict_proba(test_x)\n",
    "    auc=roc_auc_score(test_y,test_y_score,average='micro',multi_class='ovr')\n",
    "    auc=round(auc,4)\n",
    "    accuracy=accuracy_score(test_y,model.predict(test_x))\n",
    "    accuracy=round(accuracy,4)\n",
    "    # 计算灵敏度sensitivity和特异度specificity\n",
    "    # 计算灵敏度、特异度\n",
    "#     tn, fp, fn, tp = confusion_matrix(test_y,model.predict(test_x),multi_class='ovr').rival()\n",
    "#     sensitivity=round(tp/(tp+fn),4)\n",
    "#     specificity=round(tn/(fp+tn),4)\n",
    "    df_model_result.loc[df_model_result.shape[0],['model','accuracy','AUC']]=\\\n",
    "                                                              [name,accuracy,auc]\n",
    "    # 并入二分类的P-R-f1\n",
    "    # 提取classification_report结果\n",
    "    report = classification_report(test_y, model.predict(test_x), output_dict=True)  # output_dict转化为字典类型\n",
    "    df_report = pd.DataFrame(report).transpose()  # 转置\n",
    "    df_report=df_report.apply(lambda x: round(x,4),axis=0)\n",
    "    df_report=df_report.reset_index(drop=True)\n",
    "    df_model_result=pd.concat([df_model_result,df_report.loc[0:5,:].reset_index()],axis=0)\n",
    "    df_model_result=df_model_result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_result.rename(columns={'model':'',\n",
    "                               'index':'label'},inplace=True)\n",
    "# 保存模型测试效果\n",
    "df_model_result.to_excel(project_path+'/data/df_分类_模型测试效果_未插补.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 插补模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import r2_score,average_precision_score,precision_recall_curve\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,roc_auc_score,accuracy_score\n",
    "\n",
    "import xgboost\n",
    "# XGBoost模型\n",
    "xgb_model=xgboost.XGBClassifier(max_depth=5,\n",
    "                        learning_rate=0.018,\n",
    "                        n_estimators=500,\n",
    "                        min_child_weight=0.6,\n",
    "                        eta=0.1,\n",
    "                        gamma=0.5,\n",
    "                        reg_lambda=5,\n",
    "                        subsample=0.8,\n",
    "                        colsample_bytree=0.6,\n",
    "                        nthread=4,\n",
    "                        scale_pos_weight=1,\n",
    "                        random_state=3)\n",
    "\n",
    "xgb_model.fit(tran_x_sm,tran_y_sm)\n",
    "xgb_predictions=xgb_model.predict(test_x)\n",
    "\n",
    "\n",
    "import lightgbm\n",
    "# LightGBM模型\n",
    "lgbm_model=lightgbm.LGBMClassifier(iterations=300, \n",
    "                                  max_depth=8,\n",
    "                                  min_child_weight=0.9,\n",
    "                                  gamma=0.5,\n",
    "                                   reg_lambda=5,\n",
    "                                  subsample=0.4,\n",
    "                                  learning_rate=0.2, \n",
    "                                  loss_function='CrossEntropy',\n",
    "                                  random_state=3)\n",
    "lgbm_model.fit(tran_x_sm,tran_y_sm)\n",
    "lgbm_predictions=lgbm_model.predict(test_x)\n",
    "\n",
    "\n",
    "import catboost\n",
    "# CatBoost模型\n",
    "cat_model=catboost.CatBoostClassifier(iterations=300, \n",
    "                                      learning_rate=0.2, \n",
    "                                      depth=6,\n",
    "                                      l2_leaf_reg=2,\n",
    "                                      loss_function='MultiClass',\n",
    "                                      random_state=3)\n",
    "cat_model.fit(tran_x_sm,tran_y_sm)\n",
    "cat_predictions=cat_model.predict(test_x)\n",
    "\n",
    "\n",
    "# 随机森林\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# 列出参数列表\n",
    "tree_grid_parameter = {'n_estimators': list((10, 50, 100, 150, 200))}\n",
    "# 进行参数的搜索组合\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid=tree_grid_parameter, cv=3)\n",
    "# 根据已有数据去拟合随机森林模型\n",
    "grid.fit(tran_x_sm, tran_y_sm)\n",
    "rf_model = RandomForestClassifier(n_estimators=grid.best_params_['n_estimators'],\n",
    "                            max_depth=8,\n",
    "                            random_state=3)\n",
    "rf_model.fit(tran_x_sm, tran_y_sm)\n",
    "# 预测缺失值\n",
    "rf_predictions = rf_model.predict(test_x)\n",
    "\n",
    "\n",
    "# GBDT\n",
    "# 列出参数列表\n",
    "gbdt_model = GradientBoostingClassifier(n_estimators=300,\n",
    "                            learning_rate=0.1,\n",
    "                            max_depth=8,\n",
    "                            subsample=0.4,\n",
    "                            random_state=3)\n",
    "gbdt_model.fit(tran_x_sm,tran_y_sm)\n",
    "# 预测缺失值\n",
    "gbdt_predictions = gbdt_model.predict(test_x)\n",
    "\n",
    "\n",
    "# SVR\n",
    "from sklearn.svm import SVR,SVC\n",
    "# 回归模型\n",
    "# svr = SVR(kernel='linear', C=1.25)\n",
    "# 分类模型\n",
    "svr_model = SVC(kernel='rbf',\n",
    "          C=50,\n",
    "          cache_size=200,\n",
    "            probability=True,\n",
    "          random_state=3)\n",
    "svr_model.fit(tran_x_sm,tran_y_sm)\n",
    "svr_predictions=svr_model.predict(test_x)\n",
    "\n",
    "\n",
    "# Linear回归，Lasso回归，领回归，logistic回归\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge,ElasticNet,LogisticRegression\n",
    "lcv_model = LogisticRegression(penalty='l2',\n",
    "                         C=5,\n",
    "                        solver='lbfgs',\n",
    "                         max_iter=100,\n",
    "                        random_state=3)\n",
    "# lcv = Lasso()\n",
    "# lcv = Ridge()\n",
    "lcv_model.fit(tran_x_sm, tran_y_sm)\n",
    "lcv_predictions = lcv_model.predict(test_x)\n",
    "\n",
    "# ANN\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "ANN_model = MLPClassifier(alpha=0.1, \n",
    "                    hidden_layer_sizes=[100,], \n",
    "                    solver='adam', \n",
    "                    activation='relu', \n",
    "                    random_state=3)\n",
    "ANN_model.fit(tran_x_sm, tran_y_sm)\n",
    "ANN_predictions=ANN_model.predict(test_x)\n",
    "\n",
    "\n",
    "# TabNet\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "from pytorch_tabnet.multitask import TabNetMultiTaskClassifier\n",
    "TabNet_model = TabNetMultiTaskClassifier(n_d=8, \n",
    "                               n_a=8,\n",
    "                               n_steps=3, # Number of steps in the architecture (usually between 3 and 10)\n",
    "                               gamma=1.5,\n",
    "                               n_independent=2)  #TabNetRegressor()\n",
    "tran_x_x, tran_x_valid, tran_y_y, tran_y_valid = train_test_split(tran_x_sm, tran_y_sm, test_size=0.125, random_state=3)\n",
    "\n",
    "TabNet_model.fit(X_train=tran_x_x.to_numpy(), \n",
    "        y_train=tran_y_y.to_numpy().reshape(-1,1),\n",
    "        max_epochs=200, \n",
    "        patience=20,\n",
    "        batch_size=1024, \n",
    "        virtual_batch_size=128,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        loss_fn=[torch.nn.functional.cross_entropy]) # Optional, just an example of list usage\n",
    "\n",
    "TabNet_predictions=TabNet_model.predict(test_x.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统一模型输出结果\n",
    "df_model_result=pd.DataFrame(\n",
    "    columns=['model','index','precision','recall','f1-score','support','accuracy','AUC','sensitivity','specificity'])\n",
    "\n",
    "model_list=[xgb_model,lgbm_model,cat_model,rf_model,gbdt_model,svr_model,lcv_model,ANN_model,TabNet_model]\n",
    "model_name_list=['XGBoost','LGBM','CatBoost','RF','GBDT','SVR','LR','ANN','TabNet']\n",
    "for model,name in zip(model_list,model_name_list):\n",
    "#     print(name)\n",
    "    if name == 'TabNet':\n",
    "        test_x=test_x.to_numpy()\n",
    "    test_y_score=model.predict_proba(test_x)\n",
    "    auc=roc_auc_score(test_y,test_y_score,multi_class='ovr')\n",
    "    auc=round(auc,4)\n",
    "    accuracy=accuracy_score(test_y,model.predict(test_x))\n",
    "    accuracy=round(accuracy,4)\n",
    "    # 计算precision、recall、F1\n",
    "    precision=precision_score(test_y,model.predict(test_x),average='macro')\n",
    "    recall=recall_score(test_y,model.predict(test_x),average='macro')\n",
    "    f1=f1_score(test_y,model.predict(test_x),average='macro')\n",
    "    # 计算accuracy和AUC\n",
    "#     if name == 'TabNet':\n",
    "#         test_x=test_x.to_numpy()\n",
    "#     y_one_hot = label_binarize(test_y, np.arange(6))\n",
    "#     test_y_score=model.predict_proba(test_x)\n",
    "#     auc=roc_auc_score(y_one_hot,test_y_score,average='micro')\n",
    "#     auc=round(auc,4)\n",
    "\n",
    "#     accuracy=accuracy_score(test_y,model.predict(test_x),average='macro')\n",
    "#     accuracy=round(accuracy,2)\n",
    "#     # 计算灵敏度sensitivity和特异度specificity\n",
    "#     # 计算灵敏度、特异度、假阴性率、假阳性率\n",
    "#     tn, fp, fn, tp = confusion_matrix(test_y,model.predict(test_x)).ravel()\n",
    "#     sensitivity=round(tp/(tp+fn),2)\n",
    "#     specificity=round(tn/(fp+tn),2)\n",
    "#     FPR=round(fp/(fp+tn),2)\n",
    "#     FNR=round(fn/(fn+tp),2)\n",
    "#     # 计算约登指数\n",
    "#     youden_index=sensitivity+specificity-1\n",
    "    df_model_result.loc[df_model_result.shape[0],['model','accuracy','AUC',]]=\\\n",
    "                                            [name,accuracy,auc]\n",
    "    # 并入二分类的P-R-f1\n",
    "    # 提取classification_report结果\n",
    "    report = classification_report(test_y, model.predict(test_x), output_dict=True)  # output_dict转化为字典类型\n",
    "    df_report = pd.DataFrame(report).transpose()  # 转置\n",
    "    df_report=df_report.apply(lambda x: round(x,2),axis=0)\n",
    "    df_report=df_report.reset_index(drop=True)\n",
    "    df_model_result=pd.concat([df_model_result,df_report.loc[0:1,:].reset_index()],axis=0)\n",
    "    df_model_result=df_model_result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_result.rename(columns={'model':'',\n",
    "                               'index':'label'},inplace=True)\n",
    "# 保存模型测试效果\n",
    "df_model_result.to_excel(project_path+'/data/df_分类_模型测试效果_插补.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  4,  4,  2],\n",
       "       [ 0, 18,  4,  0],\n",
       "       [ 5,  5, 13,  4],\n",
       "       [ 0,  1,  5, 11]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y, xgb_model.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接使用xgboost和catboost包，而不是auto_ml\n",
    "from sklearn.metrics import r2_score,precision_score,recall_score,f1_score,auc,accuracy_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix,average_precision_score,roc_curve,precision_recall_curve\n",
    "\n",
    "import xgboost\n",
    "# XGBoost模型\n",
    "xgb_model=xgboost.XGBClassifier(max_depth=3,\n",
    "                        learning_rate=0.009,\n",
    "                        n_estimators=500,\n",
    "                        min_child_weight=0.4,\n",
    "                        eta=0.1,\n",
    "                        gamma=0.4,\n",
    "                        reg_lambda=10,\n",
    "                        subsample=0.8,\n",
    "                        colsample_bytree=0.8,\n",
    "                        nthread=4,\n",
    "                        scale_pos_weight=1,\n",
    "                        random_state=3)\n",
    "xgb_model.fit(tran_x_sm,tran_y_sm)\n",
    "xgb_predictions=xgb_model.predict(test_x)\n",
    "\n",
    "xgb_precision = precision_score(test_y,xgb_predictions,average='macro')\n",
    "xgb_recall=recall_score(test_y,xgb_predictions,average='macro')\n",
    "xgb_f1=f1_score(test_y,xgb_predictions,average='macro')\n",
    "\n",
    "# test_y_score=model.predict_proba(test_x)[:-1]\n",
    "# xgb_auc=roc_auc_score(test_y,test_y_score,multi_class='ovr')\n",
    "# xgb_auc=round(xgb_auc,2)\n",
    "\n",
    "xgb_accuracy=accuracy_score(test_y,xgb_predictions)\n",
    "print(xgb_precision,xgb_recall,xgb_f1,xgb_auc,xgb_accuracy)\n",
    "\n",
    "# xgb_fpr, xgb_tpr, thresholds = roc_curve(test_y, test_y_score, pos_label=1)  #pos_label=2，表示值为2的实际值为正样本\n",
    "# xgb_auc=auc(xgb_fpr,xgb_tpr)\n",
    "\n",
    "cm2_LogR_model = confusion_matrix(test_y, xgb_model.predict(test_x))\n",
    "print(cm2_LogR_model) #混肴矩阵\n",
    "print(classification_report(test_y, xgb_model.predict(test_x)))\n",
    "\n",
    "# # 计算灵敏度、特异度\n",
    "# xgb_tn, xgb_fp, xgb_fn, xgb_tp = confusion_matrix(test_y,xgb_model.predict(test_x)).ravel()\n",
    "# xgb_sensitivity=round(xgb_tp/(xgb_tp+xgb_fn),3)\n",
    "# xgb_specificity=round(xgb_tn/(xgb_fp+xgb_tn),3)\n",
    "# print(xgb_tn, xgb_fp, xgb_fn, xgb_tp)\n",
    "# print(xgb_sensitivity,xgb_specificity)\n",
    "# 提取classification_report结果\n",
    "# 令output_dict转化为字典类型\n",
    "report = classification_report(test_y, xgb_model.predict(test_x), output_dict=True)\n",
    "df_report = pd.DataFrame(report).transpose()  # 转置\n",
    "df_report = df_report.reset_index(drop=True)\n",
    "print(df_report)\n",
    "# xgb_ap = average_precision_score(test_y, predictions)\n",
    "# xgb_precision, xgb_recall, _ = precision_recall_curve(test_y, predictions)\n",
    "# # print(predictions)\n",
    "# print(classification_report(test_y, xgb_model.predict(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_result=pd.DataFrame(columns=['model','index','precision','recall','f1-score','support','accuracy','AUC','sensitivity','specificity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_result.loc[df_model_result.shape[0],['model','accuracy','AUC','sensitivity','specificity']]=\\\n",
    "                                                                    ['xgb',xgb_accuracy,xgb_auc,xgb_sensitivity,xgb_specificity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_result=pd.concat([df_model_result,df_report.loc[0:1,:].reset_index()],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_result.rename(columns={'model':'',\n",
    "                               'index':''},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?lgbm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "# LightGBM模型\n",
    "lgbm_model=lightgbm.LGBMClassifier(iterations=300, \n",
    "                                  max_depth=8,\n",
    "                                  min_child_weight=0.9,\n",
    "                                  gamma=0.5,\n",
    "                                   reg_lambda=5,\n",
    "                                  subsample=0.4,\n",
    "                                  learning_rate=0.2, \n",
    "                                  loss_function='CrossEntropy',\n",
    "                                  random_state=3)\n",
    "lgbm_model.fit(tran_x_sm,tran_y_sm)\n",
    "lgbm_predictions=lgbm_model.predict(test_x)\n",
    "\n",
    "lgbm_precision = precision_score(test_y,lgbm_predictions)\n",
    "lgbm_recall=recall_score(test_y,lgbm_predictions)\n",
    "lgbm_f1=f1_score(test_y,lgbm_predictions)\n",
    "\n",
    "test_y_score=lgbm_model.predict_proba(test_x)[:,-1]\n",
    "lgbm_auc=roc_auc_score(test_y,test_y_score)\n",
    "lgbm_accuracy=accuracy_score(test_y,lgbm_predictions)\n",
    "print('lgbm',lgbm_precision,lgbm_recall,lgbm_f1,lgbm_auc,lgbm_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?catboost.CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "# CatBoost模型\n",
    "cat_model=catboost.CatBoostClassifier(iterations=300, \n",
    "                                      learning_rate=0.2, \n",
    "                                      depth=6,\n",
    "                                      l2_leaf_reg=2,\n",
    "                                      subsample=1,\n",
    "                                      loss_function='CrossEntropy',\n",
    "                                      random_state=3)\n",
    "\n",
    "cat_model.fit(tran_x_sm,tran_y_sm)\n",
    "cat_predictions=cat_model.predict(test_x)\n",
    "\n",
    "cat_precision = precision_score(test_y,cat_predictions)\n",
    "cat_recall=recall_score(test_y,cat_predictions)\n",
    "cat_f1=f1_score(test_y,cat_predictions)\n",
    "\n",
    "test_y_score=cat_model.predict_proba(test_x)[:,-1]\n",
    "cat_auc=roc_auc_score(test_y,test_y_score)\n",
    "cat_accuracy=accuracy_score(test_y,cat_predictions)\n",
    "print('catboost',cat_precision,cat_recall,cat_f1,cat_auc,cat_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('catboost',cat_precision,cat_recall,cat_f1,cat_auc,cat_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机森林，GBDT\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# 列出参数列表\n",
    "tree_grid_parameter = {'n_estimators': list((10, 50, 100, 150, 200))}\n",
    "# 进行参数的搜索组合\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid=tree_grid_parameter, cv=3)\n",
    "# 根据已有数据去拟合随机森林模型\n",
    "grid.fit(tran_x_sm, tran_y_sm)\n",
    "rf_model = RandomForestClassifier(n_estimators=grid.best_params_['n_estimators'],\n",
    "                            max_depth=8,\n",
    "                            random_state=3)\n",
    "rf_model.fit(tran_x_sm, tran_y_sm)\n",
    "\n",
    "\n",
    "# 预测缺失值\n",
    "rf_predictions = rf_model.predict(test_x)\n",
    "\n",
    "rf_precision = precision_score(test_y,rf_predictions)\n",
    "rf_recall=recall_score(test_y,rf_predictions)\n",
    "rf_f1=f1_score(test_y,rf_predictions)\n",
    "\n",
    "test_y_score=rf_model.predict_proba(test_x)[:,-1]\n",
    "rf_auc=roc_auc_score(test_y,test_y_score)\n",
    "rf_accuracy=accuracy_score(test_y,rf_predictions)\n",
    "print('rf',rf_precision,rf_recall,rf_f1,rf_auc,rf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBDT\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# 列出参数列表\n",
    "tree_grid_parameter = {'n_estimators': [200,300,500],\n",
    "                      'learning_rate': [0.01,0.1],\n",
    "                      'max_depth': [3,5],\n",
    "                      'subsample':[0.5,0.6,0.8]}\n",
    "# 进行参数的搜索组合\n",
    "grid = GridSearchCV(GradientBoostingClassifier(), param_grid=tree_grid_parameter, cv=3)\n",
    "# 根据已有数据去拟合随机森林模型\n",
    "grid.fit(tran_x_sm, tran_y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt_model = GradientBoostingClassifier(n_estimators=300,\n",
    "                            learning_rate=0.1,\n",
    "                            max_depth=8,\n",
    "                            subsample=0.4,\n",
    "                            random_state=3)\n",
    "gbdt_model.fit(tran_x_sm, tran_y_sm)\n",
    "# 预测缺失值\n",
    "gbdt_predictions = gbdt_model.predict(test_x)\n",
    "\n",
    "gbdt_precision = precision_score(test_y,gbdt_predictions)\n",
    "gbdt_recall=recall_score(test_y,gbdt_predictions)\n",
    "gbdt_f1=f1_score(test_y,gbdt_predictions)\n",
    "\n",
    "test_y_score=gbdt_model.predict_proba(test_x)[:,-1]\n",
    "gbdt_auc=roc_auc_score(test_y,test_y_score)\n",
    "gbdt_accuracy=accuracy_score(test_y,gbdt_predictions)\n",
    "print('gbdt',gbdt_precision,gbdt_recall,gbdt_f1,gbdt_auc,gbdt_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVR\n",
    "from sklearn.svm import SVR,SVC\n",
    "# 回归模型\n",
    "# svr = SVR(kernel='linear', C=1.25)\n",
    "# 分类模型\n",
    "svr_model = SVC(kernel='rbf',\n",
    "          C=50,\n",
    "          cache_size=200,\n",
    "            probability=True,\n",
    "          random_state=3)\n",
    "svr_model.fit(tran_x_sm,tran_y_sm)\n",
    "svr_predictions=svr_model.predict(test_x)\n",
    "\n",
    "svr_precision = precision_score(test_y,svr_predictions)\n",
    "svr_recall=recall_score(test_y,svr_predictions)\n",
    "svr_f1=f1_score(test_y,svr_predictions)\n",
    "\n",
    "test_y_score=svr_model.predict_proba(test_x)[:,-1]\n",
    "svr_auc=roc_auc_score(test_y,test_y_score)\n",
    "svr_accuracy=accuracy_score(test_y,svr_predictions)\n",
    "print('SVC',svr_precision,svr_recall,svr_f1,svr_auc,svr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?svr_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN训练\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor()\n",
    "knn.fit(tran_x,tran_y)\n",
    "predictions=knn.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear回归，Lasso回归，领回归\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge,ElasticNet,LogisticRegression\n",
    "lcv_model = LogisticRegression(penalty='l2',\n",
    "                         C=5,\n",
    "                        solver='lbfgs',\n",
    "                         max_iter=100,\n",
    "                        random_state=3)\n",
    "# lcv = Lasso()\n",
    "# lcv = Ridge()\n",
    "\n",
    "lcv_model.fit(tran_x_sm, tran_y_sm)\n",
    "lcv_predictions = lcv_model.predict(test_x)\n",
    "\n",
    "lcv_precision = precision_score(test_y,lcv_predictions)\n",
    "lcv_recall=recall_score(test_y,lcv_predictions)\n",
    "lcv_f1=f1_score(test_y,lcv_predictions)\n",
    "\n",
    "test_y_score=lcv_model.predict_proba(test_x)[:,-1]\n",
    "lcv_auc=roc_auc_score(test_y,test_y_score)\n",
    "lcv_accuracy=accuracy_score(test_y,lcv_predictions)\n",
    "print('lr',lcv_precision,lcv_recall,lcv_f1,lcv_auc,lcv_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "ann_params = {'alpha': [0.0001,0.001,0.01,0.1,0.8],\n",
    "              \"solver\": ['adam', 'sgd', 'lbfgs'],\n",
    "              'hidden_layer_sizes': [(100,), (50,), (20,), (10,)]}\n",
    "\n",
    "ANN = MLPClassifier(random_state=3)\n",
    "grid = GridSearchCV(ANN, \n",
    "                    ann_params, \n",
    "                    cv=3, \n",
    "                    scoring='f1'\n",
    "                   )\n",
    "grid.fit(tran_x_sm, tran_y_sm)\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "ANN = MLPClassifier(alpha=0.1, \n",
    "                    hidden_layer_sizes=[100,], \n",
    "                    solver='adam', \n",
    "                    activation='relu', \n",
    "                    random_state=3)\n",
    "ANN.fit(tran_x_sm, tran_y_sm)\n",
    "ann_predictions=ANN.predict(test_x)\n",
    "\n",
    "ann_precision = precision_score(test_y,ann_predictions)\n",
    "ann_recall=recall_score(test_y,ann_predictions)\n",
    "ann_f1=f1_score(test_y,ann_predictions)\n",
    "\n",
    "test_y_score=ANN.predict_proba(test_x)[:,-1]\n",
    "ann_auc=roc_auc_score(test_y,test_y_score)\n",
    "ann_accuracy=accuracy_score(test_y,ann_predictions)\n",
    "print('ann',ann_precision,ann_recall,ann_f1,ann_auc,ann_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(test_y, predictions))\n",
    "\n",
    "cm2_LogR_model = confusion_matrix(test_y, predictions)\n",
    "print(cm2_LogR_model) #混肴矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "os.chdir('D:\\Anaconda3\\Lib\\site-packages\\~-rch\\lib')\n",
    "ctypes.cdll.LoadLibrary('caffe2_nvrtc.dll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?TabNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TabNet\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "from pytorch_tabnet.multitask import TabNetMultiTaskClassifier\n",
    "TabNet_model = TabNetMultiTaskClassifier(\n",
    "                       cat_emb_dim=1,\n",
    "                       optimizer_fn=torch.optim.Adam,\n",
    "                       optimizer_params=dict(lr=2e-2),\n",
    "                       scheduler_params={\"step_size\":50, # how to use learning rate scheduler\n",
    "                                         \"gamma\":0.9},\n",
    "                       scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                       mask_type='entmax') # \"sparsemax\"\n",
    "tran_x_x, tran_x_valid, tran_y_y, tran_y_valid = train_test_split(tran_x_sm, tran_y_sm, test_size=0.125, random_state=3)\n",
    "\n",
    "TabNet_model.fit(X_train=tran_x_x, \n",
    "        y_train=tran_y_y.reshape(-1,1),\n",
    "        max_epochs=200, \n",
    "        patience=20,\n",
    "        batch_size=1024, \n",
    "        virtual_batch_size=128,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        loss_fn=[torch.nn.functional.cross_entropy]) # Optional, just an example of list usage\n",
    "\n",
    "tabnet_predictions=TabNet_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_score=model.predict_proba(test_x)\n",
    "auc=roc_auc_score(test_y,test_y_score,multi_class='ovr')\n",
    "auc=round(auc,4)\n",
    "accuracy=accuracy_score(test_y,model.predict(test_x))\n",
    "accuracy=round(accuracy,4)\n",
    "# 计算precision、recall、F1\n",
    "precision=precision_score(test_y,model.predict(test_x),average='macro')\n",
    "recall=recall_score(test_y,model.predict(test_x),average='macro')\n",
    "f1=f1_score(test_y,model.predict(test_x),average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabnet_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TabNet\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "TabNet_model = TabNetClassifier(n_d=8, \n",
    "                               n_a=8,\n",
    "                               n_steps=3, # Number of steps in the architecture (usually between 3 and 10)\n",
    "                               gamma=1.5,\n",
    "                               n_independent=2)  #TabNetRegressor()\n",
    "tran_x_x, tran_x_valid, tran_y_y, tran_y_valid = train_test_split(tran_x_sm, tran_y_sm, test_size=0.125, random_state=3)\n",
    "\n",
    "TabNet_model.fit(X_train=tran_x_x.to_numpy(), \n",
    "        y_train=tran_y_y.to_numpy(), \n",
    "        eval_set=[(tran_x_valid.to_numpy(), tran_y_valid.to_numpy())], \n",
    "        eval_name=['train'], \n",
    "        eval_metric=['auc'],\n",
    "        max_epochs=100,\n",
    "        patience=50,\n",
    "        batch_size=128,\n",
    "        virtual_batch_size=14,\n",
    "        num_workers=0,\n",
    "        drop_last=False)\n",
    "\n",
    "tab_predictions=TabNet_model.predict(test_x.to_numpy())\n",
    "\n",
    "tab_precision = precision_score(test_y,tab_predictions)\n",
    "tab_recall=recall_score(test_y,tab_predictions)\n",
    "tab_f1=f1_score(test_y,tab_predictions)\n",
    "\n",
    "test_y_score = TabNet_model.predict_proba(test_x.to_numpy())[:,-1]\n",
    "tab_auc = roc_auc_score(y_score=test_y_score, y_true=test_y)\n",
    "tab_accuracy=accuracy_score(test_y,tab_predictions)\n",
    "print('tab',tab_precision,tab_recall,tab_f1,tab_auc,tab_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tab',tab_precision,tab_recall,tab_f1,tab_auc,tab_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "predictions=TabNet_model.predict(test_x.to_numpy())\n",
    "print(classification_report(test_y, predictions))\n",
    "\n",
    "cm2_LogR_model = confusion_matrix(test_y, predictions)\n",
    "print(cm2_LogR_model) #混肴矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算评价指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算R2和均方误差MSE\n",
    "print('-----------------------计算R2和均方误差MSE---------------------------')\n",
    "\n",
    "from sklearn.metrics import mean_squared_error  # 均方误差\n",
    "from sklearn.metrics import mean_absolute_error  # 平方绝对误差\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score  # R square\n",
    "# 调用\n",
    "\n",
    "r2 = precision_score(test_y,xgb_predictions)\n",
    "print('precision: ',r2)\n",
    "mse=recall_score(test_y,xgb_predictions)\n",
    "print('recall: ',mse)\n",
    "mae=f1_score(test_y,xgb_predictions)\n",
    "print('f1: ',mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions= pd.DataFrame(data={'真实值':test_y,'预测值':xgb_predictions})\n",
    "writer = pd.ExcelWriter(project_path + '/data/df_model_测试集结果.xlsx')\n",
    "df_predictions.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重要性评分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importance =pd.read_excel(project_path +'/data/result/modeling/df_1.6_模型重要性评分_术后.xlsx',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['特征', '重要性评分'], dtype='object')"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_importance.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importance['重要性评分']=df_importance['重要性评分'].apply(lambda x: round(x,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>特征</th>\n",
       "      <th>重要性评分</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tumor_CA19-9</td>\n",
       "      <td>11.596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DB</td>\n",
       "      <td>10.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALT</td>\n",
       "      <td>10.377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tumor_CA125</td>\n",
       "      <td>9.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tumor_CEA</td>\n",
       "      <td>8.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tumor_size</td>\n",
       "      <td>8.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tumor_AFP</td>\n",
       "      <td>7.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>N</td>\n",
       "      <td>5.439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>surgery_result</td>\n",
       "      <td>4.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T</td>\n",
       "      <td>4.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>emaciation</td>\n",
       "      <td>4.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bismuth_C</td>\n",
       "      <td>3.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MSKCC</td>\n",
       "      <td>1.942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gazzaniga_T</td>\n",
       "      <td>1.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Blumgart_T</td>\n",
       "      <td>1.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>biliary_disease</td>\n",
       "      <td>1.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HBsAg</td>\n",
       "      <td>1.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>M</td>\n",
       "      <td>1.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>jaundice</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cardio_disease</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>nbdd</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HCVAb</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 特征   重要性评分\n",
       "0      tumor_CA19-9  11.596\n",
       "1                DB  10.625\n",
       "2               ALT  10.377\n",
       "3       tumor_CA125   9.468\n",
       "4         tumor_CEA   8.963\n",
       "5        tumor_size   8.164\n",
       "6         tumor_AFP   7.325\n",
       "7                 N   5.439\n",
       "8    surgery_result   4.434\n",
       "9                 T   4.330\n",
       "10       emaciation   4.316\n",
       "11        Bismuth_C   3.324\n",
       "12            MSKCC   1.942\n",
       "13      Gazzaniga_T   1.713\n",
       "14       Blumgart_T   1.648\n",
       "15  biliary_disease   1.513\n",
       "16            HBsAg   1.329\n",
       "17                M   1.077\n",
       "18         jaundice   0.860\n",
       "19   cardio_disease   0.842\n",
       "20             nbdd   0.630\n",
       "21            HCVAb   0.085"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tumor_CA19-9', 'DB', 'ALT', 'tumor_CA125', 'tumor_CEA',\n",
       "       'tumor_size', 'tumor_AFP', 'N', 'surgery_result', 'T',\n",
       "       'emaciation', 'Bismuth_C', 'MSKCC', 'Gazzaniga_T', 'Blumgart_T',\n",
       "       'biliary_disease', 'HBsAg', 'M', 'jaundice', 'cardio_disease',\n",
       "       'nbdd', 'HCVAb'], dtype=object)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_importance.特征.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_importance['特征']=['手术结果','AJCC_8分期','血型','肿瘤指标CA19-9','MSKCC分期','肿瘤指标CA125','乙肝核心抗体','输血浆','乙肝表面抗原',\n",
    "#                      '术中出血','肿瘤最大径','吸烟史','有无消瘦','饮酒史','直接胆红素','肿瘤指标AFP','肿瘤指标CEA','术前减黄','有无胆道系统疾病',\n",
    "#                      '性别','有无肝硬化']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pylab import mpl\n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei']  ##绘图显示中文\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import rc\n",
    "\n",
    "names = df_importance['特征']\n",
    "index = np.arange(len(names))\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.bar(df_importance['特征'], df_importance['重要性评分'], width=0.7,\n",
    "        color=(0.42941176470588235, 0.7294117647058823, 0.7490196078431373), tick_label=names)\n",
    "# 设置坐标刻度值的大小\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.xticks(rotation=60)\n",
    "\n",
    "plt.ylabel('Importance Score',fontsize=20)\n",
    "plt.xlabel('Variable Name',fontsize=20)\n",
    "for a, b in zip(index, df_importance['重要性评分']):\n",
    "    plt.text(a, b + 0.002, '%.4f' % b, ha='center', va='bottom', fontsize=10)\n",
    "# plt.title('重要变量得分柱形图')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 散点图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判断文件路径是否存在，如果不存在则创建该路径\n",
    "def mkdir(path):\n",
    "    folder = os.path.exists(path)\n",
    "    if not folder:  # 判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(path)  # makedirs 创建文件时如果路径不存在会创建这个路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画图\n",
    "print('-----------------------画图---------------------------')\n",
    "from pylab import mpl\n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei']  ##绘图显示中文\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import rc\n",
    "rc('mathtext', default='regular')\n",
    "\n",
    "# 散点图\n",
    "# axis设置坐标轴的范围\n",
    "# plt.axis([-20, 20, 0, 200])\n",
    "# x为x轴中坐标x的值，y为y轴中坐标y的值，x与y都是长度相同的数组序列，color为点的颜色，marker为散点的形状，\n",
    "# 折线图刻度调小，要不然点都堆到一块了\n",
    "ax = plt.gca()\n",
    "ax.set_xlim(0,10)\n",
    "ax.set_ylim(0,10)\n",
    "# plt.scatter(range(len(test_y)),test_y,c='r')\n",
    "plt.scatter(test_y,predictions,c='b')\n",
    "# 红色参照线\n",
    "plt.plot(list(range(test_y.shape[0])), list(range(test_y.shape[0])),color='r')\n",
    "# plt.plot(list(range(30)), list(range(30)),color='r')\n",
    "plt.xlabel('Number of Events(unit)')\n",
    "plt.ylabel('MTX Bone Suppression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.show()\n",
    "# 判断图片保存路径是否存在，否则创建\n",
    "jpg_path = project_path + \"/jpg\"\n",
    "mkdir(jpg_path)\n",
    "plt.savefig(jpg_path + \"/他克莫司血药浓度测试集散点图v2.0.jpg\", dpi=300)\n",
    "plt.clf()  # 删除前面所画的图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import mpl\n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei']  ##绘图显示中文\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# plt.plot(logistic_fpr, logistic_tpr,label='LogisticRegression(AUC = %0.2f)' % logistic_auc) \n",
    "# plt.plot(rf_fpr, rf_tpr,label='RandomForest(AUC = %0.2f)' % rf_auc) \n",
    "plt.plot(xgb_fpr, xgb_tpr,label='XGBoost(AUC = %0.2f)' % xgb_auc) \n",
    "# plt.plot(ann_fpr, ann_tpr,label='ANN(AUC = %0.2f)' % ann_auc) \n",
    "\n",
    "plt.plot([0, 1], [0, 1],linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('AUC Curve of MTX drug')\n",
    "plt.legend(loc=\"lower right\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.plot(logistic_recall, logistic_precision, label='LogisticRegression(AP = %0.2f)' % logistic_ap)\n",
    "plt.plot(rf_recall, rf_precision,label='RandomForest(AP = %0.2f)' % rf_ap) \n",
    "plt.plot(xgb_recall, xgb_precision,label='XGBoost(AP = %0.2f)' % xgb_ap) \n",
    "plt.plot(ann_recall, ann_precision,label='ANN(AP = %0.2f)' % ann_ap) \n",
    "         \n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 0.6])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curves')\n",
    "plt.legend(loc=\"upper right\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### summary_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(tran_y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP图\n",
    "from pylab import mpl\n",
    "from matplotlib import pyplot as plt\n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei']  ##绘图显示中文\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "from matplotlib import rc\n",
    "rc('mathtext', default='regular')\n",
    "\n",
    "import catboost,xgboost\n",
    "import shap\n",
    "shap.initjs()  # notebook环境下，加载用于可视化的JS代码\n",
    "# CatBoost模型\n",
    "cat_model=xgboost.XGBClassifier(max_depth=5,\n",
    "                        learning_rate=0.001,\n",
    "                        n_estimators=500,\n",
    "                        min_child_weight=0.5,\n",
    "                        eta=0.1,\n",
    "                        gamma=0.5,\n",
    "                        reg_lambda=5,\n",
    "                        subsample=0.8,\n",
    "                        colsample_bytree=0.8,\n",
    "                        nthread=4,\n",
    "                        scale_pos_weight=1,\n",
    "                        random_state=3)\n",
    "cat_model.fit(tran_x_sm, tran_y_sm)\n",
    "\n",
    "explainer = shap.TreeExplainer(cat_model)\n",
    "shap_values = explainer.shap_values(tran_x_sm)  # 传入特征矩阵X，计算SHAP值\n",
    "# print(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_x_sm=tran_x_sm.rename(columns={'日剂量':'上一次日剂量',\n",
    "                                   'gender':'性别',\n",
    "                                   'age':'年龄',\n",
    "                                   'test_result':'上一次TDM值'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?shap.summary_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the effects of all the features\n",
    "shap.summary_plot(shap_values, tran_x_sm,plot_size=(12,8),\n",
    "                 class_names=['1mg','1.5mg','4mg','3mg','2.5mg','2mg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_x_sm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shap = pd.DataFrame(data={'features':shap_col,\n",
    "                            'shap_pos':shap_pos_list,\n",
    "                            'shap_neg':shap_neg_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shap.to_excel(project_path+'/data/result/df_shap.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_list=[]\n",
    "for i in range(df_shap_values.shape[1]-1):\n",
    "    shap_value=df_shap_values.iloc[:,i].sum()\n",
    "    shap_list.append(shap_value)\n",
    "df_shap = pd.DataFrame(data={'features':tran_x_sm.columns,\n",
    "                            'shap_value':shap_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shap_values.iloc[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(project_path + '/data/result/df_shap值排序.xlsx')\n",
    "df_shap.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multioutput_decision_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?shap.multioutput_decision_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=df_model.columns.to_list()\n",
    "col.remove('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.multioutput_decision_plot(shap_values,shap_values,row_index=3,\n",
    "                              feature_names=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 混淆矩阵图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import catboost\n",
    "# CatBoost模型\n",
    "cat_model=xgboost.XGBClassifier(max_depth=5,\n",
    "                        learning_rate=0.001,\n",
    "                        n_estimators=500,\n",
    "                        min_child_weight=0.5,\n",
    "                        eta=0.1,\n",
    "                        gamma=0.5,\n",
    "                        reg_lambda=5,\n",
    "                        subsample=0.8,\n",
    "                        colsample_bytree=0.8,\n",
    "                        nthread=4,\n",
    "                        scale_pos_weight=1,\n",
    "                        random_state=3)\n",
    "\n",
    "cat_model.fit(tran_x_sm,tran_y_sm)\n",
    "cat_predictions=cat_model.predict(test_x)\n",
    "# 计算混淆矩阵\n",
    "cat_confusion=confusion_matrix(test_y,cat_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(cat_confusion, cmap=plt.cm.Blues) # 在特定的窗口上显示图像\n",
    "# 设置图表标题\n",
    "plt.title('XGBoost Confusion Matrix',size=20)    # 图像标题\n",
    "plt.colorbar()\n",
    "# 设置坐标轴标题\n",
    "font_x = {'family': 'Times New Roman',\n",
    "         'weight': 'normal',\n",
    "         'size': 20,}\n",
    "plt.xlabel('prediction label',font_x)\n",
    "plt.ylabel('True label',font_x)\n",
    "# 设置坐标轴刻度\n",
    "plt.tick_params(labelsize=23)  # 设置刻度值大小\n",
    "label_names=['1g','1.5g','2mg','2.5mg','3mg','4mg']\n",
    "plt.xticks(range(len(label_names)),label_names)\n",
    "plt.yticks(range(len(label_names)),label_names)\n",
    "# 显示数据\n",
    "for first_index in range(len(cat_confusion)):    #第几行\n",
    "    for second_index in range(len(cat_confusion[first_index])):    #第几列\n",
    "        print(first_index, second_index)\n",
    "        plt.text(second_index,first_index, cat_confusion[first_index][second_index],size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for first_index in range(len(cat_confusion)):    #第几行\n",
    "    print(cat_confusion[first_index])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for second_index in range(len(cat_confusion[first_index])):    #第几列\n",
    "    print(cat_confusion[first_index][second_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示数据\n",
    "for first_index in range(len(cat_confusion)):    #第几行\n",
    "    for second_index in range(len(cat_confusion[first_index])):    #第几列\n",
    "        print(first_index, second_index)\n",
    "        print(cat_confusion[first_index][second_index])\n",
    "        plt.text(first_index, second_index, cat_confusion[first_index][second_index],size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tabnet mask graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "TabNet_model = TabNetClassifier()  #TabNetRegressor()\n",
    "tran_x_x, tran_x_valid, tran_y_y, tran_y_valid = train_test_split(tran_x_sm, tran_y_sm, test_size=0.1, random_state=3)\n",
    "\n",
    "TabNet_model.fit(X_train=tran_x_x.to_numpy(),  \n",
    "        y_train=tran_y_y.to_numpy(), \n",
    "        eval_set=[(tran_x_valid.to_numpy(), tran_y_valid.to_numpy())], \n",
    "        eval_name=['train'], \n",
    "        eval_metric=['auc'],\n",
    "        max_epochs=100,\n",
    "        patience=15,\n",
    "        batch_size=128,\n",
    "        virtual_batch_size=15,\n",
    "        num_workers=0,\n",
    "        drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_matrix,masks=TabNet_model.explain(tran_x_sm.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# fig = plt.figure(figsize=(40,40))\n",
    "# ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "# plt.yticks(np.arange(0, len(explain_matrix), 1.0))\n",
    "# plt.xticks(np.arange(0, len(explain_matrix[0]), 1.0))\n",
    "# ax.set_xticklabels(tran_x_sm.columns, rotation=75)\n",
    "# plt.ylabel('Sample Number')\n",
    "# plt.xlabel('Variable')\n",
    "# # plt.imshow(explain_matrix[:30])  # 显示30个\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20,20))\n",
    "for i in range(3):\n",
    "    axs[i].set_yticks(np.arange(0, len(explain_matrix), 1.0))  # 设置左边间距\n",
    "    axs[i].set_xticks(np.arange(0, len(explain_matrix[0]), 2.0))\n",
    "    axs[i].set_ylabel('Sample Number',size=20)\n",
    "    axs[i].set_xlabel('Variable',size=20)\n",
    "    # 设置坐标刻度值的大小\n",
    "    axs[i].tick_params(labelsize=15)\n",
    "    axs[i].imshow(masks[i][:30])\n",
    "    axs[i].set_title(f\"mask {i}\")\n",
    "    axs[i].set_xticklabels(tran_x_sm.columns[::2], rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_x_sm.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "460.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
